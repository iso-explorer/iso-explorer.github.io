post_cb({"bq_ids": {"n4140": {"so_25478029_39056569_3": {"length": 38, "quality": 0.9047619047619048, "section_id": 1155}}, "n3337": {"so_25478029_39056569_3": {"length": 38, "quality": 0.9047619047619048, "section_id": 1152}}, "n4659": {"so_25478029_39056569_3": {"length": 38, "quality": 0.9047619047619048, "section_id": 1249}}}, "25478029": {"ViewCount": "550", "Body": "<p>A full/general memory barrier is one where all the LOAD and STORE operations specified before the barrier will appear to happen before all the LOAD and STORE operations specified after the barrier with respect to the other components of the system.</p>\n<p>According to <a href=\"http://en.cppreference.com/w/cpp/atomic/memory_order\" rel=\"noreferrer\">cppreference</a>, <code>memory_order_seq_cst</code> is equal to <code>memory_order_acq_rel</code> plus a single total modification order on all operations so tagged. But as far as I know, neither acquire nor release fence in C++11 enforces a #StoreLoad (load after store) ordering. A release fence requires that no previous read/write can be reordered with any following write; An acquire fence requires that no following read/write can be reordered with any previous read. Please correct me if I am wrong;)</p>\n<p>Giving an example,</p>\n<pre><code>atomic&lt;int&gt; x;\natomic&lt;int&gt; y;\n\ny.store(1, memory_order_relaxed);            //(1)\natomic_thread_fence(memory_order_seq_cst);   //(2)\nx.load(memory_order_relaxed);                //(3)\n</code></pre>\n<p>Is it allowed by a optimizing compiler to reorder instruction (3) to before (1) so that it effective looks like:</p>\n<pre><code>x.load(memory_order_relaxed);                //(3)\ny.store(1, memory_order_relaxed);            //(1)\natomic_thread_fence(memory_order_seq_cst);   //(2)\n</code></pre>\n<p>If this is a valid tranformation, then it proves that <code>atomic_thread_fence(memory_order_seq_cst)</code> doesn't not necessarily encompass the semantics of what a full barrier has.</p>\n", "Title": "Does atomic_thread_fence(memory_order_seq_cst) have the semantics of a full memory barrier?", "CreationDate": "2014-08-25T01:47:27.913", "LastActivityDate": "2016-08-23T12:30:54.613", "CommentCount": "1", "FavoriteCount": "1", "PostTypeId": "1", "LastEditDate": "2014-08-25T15:45:14.720", "LastEditorUserId": "212858", "Id": "25478029", "Score": "6", "OwnerUserId": "419391", "Tags": "<c++><c++11>", "AnswerCount": "2"}, "39056569": {"Id": "39056569", "PostTypeId": "2", "Body": "<p><code>atomic_thread_fence(memory_order_seq_cst)</code> always generates a full-barrier.</p>\n<ul>\n<li>x86_64: <code>MFENCE</code></li>\n<li>PowerPC: <code>hwsync</code></li>\n<li>Itanuim: <code>mf</code></li>\n<li>ARMv7 / ARMv8: <code>dmb ish</code></li>\n<li>MIPS64: <code>sync</code></li>\n</ul>\n<p><strong>The main thing:</strong> observing thread can simply observe in a different order, and will not matter what fences you are using in the observed thread.</p>\n<blockquote>\n<p id=\"so_25478029_39056569_0\">Is it allowed by a optimizing compiler to reorder instruction (3) to\n  before (1)?</p>\n</blockquote>\n<p>Not, it isn't allowed. But in globally visible for multithreading programm this is true, only if:</p>\n<ul>\n<li>other threads use the same <code>memory_order_seq_cst</code> for atomically read/write-operations with these values</li>\n<li>or if other threads use the same <code>atomic_thread_fence(memory_order_seq_cst);</code> between load() and store() too - but this approach doesn't guarantee sequential consistency in general, because sequential consistency is more strong guarantee</li>\n</ul>\n<p>Working Draft, Standard for Programming Language C++ 2016-07-12: <a href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4606.pdf\" rel=\"nofollow\">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4606.pdf</a></p>\n<blockquote>\n<p id=\"so_25478029_39056569_1\">\u00a7 29.3 Order and consistency</p>\n<p id=\"so_25478029_39056569_2\">\u00a7 29.3 / 8</p>\n<p id=\"so_25478029_39056569_3\">[ Note: memory_order_seq_cst ensures sequential consistency only for a\n  program that is free of data races and uses exclusively\n  memory_order_seq_cst operations. Any use of weaker ordering will\n  invalidate this guarantee unless extreme care is used. In particular,\n  memory_order_seq_cst fences ensure a total order only for the fences\n  themselves. <strong>Fences cannot, in general, be used to restore sequential\n  consistency</strong> for atomic operations with weaker ordering specifications.\n  \u2014 end note ]</p>\n</blockquote>\n<hr>\n<p><strong>How it can be mapped to assembler:</strong></p>\n<p><strong>Case-1:</strong></p>\n<pre><code>atomic&lt;int&gt; x, y\n\ny.store(1, memory_order_relaxed);            //(1)\natomic_thread_fence(memory_order_seq_cst);   //(2)\nx.load(memory_order_relaxed);                //(3)\n</code></pre>\n<p>This code <strong>isn't</strong> always equivalent to the meaning of Case-2, but this code produce the same instructions between STORE &amp; LOAD, as well as if both LOAD and STORE uses <code>memory_order_seq_cst</code> - this is Sequential Consistency which prevents StoreLoad-reordering, <strong>Case-2</strong>:</p>\n<pre><code>atomic&lt;int&gt; x, y;\n\ny.store(1, memory_order_seq_cst);            //(1)\n\nx.load(memory_order_seq_cst);                //(3)\n</code></pre>\n<p>With some notes:</p>\n<ol>\n<li>it may add duplicate instructions (as in the following example for MIPS64)</li>\n<li><p>or may use similar operations in the form of other instructions:</p>\n<ul>\n<li>as in  alternative-3/4 mappings for x86_64, <code>LOCK</code>-prefix flushes Store-Buffer exactly as <code>MFENCE</code> to prevent StoreLoad-reordering</li>\n<li>or ARMv8 - we known, that <code>DMB ISH</code> are full-barrier which prevents StoreLoad-reordering: <a href=\"http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/CHDGACJD.html\" rel=\"nofollow\">http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.den0024a/CHDGACJD.html</a></li>\n</ul></li>\n</ol>\n<blockquote>\n<p id=\"so_25478029_39056569_4\">Guide for ARMv8-A</p>\n<p id=\"so_25478029_39056569_5\">Table 13.1. Barrier parameters </p>\n<p id=\"so_25478029_39056569_6\"><code>ISH</code> Any - Any</p>\n<p id=\"so_25478029_39056569_7\">Any - Any This means that both loads and stores must complete before\n  the barrier. Both loads and stores that appear after the barrier in\n  program order must wait for the barrier to complete.</p>\n</blockquote>\n<p>Prevent reordering of two instructions can be done by additional instructions between these two. And as we see the first STORE(seq_cst) and next LOAD(seq_cst) <strong>generate instructions between its are the same as FENCE(seq_cst)</strong> (<code>atomic_thread_fence(memory_order_seq_cst)</code>)</p>\n<p>Mapping of C/C++11 <code>memory_order_seq_cst</code> to differenct CPU architectures for: <code>load()</code>, <code>store()</code>, <code>atomic_thread_fence()</code>:</p>\n<p>Note <code>atomic_thread_fence(memory_order_seq_cst);</code> <strong>always generates Full-barrier:</strong></p>\n<ul>\n<li><p><a href=\"https://godbolt.org/g/Nmlh2J\" rel=\"nofollow\">x86_64:</a> STORE-<a href=\"https://godbolt.org/g/cTmGNB\" rel=\"nofollow\"><code>MOV (into memory),</code><strong><code>MFENCE</code></strong></a>, LOAD-<code>MOV (from memory)</code>, fence-<code>MFENCE</code></p></li>\n<li><p>x86_64-alt: STORE-<code>MOV (into memory)</code>, LOAD-<strong><code>MFENCE</code></strong><code>,MOV (from memory)</code>, fence-<code>MFENCE</code></p></li>\n<li><p>x86_64-alt3: STORE-<a href=\"https://godbolt.org/g/cvM89x\" rel=\"nofollow\"><code>(LOCK) XCHG</code></a>, LOAD-<code>MOV (from memory)</code>, fence-<code>MFENCE</code> - <strong>full barrier</strong></p></li>\n<li><p>x86_64-alt4: STORE-<code>MOV (into memory)</code>, LOAD-<code>LOCK XADD(0)</code>, fence-<code>MFENCE</code> - <strong>full barrier</strong></p></li>\n<li><p><a href=\"https://godbolt.org/g/91L8hu\" rel=\"nofollow\">PowerPC:</a> STORE-<a href=\"https://godbolt.org/g/LWbC3x\" rel=\"nofollow\"><code>hwsync; st</code></a>, LOAD-<strong><code>hwsync;</code></strong><a href=\"https://godbolt.org/g/qh5kF3\" rel=\"nofollow\"><code>ld; cmp; bc; isync</code></a>, fence-<code>hwsync</code></p></li>\n<li><p>Itanium:  STORE-<code>st.rel;</code><strong><code>mf</code></strong>, LOAD-<code>ld.acq</code>, fence-<code>mf</code></p></li>\n<li><p><a href=\"https://godbolt.org/g/5OlkaS\" rel=\"nofollow\">ARMv7:</a> STORE-<code>dmb ish; str;</code><strong><code>dmb ish</code></strong>, LOAD-<code>ldr; dmb ish</code>, fence-<code>dmb ish</code></p></li>\n<li><p>ARMv7-alt: STORE-<code>dmb ish; str</code>, LOAD-<strong><code>dmb ish;</code></strong><code>ldr; dmb ish</code>, fence-<code>dmb ish</code></p></li>\n<li><p>ARMv8(AArch32): STORE-<code>STL</code>, LOAD-<code>LDA</code>, fence-<code>DMB ISH</code> - <strong>full barrier</strong></p></li>\n<li><p><a href=\"https://godbolt.org/g/WlhvUB\" rel=\"nofollow\">ARMv8(AArch64):</a> STORE-<code>STLR</code>, LOAD-<code>LDAR</code>, fence-<code>DMB ISH</code> - <strong>full barrier</strong></p></li>\n<li><p><a href=\"https://godbolt.org/g/hBrV7B\" rel=\"nofollow\">MIPS64:</a>  STORE-<a href=\"https://godbolt.org/g/KCUj5v\" rel=\"nofollow\"><code>sync; sw;</code><strong><code>sync;</code></strong></a>, LOAD-<a href=\"https://godbolt.org/g/KCUj5v\" rel=\"nofollow\"><code>sync; lw; sync;</code></a>, fence-<code>sync</code></p></li>\n</ul>\n<p>There are described all mapping of C/C++11 semantics to differenct CPU architectures for: load(), store(), atomic_thread_fence(): <a href=\"http://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html\" rel=\"nofollow\">http://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html</a></p>\n<p>Because Sequential-Consistency prevents StoreLoad-reordering, and because Sequential-Consistency (<code>store(memory_order_seq_cst)</code> and next <code>load(memory_order_seq_cst)</code>) generates instructions between its are the same as <code>atomic_thread_fence(memory_order_seq_cst)</code>, then <code>atomic_thread_fence(memory_order_seq_cst)</code> prevents StoreLoad-reordering.</p>\n</hr>", "LastEditorUserId": "1558037", "LastActivityDate": "2016-08-23T12:30:54.613", "Score": "1", "CreationDate": "2016-08-20T16:50:06.253", "ParentId": "25478029", "CommentCount": "0", "OwnerUserId": "1558037", "LastEditDate": "2016-08-23T12:30:54.613"}, "26161971": {"Id": "26161971", "PostTypeId": "2", "Body": "<p>C++ fences are not direct equivalents of CPU fence instructions, though they may well be implemented as such. C++ fences are part of the C++ memory model, which is all about visibility and ordering constraints.</p>\n<p>Given that processors typically reorder reads and writes, and cache values locally before they are made available to other cores or processors, the order in which effects become visible to other processors is not usually predictable.</p>\n<p>When thinking about these semantics, it is important therefore to think about what it is that you are trying to prevent.</p>\n<p>Let's assume that the code is mapped to machine instructions as written, (1) then (2) then (3), and these instructions guarantee that (1) is globally visible before (3) is executed.</p>\n<p>The whole purpose of the snippet is to communicate with another thread. You cannot guarantee that the other thread is running on any processor at the time that this snippet executes on our processor. Therefore the whole snippet may run uninterrupted, and (3) will still read whatever value was in <code>x</code> when (1) was executed. In this case, it is indistinguishable from an execution order of (3) (1) (2).</p>\n<p>So: yes, this is an allowed optimization, because you cannot tell the difference.</p>\n", "LastActivityDate": "2014-10-02T13:31:03.333", "CommentCount": "4", "CreationDate": "2014-10-02T13:31:03.333", "ParentId": "25478029", "Score": "0", "OwnerUserId": "5597"}});