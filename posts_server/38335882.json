post_cb({"38336167": {"ParentId": "38335882", "CommentCount": "6", "Body": "<p>The C Standard's rules for bitfields aren't precise enough to tell programmers anything useful about the layout, but nonetheless deny implementations what might otherwise be useful freedoms.</p>\n<p>In particular, bitfields are required to be stored <em>within</em> objects that are of the indicated types, or the signed/unsigned equivalent thereof.  In your first example, the first bitfield must be stored in an int64_t or uint64_t object,\nand the second one likewise, but there's enough room for them to fit into the\nsame object.  In the second example, the first bitfield must be stored in an\nint64_t or uint64_t, and the second one in an int32_t or uint32_t.  The uint64_t will have 24 bits that would be \"stranded\" even if additional bit fields were added to the end of the struct; the uint32_t has 8 bits which aren't presently used, but would be available for use of another int32_t or uint32_t bitfield whose width was less than 8 were added to the type.</p>\n<p>IMHO, the Standard strikes just about the worst possible balance here between giving compilers freedom vs giving programmers useful information/control, but it is what it is.  Personally I think bitfields would be much more useful if the preferred syntax let programmers specify their layout precisely in terms of ordinary objects (e.g. bitfield \"foo\" should be stored in 3 bits, starting at bit 4 (value of 16), of field \"foo_bar\") but I know of no plans to define such a thing in the Standard.</p>\n", "OwnerUserId": "363751", "PostTypeId": "2", "Id": "38336167", "Score": "15", "CreationDate": "2016-07-12T18:12:40.313", "LastActivityDate": "2016-07-12T18:12:40.313"}, "38335948": {"ParentId": "38335882", "PostTypeId": "2", "CommentCount": "9", "Body": "<p>In your first example</p>\n<pre><code>int64_t first : 40;\nint64_t second : 24;\n</code></pre>\n<p>Both <code>first</code> and <code>second</code> use the 64 bits of a single 64 bit integer.  This  causes the size of the class to be a single 64 bit integer.  In the second example you have</p>\n<pre><code>int64_t first : 40;\nint32_t second : 24;\n</code></pre>\n<p>Which is two separate bit fields being stored in two different chunks of memory.  You use 40 bits of the 64 bit integer and then you use 24 bit of another 32 bit integer.  This means you need at least 12 bytes(this example is using 8 bit bytes).  Most likely the extra 4 bytes you see is padding to align the class on 64 bit boundaries.</p>\n<p>As other answers and comments have pointed out this is implementation defined behavior and you can/will see different results on different implementations.</p>\n", "OwnerUserId": "4342498", "LastEditorUserId": "4342498", "LastEditDate": "2016-07-12T19:10:57.850", "Id": "38335948", "Score": "35", "CreationDate": "2016-07-12T17:58:54.933", "LastActivityDate": "2016-07-12T19:10:57.850"}, "38335882": {"CommentCount": "13", "AcceptedAnswerId": "38335948", "PostTypeId": "1", "LastEditorUserId": "963864", "CreationDate": "2016-07-12T17:54:07.203", "LastActivityDate": "2017-01-19T23:53:12.860", "LastEditDate": "2017-01-19T23:53:12.860", "ViewCount": "1947", "FavoriteCount": "3", "Title": "Why class size increases when int64_t changes to int32_t", "Id": "38335882", "Score": "28", "Body": "<p>In my first example I have two bitfields using <code>int64_t</code>.  When I compile and get the size of the class I get 8.</p>\n<pre><code>class Test\n{\n    int64_t first : 40;\n    int64_t second : 24;\n};\n\nint main()\n{\n    std::cout &lt;&lt; sizeof(Test); // 8\n}\n</code></pre>\n<p>But when I change the second bitfeild to be a <code>int32_t</code> the size of the class doubles to 16:</p>\n<pre><code>class Test\n{\n    int64_t first : 40;\n    int32_t second : 24;\n};\n\nint main()\n{\n    std::cout &lt;&lt; sizeof(Test); // 16\n}\n</code></pre>\n<p>This happens on both GCC 5.3.0 and MSVC 2015. But why?</p>\n", "Tags": "<c++><memory-alignment><bit-fields><memory-layout><object-layout>", "OwnerUserId": "5405086", "AnswerCount": "4"}, "38339166": {"ParentId": "38335882", "CommentCount": "0", "Body": "<p>To add to what others have already said:</p>\n<p>If you want to examine it, you can use a compiler option or external program to output the struct layout.</p>\n<p>Consider this file:</p>\n<pre><code>// test.cpp\n#include &lt;cstdint&gt;\n\nclass Test_1 {\n    int64_t first  : 40;\n    int64_t second : 24;\n};\n\nclass Test_2 {\n    int64_t first  : 40;\n    int32_t second : 24;\n};\n\n// Dummy instances to force Clang to output layout.\nTest_1 t1;\nTest_2 t2;\n</code></pre>\n<p>If we use a layout output flag, such as Visual Studio's <code>/d1reportSingleClassLayoutX</code> (where <code>X</code> is all or part of the class or struct name) or Clang++'s <code>-Xclang -fdump-record-layouts</code> (where <code>-Xclang</code> tells the compiler to interpret <code>-fdump-record-layouts</code> as a Clang frontend command instead of a GCC frontend command), we can dump the memory layouts of <code>Test_1</code> and <code>Test_2</code> to standard output.  [Unfortunately, I'm not sure how to do this directly with GCC.]</p>\n<p>If we do so, the compiler will output the following layouts:</p>\n<ul>\n<li>Visual Studio:</li>\n</ul>\n<pre class=\"lang-sh prettyprint-override\"><code>cl /c /d1reportSingleClassLayoutTest test.cpp\n\n// Output:\ntst.cpp\nclass Test_1    size(8):\n    +---\n 0. | first (bitstart=0,nbits=40)\n 0. | second (bitstart=40,nbits=24)\n    +---\n\n\n\nclass Test_2    size(16):\n    +---\n 0. | first (bitstart=0,nbits=40)\n 8. | second (bitstart=0,nbits=24)\n    | &lt;alignment member&gt; (size=4)\n    +---\n</code></pre>\n<ul>\n<li>Clang:</li>\n</ul>\n<pre class=\"lang-sh prettyprint-override\"><code>clang++ -c -std=c++11 -Xclang -fdump-record-layouts test.cpp\n\n// Output:\n*** Dumping AST Record Layout\n   0 | class Test_1\n   0 |   int64_t first\n   5 |   int64_t second\n     | [sizeof=8, dsize=8, align=8\n     |  nvsize=8, nvalign=8]\n\n*** Dumping IRgen Record Layout\nRecord: CXXRecordDecl 0x344dfa8 &lt;source_file.cpp:3:1, line:6:1&gt; line:3:7 referenced class Test_1 definition\n|-CXXRecordDecl 0x344e0c0 &lt;col:1, col:7&gt; col:7 implicit class Test_1\n|-FieldDecl 0x344e1a0 &lt;line:4:2, col:19&gt; col:10 first 'int64_t':'long'\n| `-IntegerLiteral 0x344e170 &lt;col:19&gt; 'int' 40\n|-FieldDecl 0x344e218 &lt;line:5:2, col:19&gt; col:10 second 'int64_t':'long'\n| `-IntegerLiteral 0x344e1e8 &lt;col:19&gt; 'int' 24\n|-CXXConstructorDecl 0x3490d88 &lt;line:3:7&gt; col:7 implicit used Test_1 'void (void) noexcept' inline\n| `-CompoundStmt 0x34912b0 &lt;col:7&gt;\n|-CXXConstructorDecl 0x3490ee8 &lt;col:7&gt; col:7 implicit constexpr Test_1 'void (const class Test_1 &amp;)' inline noexcept-unevaluated 0x3490ee8\n| `-ParmVarDecl 0x3491030 &lt;col:7&gt; col:7 'const class Test_1 &amp;'\n`-CXXConstructorDecl 0x34910c8 &lt;col:7&gt; col:7 implicit constexpr Test_1 'void (class Test_1 &amp;&amp;)' inline noexcept-unevaluated 0x34910c8\n  `-ParmVarDecl 0x3491210 &lt;col:7&gt; col:7 'class Test_1 &amp;&amp;'\n\nLayout: &lt;CGRecordLayout\n  LLVMType:%class.Test_1 = type { i64 }\n  NonVirtualBaseLLVMType:%class.Test_1 = type { i64 }\n  IsZeroInitializable:1\n  BitFields:[\n    &lt;CGBitFieldInfo Offset:0 Size:40 IsSigned:1 StorageSize:64 StorageOffset:0&gt;\n    &lt;CGBitFieldInfo Offset:40 Size:24 IsSigned:1 StorageSize:64 StorageOffset:0&gt;\n]&gt;\n\n*** Dumping AST Record Layout\n   0 | class Test_2\n   0 |   int64_t first\n   5 |   int32_t second\n     | [sizeof=8, dsize=8, align=8\n     |  nvsize=8, nvalign=8]\n\n*** Dumping IRgen Record Layout\nRecord: CXXRecordDecl 0x344e260 &lt;source_file.cpp:8:1, line:11:1&gt; line:8:7 referenced class Test_2 definition\n|-CXXRecordDecl 0x344e370 &lt;col:1, col:7&gt; col:7 implicit class Test_2\n|-FieldDecl 0x3490bd0 &lt;line:9:2, col:19&gt; col:10 first 'int64_t':'long'\n| `-IntegerLiteral 0x344e400 &lt;col:19&gt; 'int' 40\n|-FieldDecl 0x3490c70 &lt;line:10:2, col:19&gt; col:10 second 'int32_t':'int'\n| `-IntegerLiteral 0x3490c40 &lt;col:19&gt; 'int' 24\n|-CXXConstructorDecl 0x3491438 &lt;line:8:7&gt; col:7 implicit used Test_2 'void (void) noexcept' inline\n| `-CompoundStmt 0x34918f8 &lt;col:7&gt;\n|-CXXConstructorDecl 0x3491568 &lt;col:7&gt; col:7 implicit constexpr Test_2 'void (const class Test_2 &amp;)' inline noexcept-unevaluated 0x3491568\n| `-ParmVarDecl 0x34916b0 &lt;col:7&gt; col:7 'const class Test_2 &amp;'\n`-CXXConstructorDecl 0x3491748 &lt;col:7&gt; col:7 implicit constexpr Test_2 'void (class Test_2 &amp;&amp;)' inline noexcept-unevaluated 0x3491748\n  `-ParmVarDecl 0x3491890 &lt;col:7&gt; col:7 'class Test_2 &amp;&amp;'\n\nLayout: &lt;CGRecordLayout\n  LLVMType:%class.Test_2 = type { i64 }\n  NonVirtualBaseLLVMType:%class.Test_2 = type { i64 }\n  IsZeroInitializable:1\n  BitFields:[\n    &lt;CGBitFieldInfo Offset:0 Size:40 IsSigned:1 StorageSize:64 StorageOffset:0&gt;\n    &lt;CGBitFieldInfo Offset:40 Size:24 IsSigned:1 StorageSize:64 StorageOffset:0&gt;\n]&gt;\n</code></pre>\n<p>Note that the version of Clang I used to generate this output (the one used by <a href=\"http://rextester.com/l/cpp_online_compiler_clang\">Rextester</a>) appears to default to optimising both bitfields into a single variable, and I'm unsure how to disable this behaviour.</p>\n", "OwnerUserId": "5386374", "PostTypeId": "2", "Id": "38339166", "Score": "6", "CreationDate": "2016-07-12T21:26:55.707", "LastActivityDate": "2016-07-12T21:26:55.707"}, "38336704": {"ParentId": "38335882", "PostTypeId": "2", "CommentCount": "0", "Body": "<p>Standard says:</p>\n<blockquote>\n<p id=\"so_38335882_38336704_0\">\u00a7 9.6 bit-fields</p>\n<p id=\"so_38335882_38336704_1\">Allocation of bit-fields within a class\n  object is implementation-defined. Alignment of bit-fields is implementation-defined. [<em>Note:</em> Bit-fields straddle allocation units on some machines and not\n  on others. Bit-fields are assigned right-to-left on some machines, left-to-right on others. <em>\u2014 end note</em>]</p>\n</blockquote>\n<p><a href=\"https://isocpp.org/files/papers/N3690.pdf\" rel=\"nofollow\">c++11 paper</a></p>\n<p>So layout depends on compiler implementation, compilation flags, target arch and so on. Just checked several compilers and output mostly is <code>8 8</code>:</p>\n<pre><code>#include &lt;stdint.h&gt;\n#include &lt;iostream&gt;\n\nclass Test32\n{\n    int64_t first : 40;\n    int32_t second : 24;\n};\n\nclass Test64\n{\n    int64_t first : 40;\n    int64_t second : 24;\n};\n\nint main()\n{\n    std::cout &lt;&lt; sizeof(Test32) &lt;&lt; \" \" &lt;&lt; sizeof(Test64);\n}\n</code></pre>\n", "OwnerUserId": "513392", "LastEditorUserId": "636009", "LastEditDate": "2016-07-13T08:02:42.073", "Id": "38336704", "Score": "5", "CreationDate": "2016-07-12T18:47:05.427", "LastActivityDate": "2016-07-13T08:02:42.073"}, "bq_ids": {"n4140": {"so_38335882_38336704_1": {"section_id": 5921, "quality": 0.8076923076923077, "length": 21}}, "n3337": {"so_38335882_38336704_1": {"section_id": 5693, "quality": 0.8076923076923077, "length": 21}}, "n4659": {"so_38335882_38336704_1": {"section_id": 7395, "quality": 0.8076923076923077, "length": 21}}}});