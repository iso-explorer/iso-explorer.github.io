post_cb({"3257527": {"ParentId": "3257263", "CommentCount": "4", "Body": "<p>No, there is no way to make Windows treat \"narrow\" strings as UTF-8.</p>\n<p>Here is what works best for me in this situation (cross-platform application that has Windows and Linux builds).</p>\n<ul>\n<li>Use std::string in cross-platform portion of the code. Assume that it always contains UTF-8 strings.</li>\n<li>In Windows portion of the code, use \"wide\" versions of Windows API explicitly, i.e. write e.g. CreateFileW instead of CreateFile. This allows to avoid dependency on build system configuration.</li>\n<li>In the platfrom abstraction layer, convert between UTF-8 and UTF-16 where needed (MultiByteToWideChar/WideCharToMultiByte).</li>\n</ul>\n<p>Other approaches that I tried but don't like much:</p>\n<ul>\n<li><code>typedef std::basic_string&lt;TCHAR&gt; tstring;</code> then use tstring in the business code. Wrappers/overloads can be made to streamline conversion between std::string and std::tstring, but it still adds a lot of pain.</li>\n<li>Use <code>std::wstring</code> everywhere. Does not help much since <code>wchar_t</code> is 16 bit on Windows, so you either have to restrict yourself to BMP or go to a lot of complications to make the code dealing with Unicode cross-platform. In the latter case, all benefits over UTF-8 evaporate.</li>\n<li>Use ATL/WTL/MFC <code>CString</code> in the platfrom-specific portion; use <code>std::string</code> in cross-platfrom portion. This is actually a variant of what I recommend above. <code>CString</code> is in many aspects superior to <code>std::string</code> (in my opinion). But it introduces an additional dependency and thus not always acceptable or convenient.</li>\n</ul>\n", "OwnerUserId": "23252", "PostTypeId": "2", "Id": "3257527", "Score": "2", "CreationDate": "2010-07-15T16:07:16.920", "LastActivityDate": "2010-07-15T16:07:16.920"}, "3278218": {"ParentId": "3257263", "CommentCount": "1", "Body": "<p>Yes - by being more aware of locales and encodings.</p>\n<p>Windows has two function calls for everything that requires text, a FoobarA() and a FoobarW(). The *W() functions take UTF-16 encoded strings, the *A() takes strings in the current codepage. However, Windows doesn't support a UTF-8 code page, so you can't directly use it in that sense with the *A() functions, nor would you want to depend on that being set by users. If you want \"Unicode\" in Windows, use the Unicode-capable (*W) functions. There are tutorials out there, Googling \"Unicode Windows tutorial\" should get you some.</p>\n<p>If you are storing UTF-8 data in a std::string, then before you pass it off to Windows, convert it to UTF-16 (Windows provides functions for doing such), and then pass it to Windows.</p>\n<p>Many of these problems arise from C/C++ being generally encoding-agnostic. <code>char</code> isn't really a character, it's just an integral type. Even using <code>char</code> arrays to store UTF-8 data can get you into trouble if you need to access individual code units, as <code>char</code>'s signed-ness is left undefined by the standards. A statement like <code>str[x] &lt; 0x80</code> to check for multiple-byte characters can quickly introduce a bug. (That statement is always true if <code>char</code> is signed.) A UTF-8 code unit is an unsigned integral type with a range of 0-255. That maps to the C type of <code>uint8_t</code> exactly, although <code>unsigned char</code> works as well. Ideally then, I'd make a UTF-8 string an array of <code>uint8_t</code>s, but due to old APIs, this is rarely done.</p>\n<p>Some people have recommended <code>wchar_t</code>, claiming it to be \"A Unicode character type\" or something like that. Again, here the standard is just as agnostic as before, as C is meant to work anywhere, and anywhere might not be using Unicode. Thus, <code>wchar_t</code> is no more Unicode than <code>char</code>. The standard states:</p>\n<blockquote>\n<p id=\"so_3257263_3278218_0\">which is an integer type whose range of values can represent distinct codes for all members of the largest extended character set specified among the supported locales</p>\n</blockquote>\n<p>In Linux, a <code>wchat_t</code> represents a UTF-32 code unit / code point. It is thus 4 bytes. However, in Windows, it's a UTF-16 code unit, and is only 2 bytes. (Which, I would have said does not conform to the above, since 2-bytes cannot represent all of Unicode, but that's the way it works.) This size difference, and difference in data encoding, clearly puts a strain on portability. The Unicode standard itself recommends against <code>wchar_t</code> if you need portability. (\u00a75.2)</p>\n<p><strong>The end lesson:</strong> I find it easiest to store all my data in some well-declared format. (Typically UTF-8, usually in std::string's, but I'd really like something better.) The important thing here is not the UTF-8 part, but rather, I <em>know</em> that my strings are UTF-8. If I'm passing them to some other API, I must also <em>know</em> that that API expects UTF-8 strings. If it doesn't, then I must convert them. (Thus, if I speak to Window's API, I must convert strings to UTF-16 first.) A UTF-8 text string is an \"orange\", and a \"latin1\" text string is an \"apple\". A <code>char</code> array that doesn't know what encoding it is in is a recipe for disaster.</p>\n", "OwnerUserId": "101999", "PostTypeId": "2", "Id": "3278218", "Score": "8", "CreationDate": "2010-07-19T03:04:45.663", "LastActivityDate": "2010-07-19T03:04:45.663"}, "3273410": {"ParentId": "3257263", "PostTypeId": "2", "CommentCount": "1", "Body": "<p>In the Windows API and C runtime library, <code>char*</code> parameters are interpreted as being encoded in the \"ANSI\" code page.  The problem is that <a href=\"http://www.siao2.com/2007/01/03/1392379.aspx\" rel=\"nofollow noreferrer\">UTF-8 isn't supported as an ANSI code page</a>, which <a href=\"https://stackoverflow.com/questions/2995111/why-isnt-utf-8-allowed-as-the-ansi-code-page\">I find incredibly annoying</a>.</p>\n<p>I'm in a similar situation, being in the middle of porting software from Windows to Linux while also making it Unicode-aware.  The approach we've taken for this is:</p>\n<ul>\n<li>Use UTF-8 as the default encoding for strings.</li>\n<li>In Windows-specific code, always call the \"W\" version of functions, converting string arguments between UTF-8 and UTF-16 as necessary.</li>\n</ul>\n<p>This is also <a href=\"http://pocoproject.org/blog/?p=109\" rel=\"nofollow noreferrer\">the approach Poco has taken</a>.</p>\n", "OwnerUserId": "287586", "LastEditorUserId": "-1", "LastEditDate": "2017-05-23T12:33:39.247", "Id": "3273410", "Score": "1", "CreationDate": "2010-07-17T21:47:51.653", "LastActivityDate": "2010-07-17T21:47:51.653"}, "3257333": {"ParentId": "3257263", "CommentCount": "4", "Body": "<p>Putting UTF-8 code points into an <code>std::string</code> should be fine regardless of platform. The problem on Windows is that almost nothing else expects or works with UTF-8 -- it expects and works with UTF-16 instead. You can switch to an <code>std::wstring</code> which will store UTF-16 (at least on most Windows compilers) or you can write other routines that will accept UTF-8 (probably by converting to UTF-16, and then passing through to the OS).</p>\n", "OwnerUserId": "179910", "PostTypeId": "2", "Id": "3257333", "Score": "7", "CreationDate": "2010-07-15T15:50:06.293", "LastActivityDate": "2010-07-15T15:50:06.293"}, "40824212": {"ParentId": "3257263", "CommentCount": "0", "Body": "<p>It really platform dependant, Unicode is headache. Depends on which compiler you use. For older ones from MS (VS2010 or older), you would need use API described in MSDN</p>\n<p>for VS2015</p>\n<pre><code>std::string _old = u8\"D:\\\\Folder\\\\This \\xe2\\x80\\x93 by ABC.txt\"s;\n</code></pre>\n<p>according to their docs. I can't check that one.</p>\n<p>for mingw, gcc, etc.</p>\n<pre><code>std::string _old = u8\"D:\\\\Folder\\\\This \\xe2\\x80\\x93 by ABC.txt\";\nstd::cout &lt;&lt; _old.data();\n</code></pre>\n<p>output contains proper file name...</p>\n", "OwnerUserId": "2742717", "PostTypeId": "2", "Id": "40824212", "Score": "0", "CreationDate": "2016-11-26T23:26:33.797", "LastActivityDate": "2016-11-26T23:26:33.797"}, "3257263": {"CommentCount": "3", "ViewCount": "15476", "PostTypeId": "1", "LastEditorUserId": "527702", "CreationDate": "2010-07-15T15:43:07.243", "LastActivityDate": "2016-11-26T23:26:33.797", "Title": "How do I get STL std::string to work with unicode on windows?", "FavoriteCount": "4", "LastEditDate": "2011-03-30T13:17:01.047", "Id": "3257263", "Score": "8", "Body": "<p>At my company we have a cross platform(Linux &amp; Windows) library that contains our own extension of the STL std::string, this class provides all sort of functionality on top of the string; split, format, to/from base64, etc. Recently we were given the requirement of making this string unicode \"friendly\" basically it needs to support characters from Chinese, Japanese, Arabic, etc. After initial research this seems fine on the Linux side since every thing is inherently UTF-8, however I am having trouble with the Windows side; is there a trick to getting the STL std::string to work as UTF-8 on windows? Is it even possible? Is there a better way? Ideally we would keep ourselves based on the std::string since that is what the string class is based on in Linux.</p>\n<p>Thank you,</p>\n", "Tags": "<c++><windows><string><unicode><stl>", "OwnerUserId": "90416", "AnswerCount": "8"}, "3257312": {"ParentId": "3257263", "CommentCount": "1", "Body": "<p>Have you looked at <code>std::wstring</code>? It's a version of <code>std::basic_string</code> for <code>wchar_t</code> rather than the <code>char</code> that <code>std::string</code> uses.</p>\n", "OwnerUserId": "251738", "PostTypeId": "2", "Id": "3257312", "Score": "4", "CreationDate": "2010-07-15T15:47:58.167", "LastActivityDate": "2010-07-15T15:47:58.167"}, "3257344": {"ParentId": "3257263", "PostTypeId": "2", "CommentCount": "5", "Body": "<p>There are several misconceptions in your question.</p>\n<ul>\n<li><p>Neither C++ nor the STL deal with encodings.</p></li>\n<li><p><code>std::string</code> is essentially a string of <em>bytes</em>, not <em>characters</em>. So you should have no problem stuffing UTF-8 encoded Unicode into it. However, keep in mind that all <code>string</code> functions also work on bytes, so <code>myString.length()</code> will give you the number of bytes, not the number of characters.</p></li>\n<li><p>Linux is <em>not</em> inherently UTF-8. Most distributions nowadays default to UTF-8, but it should not be relied upon.</p></li>\n</ul>\n", "OwnerUserId": "14637", "LastEditorUserId": "14637", "LastEditDate": "2011-08-26T12:01:08.557", "Id": "3257344", "Score": "11", "CreationDate": "2010-07-15T15:51:30.420", "LastActivityDate": "2011-08-26T12:01:08.557"}, "bq_ids": {"n4140": {"so_3257263_3278218_0": {"section_id": 7214, "quality": 0.8947368421052632, "length": 17}}, "n3337": {"so_3257263_3278218_0": {"section_id": 6958, "quality": 0.8947368421052632, "length": 17}}, "n4659": {"so_3257263_3278218_0": {"section_id": 8723, "quality": 0.8947368421052632, "length": 17}}}, "3266185": {"ParentId": "3257263", "CommentCount": "0", "Body": "<p>If you want to avoid headache, don't use the STL string types at all. C++ knows nothing about Unicode or encodings, so to be portable, it's better to use a library that is tailored for Unicode support, e.g. the ICU library. ICU uses UTF-16 strings by default, so no conversion is required, and supports conversions to many other important encodings like UTF-8. Also try to use cross-platform libraries like Boost.Filesystem for things like path manipulations (<code>boost::wpath</code>). Avoid <code>std::string</code> and <code>std::fstream</code>.</p>\n", "OwnerUserId": "178761", "PostTypeId": "2", "Id": "3266185", "Score": "2", "CreationDate": "2010-07-16T15:01:25.020", "LastActivityDate": "2010-07-16T15:01:25.020"}});