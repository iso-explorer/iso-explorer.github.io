post_cb({"38399181": {"CommentCount": "5", "ViewCount": "255", "PostTypeId": "1", "LastEditorUserId": "1576556", "CreationDate": "2016-07-15T14:52:27.620", "LastActivityDate": "2016-07-17T01:53:51.367", "Title": "How to synchronize threads/CPUs without mutexes if sequence of access is known to be safe?", "AcceptedAnswerId": "38406548", "LastEditDate": "2016-07-15T19:27:28.143", "Id": "38399181", "Score": "3", "Body": "<p>Consider the following:</p>\n<pre><code>// these services are running on different threads that are started a long time ago\nstd::vector&lt;io_service&amp;&gt; io_services;\n\nstruct A {\n  std::unique_ptr&lt;Object&gt; u;\n} a;\n\nio_services[0].post([&amp;io_services, &amp;a] {\n      std::unique_ptr&lt;Object&gt; o{new Object};\n\n      a.u = std::move(o);\n\n      io_services[1].post([&amp;a] {\n            // as far as I know changes to `u` isn't guaranteed to be seen in this thread \n            a.u-&gt;...;\n          });\n    });\n</code></pre>\n<p>The actual code passes a struct to a bunch of different <code>boost::asio::io_service</code> objects and each field of struct is filled by a different service object <strong>(the struct is never accessed from different io_service objects/threads at the same time, it is passed between the services by reference until the process is done)</strong>.</p>\n<p>As far as I know I always need some kind of explicit synchronization/memory flushing when I pass anything between threads even if there is no read/write race (as in simultaneous access). What is the way of correctly doing it in this case?</p>\n<p>Note that <strong>Object</strong> does not belong to me and it is not trivially copy-able or movable. I could use a <code>std::atomic&lt;Object*&gt;</code> (if I am not wrong) but I would rather use the smart pointer. Is there a way to do that?</p>\n<p>Edit:\nIt seems like <a href=\"http://en.cppreference.com/w/cpp/atomic/atomic_thread_fence\" rel=\"nofollow\">std::atomic_thread_fence</a> is the tool for the job but I cannot really wrap the 'memory model' concepts to safely code.\nMy understanding is that the following lines are needed for this code to work correctly. Is it really the case?</p>\n<pre><code>// these services are running on different threads that are started a long time ago\nstd::vector&lt;io_service&amp;&gt; io_services;\n\nstruct A {\n  std::unique_ptr&lt;Object&gt; u;\n} a;\n\nio_services[0].post([&amp;io_services, &amp;a] {\n      std::unique_ptr&lt;Object&gt; o{new Object};\n\n      a.u = std::move(o);\n\n      std::atomic_thread_fence(std::memory_order_release);\n\n      io_services[1].post([&amp;a] {\n            std::atomic_thread_fence(std::memory_order_acquire);\n\n            a.u-&gt;...;\n          });\n    });\n</code></pre>\n", "Tags": "<c++><multithreading><c++11><synchronization><memory-barriers>", "OwnerUserId": "1576556", "AnswerCount": "2"}, "38399280": {"ParentId": "38399181", "PostTypeId": "2", "CommentCount": "7", "CreationDate": "2016-07-15T14:57:14.527", "Score": "3", "LastEditorUserId": "6255513", "LastEditDate": "2016-07-15T15:34:16.697", "Id": "38399280", "OwnerUserId": "6255513", "Body": "<p>Synchronisation is only needed when there would be a data race without it. A data race is defined as unsequenced access by different threads. </p>\n<p>You have no such unsequenced access. The <code>t.join()</code> guarantees that all statements that follow are sequenced strictly after all statements that run as part of <code>t</code>. So no synchronisation is required.</p>\n<p><strong>ELABORATION:</strong> (To explain why <code>thread::join</code> has the above claimed properties) First, description of <code>thread::join</code> from standard [thread.thread.member]:</p>\n<blockquote>\n<p id=\"so_38399181_38399280_0\">void join(); </p>\n<ol start=\"3\">\n<li>Requires: joinable() is true. </li>\n<li>Effects: Blocks until\n  the thread represented by *this has completed. </li>\n<li>Synchronization: The\n  completion of the thread represented by *this <strong>synchronizes with (1.10)\n  the corresponding successful join() return</strong>.</li>\n</ol>\n</blockquote>\n<p>a). The above shows that <code>join()</code> provides synchronisation (specifically: the completion of the thread represented by *this synchronises with the outer thread calling <code>join()</code>). Next [intro.multithread]:</p>\n<blockquote>\n<ol start=\"13\">\n<li>An evaluation A <em>inter-thread happens before</em> an evaluation B if</li>\n</ol>\n<p id=\"so_38399181_38399280_1\">(13.1) \u2014 A synchronizes with B, or ...</p>\n</blockquote>\n<p>Which shows that, because of a), we have that the completion of <code>t</code> <em>inter-thread happens before</em> the return of the <code>join()</code> call.</p>\n<p>Finally, [intro.multithread]:</p>\n<blockquote>\n<ol start=\"23\">\n<li>Two actions are potentially concurrent if </li>\n</ol>\n<p id=\"so_38399181_38399280_2\">(23.1) \u2014 they are performed\n  by different threads, or </p>\n<p id=\"so_38399181_38399280_3\">(23.2) \u2014 they are unsequenced, and at least\n  one is performed by a signal handler.</p>\n<p id=\"so_38399181_38399280_4\">The execution of a program\n  contains a data race if it contains two potentially concurrent\n  conflicting actions, at least one of which is not atomic, and neither\n  <em>happens before</em> the other ...</p>\n</blockquote>\n<p>Above the required conditions for a data race are described. The situation with <code>t.join()</code> does not meet these conditions because, as shown, the completion of <code>t</code> does in fact <em>happen-before</em> the return of <code>join()</code>.</p>\n<p>So there is no data race, and all data accesses are guaranteed well-defined behaviour.</p>\n", "LastActivityDate": "2016-07-15T15:34:16.697"}, "bq_ids": {"n4140": {"so_38399181_38399280_4": {"section_id": 5834, "quality": 0.8888888888888888, "length": 16}, "so_38399181_38399280_3": {"section_id": 5834, "quality": 0.875, "length": 7}, "so_38399181_38399280_2": {"section_id": 5834, "quality": 0.8, "length": 4}}, "n3337": {"so_38399181_38399280_4": {"section_id": 5605, "quality": 0.7777777777777778, "length": 14}}, "n4659": {"so_38399181_38399280_4": {"section_id": 7296, "quality": 0.8888888888888888, "length": 16}, "so_38399181_38399280_3": {"section_id": 7296, "quality": 0.875, "length": 7}, "so_38399181_38399280_2": {"section_id": 7296, "quality": 0.8, "length": 4}}}, "38406548": {"ParentId": "38399181", "PostTypeId": "2", "CommentCount": "1", "CreationDate": "2016-07-16T00:18:49.130", "Score": "1", "LastEditorUserId": "636019", "LastEditDate": "2016-07-17T01:53:51.367", "Id": "38406548", "OwnerUserId": "636019", "Body": "<p><sup>(I'd like to remark that you appear to have changed your question in some significant way since @Smeeheey answered it; essentially, he answered your originally-worded question but cannot get credit for it since you asked two different questions. This is poor form \u2013 in the future, please just post a new question so the original answerer can get credit as due.)</sup></p>\n<p>If multiple threads read/write a variable, even if <em>you</em> know said variable is accessed in a defined sequence, you <em>must</em> still inform the compiler of that. The correct way to do this necessarily involves synchronization, atomics, or something documented to perform one of the prior itself (such as <code>std::thread::join</code>). Presuming the synchronization route is both obvious in implementation and undesirable..:</p>\n<p>Addressing this with atomics <em>may</em> simply consist of <code>std::atomic_thread_fence</code>; however, an acquire fence in C++ cannot <em>synchronize-with</em> a release fence alone \u2013 an actual atomic object must be modified. Consequently, if you want to use fences alone you'll need to specify <code>std::memory_order_seq_cst</code>; that done, your code will work as shown otherwise.</p>\n<p>If you want to stick with release/acquire semantics, fortunately even the simplest atomic will do \u2013 <a href=\"http://en.cppreference.com/w/cpp/atomic/atomic_flag\" rel=\"nofollow\"><code>std::atomic_flag</code></a>:</p>\n<pre><code>std::vector&lt;io_service&amp;&gt; io_services;\n\nstruct A {\n  std::unique_ptr&lt;Object&gt; u;\n} a;\nstd::atomic_flag a_initialized = ATOMIC_FLAG_INIT;\n\nio_services[0].post([&amp;io_services, &amp;a, &amp;a_initialized] {\n    std::unique_ptr&lt;Object&gt; o{new Object};\n\n    a_initialized.clear(std::memory_order_release); // initiates release sequence (RS)\n    a.u = std::move(o);\n    a_initialized.test_and_set(std::memory_order_relaxed); // continues RS\n\n    io_services[1].post([&amp;a, &amp;a_initialized] {\n        while (!a_initialized.test_and_set(std::memory_order_acquire)) ; // completes RS\n\n        a.u-&gt;...;\n    });\n});\n</code></pre>\n<p>For information on release sequences, see <a href=\"http://en.cppreference.com/w/cpp/atomic/memory_order#Release_sequence\" rel=\"nofollow\">here</a>.</p>\n", "LastActivityDate": "2016-07-17T01:53:51.367"}});