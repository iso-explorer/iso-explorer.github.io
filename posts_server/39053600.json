post_cb({"bq_ids": {"n4140": {"so_39053600_42857017_2": {"length": 28, "quality": 1.0, "section_id": 1150}, "so_39053600_42857017_4": {"length": 38, "quality": 0.9047619047619048, "section_id": 1155}, "so_39053600_39053600_2": {"length": 20, "quality": 0.9090909090909091, "section_id": 1148}}, "n3337": {"so_39053600_42857017_2": {"length": 28, "quality": 1.0, "section_id": 1147}, "so_39053600_42857017_4": {"length": 38, "quality": 0.9047619047619048, "section_id": 1152}, "so_39053600_39053600_2": {"length": 20, "quality": 0.9090909090909091, "section_id": 1145}}, "n4659": {"so_39053600_42857017_2": {"length": 28, "quality": 1.0, "section_id": 1244}, "so_39053600_42857017_4": {"length": 38, "quality": 0.9047619047619048, "section_id": 1249}, "so_39053600_39053600_2": {"length": 20, "quality": 0.9090909090909091, "section_id": 1242}}}, "39053600": {"ViewCount": "349", "Body": "<p>Does standard C++11 guarantee that <code>memory_order_seq_cst</code> prevents StoreLoad reordering around an atomic operation for non-atomic memory accesses?</p>\n<p>As known, there are 6 <code>std::memory_order</code>s in C++11, and its specifies <strong>how regular, non-atomic</strong> memory accesses are to be ordered around an atomic operation - Working Draft, Standard for Programming Language C++ 2016-07-12: <a href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4606.pdf\" rel=\"nofollow noreferrer\">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4606.pdf</a></p>\n<blockquote>\n<p id=\"so_39053600_39053600_0\">\u00a7 29.3 Order and consistency</p>\n<p id=\"so_39053600_39053600_1\">\u00a7 29.3 / 1</p>\n<p id=\"so_39053600_39053600_2\">The enumeration <strong>memory_order</strong> specifies the detailed <strong>regular\n  (non-atomic) memory</strong> synchronization order as defined in 1.10 and may\n  provide for operation ordering. Its enumerated values and their\n  meanings are as follows:</p>\n</blockquote>\n<p>Also known, that these 6 memory_orders prevent some of these reordering:</p>\n<p><a href=\"https://i.stack.imgur.com/YWWWs.jpg\" rel=\"nofollow noreferrer\"><img alt=\"enter image description here\" src=\"https://i.stack.imgur.com/YWWWs.jpg\"/></a></p>\n<p>But, does <code>memory_order_seq_cst</code> prevent StoreLoad reordering around an atomic operation for <strong>regular, non-atomic</strong> memory accesses or only for other atomic with the same <code>memory_order_seq_cst</code>?</p>\n<p>I.e. to prevent this StoreLoad-reordering should we use <code>std::memory_order_seq_cst</code> for both STORE and LOAD, or only for one of it?</p>\n<pre><code>std::atomic&lt;int&gt; a, b;\nb.store(1, std::memory_order_seq_cst); // Sequential Consistency\na.load(std::memory_order_seq_cst); // Sequential Consistency\n</code></pre>\n<hr>\n<p>About Acquire-Release semantic is all clear, it specifies exactly non-atomic memory-access reordering across atomic operations: <a href=\"http://en.cppreference.com/w/cpp/atomic/memory_order\" rel=\"nofollow noreferrer\">http://en.cppreference.com/w/cpp/atomic/memory_order</a></p>\n<hr>\n<p>To prevent StoreLoad-reordering we should use <code>std::memory_order_seq_cst</code>.</p>\n<p>Two examples:</p>\n<ol>\n<li><code>std::memory_order_seq_cst</code> for both STORE and LOAD: <strong>there is <code>MFENCE</code></strong> </li>\n</ol>\n<p>StoreLoad can't be reordered - GCC 6.1.0 x86_64: <a href=\"https://godbolt.org/g/mVZJs0\" rel=\"nofollow noreferrer\">https://godbolt.org/g/mVZJs0</a></p>\n<pre><code>std::atomic&lt;int&gt; a, b;\nb.store(1, std::memory_order_seq_cst); // can't be executed after LOAD\na.load(std::memory_order_seq_cst); // can't be executed before STORE\n</code></pre>\n<ol start=\"2\">\n<li><code>std::memory_order_seq_cst</code> for LOAD only: <strong>there isn't <code>MFENCE</code></strong></li>\n</ol>\n<p>StoreLoad can be reordered - GCC 6.1.0 x86_64: <a href=\"https://godbolt.org/g/2NLy12\" rel=\"nofollow noreferrer\">https://godbolt.org/g/2NLy12</a></p>\n<pre><code>std::atomic&lt;int&gt; a, b;\nb.store(1, std::memory_order_release); // can be executed after LOAD\na.load(std::memory_order_seq_cst); // can be executed before STORE\n</code></pre>\n<p>Also if C/C++-compiler used alternative mapping of C/C++11 to x86, which flushes the Store Buffer before the LOAD: <code>MFENCE,MOV (from memory)</code>, so we must use <code>std::memory_order_seq_cst</code> for LOAD too: <a href=\"http://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html\" rel=\"nofollow noreferrer\">http://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html</a> As this example is discussed in another question as approach (3): <a href=\"https://stackoverflow.com/questions/20316124/does-it-make-any-sense-instruction-lfence-in-processors-x86-x86-64?noredirect=1&amp;lq=1\">Does it make any sense instruction LFENCE in processors x86/x86_64?</a> </p>\n<p>I.e. we should use <code>std::memory_order_seq_cst</code> for both STORE and LOAD to generate <code>MFENCE</code> guaranteed, that prevents StoreLoad reordering.</p>\n<p>Is it true, that <code>memory_order_seq_cst</code> for atomic Load or Store:</p>\n<ul>\n<li><p>specifi Acquire-Release semantic - prevent: LoadLoad, LoadStore, StoreStore reordering around an atomic operation for <strong>regular, non-atomic</strong> memory accesses, </p></li>\n<li><p>but prevent StoreLoad reordering around an atomic operation <strong>only for other atomic</strong> operations with  the same <code>memory_order_seq_cst</code>?</p></li>\n</ul>\n</hr></hr>", "AcceptedAnswerId": "42857017", "Title": "Does standard C++11 guarantee that memory_order_seq_cst prevents StoreLoad reordering of non-atomic around an atomic?", "CreationDate": "2016-08-20T11:28:12.050", "Id": "39053600", "CommentCount": "0", "FavoriteCount": "3", "PostTypeId": "1", "LastEditDate": "2017-05-23T12:34:11.653", "LastEditorUserId": "-1", "LastActivityDate": "2017-07-30T22:40:40.977", "Score": "10", "OwnerUserId": "1558037", "Tags": "<c++><multithreading><c++11><concurrency><standards>", "AnswerCount": "2"}, "42857017": {"Id": "42857017", "PostTypeId": "2", "Body": "<p>No, standard C++11 <strong>doesn't</strong> guarantee that <code>memory_order_seq_cst</code> prevents <strong>StoreLoad</strong> reordering of <code>non-atomic</code> around an <code>atomic(seq_cst)</code>.</p>\n<p>Even standard C++11 <strong>doesn't</strong> guarantee that <code>memory_order_seq_cst</code> prevents <strong>StoreLoad</strong> reordering of <code>atomic(non-seq_cst)</code> around an <code>atomic(seq_cst)</code>.</p>\n<p>Working Draft, Standard for Programming Language C++ 2016-07-12: <a href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4606.pdf\" rel=\"nofollow noreferrer\">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/n4606.pdf</a></p>\n<ul>\n<li>There shall be a single total order S on all <code>memory_order_seq_cst</code> operations - C++11 Standard:</li>\n</ul>\n<blockquote>\n<p id=\"so_39053600_42857017_0\">\u00a7 29.3 </p>\n<p id=\"so_39053600_42857017_1\">3 </p>\n<p id=\"so_39053600_42857017_2\"><strong>There shall be a single total order S on all memory_order_seq_cst\n  operations, consistent with the \u201chappens before\u201d order and\n  modification orders for all affected locations</strong>, such that each\n  memory_order_seq_cst operation B that loads a value from an atomic\n  object M observes one of the following values: ...</p>\n</blockquote>\n<ul>\n<li>But, any atomic operations with ordering weaker than <code>memory_order_seq_cst</code> hasn't sequential consistency and hasn't single total order, i.e. non-<code>memory_order_seq_cst</code> operations can be reordered with <code>memory_order_seq_cst</code> operations in allowed directions - C++11 Standard:</li>\n</ul>\n<blockquote>\n<p id=\"so_39053600_42857017_3\">\u00a7 29.3  </p>\n<p id=\"so_39053600_42857017_4\">8 [ Note: <strong>memory_order_seq_cst ensures sequential consistency\n  only for a program that</strong> is free of data races and <strong>uses exclusively\n  memory_order_seq_cst operations. Any use of weaker ordering will\n  invalidate this guarantee</strong> unless extreme care is used. In particular,\n  memory_order_seq_cst fences ensure a total order only for the fences\n  themselves. Fences cannot, in general, be used to restore sequential\n  consistency for atomic operations with weaker ordering specifications.\n  \u2014 end note ]</p>\n</blockquote>\n<hr>\n<p>Also C++-compilers allows such reorderings:</p>\n<ol>\n<li><strong>On x86_64</strong></li>\n</ol>\n<p>Usually - if in compilers seq_cst implemented as barrier after store, then:</p>\n<p><code>STORE-C(relaxed);</code> <code>LOAD-B(seq_cst);</code> can be reordered to <code>LOAD-B(seq_cst);</code> <code>STORE-C(relaxed);</code></p>\n<p>Screenshot of Asm generated by GCC 7.0 x86_64: <a href=\"https://godbolt.org/g/4yyeby\" rel=\"nofollow noreferrer\">https://godbolt.org/g/4yyeby</a></p>\n<p>Also, theoretically possible - if in compilers seq_cst implemented as barrier before load, then:</p>\n<p><code>STORE-A(seq_cst);</code> <code>LOAD-C(acq_rel);</code> can be reordered to <code>LOAD-C(acq_rel);</code> <code>STORE-A(seq_cst);</code> </p>\n<ol start=\"2\">\n<li><strong>On PowerPC</strong></li>\n</ol>\n<p><code>STORE-A(seq_cst);</code> <code>LOAD-C(relaxed);</code> can be reordered to <code>LOAD-C(relaxed);</code> <code>STORE-A(seq_cst);</code></p>\n<p>Also on PowerPC can be such reordering:</p>\n<p><code>STORE-A(seq_cst);</code> <code>STORE-C(relaxed);</code> can reordered to <code>STORE-C(relaxed);</code> <code>STORE-A(seq_cst);</code></p>\n<p>If even atomic variables are allowed to be reordered across atomic(seq_cst), then non-atomic variables can also be reordered across atomic(seq_cst).</p>\n<p>Screenshot of Asm generated by GCC 4.8 PowerPC: <a href=\"https://godbolt.org/g/BTQBr8\" rel=\"nofollow noreferrer\">https://godbolt.org/g/BTQBr8</a></p>\n<hr>\n<p>More details:</p>\n<ol>\n<li><strong>On x86_64</strong></li>\n</ol>\n<p><code>STORE-C(release);</code> <code>LOAD-B(seq_cst);</code> can be reordered to <code>LOAD-B(seq_cst);</code> <code>STORE-C(release);</code></p>\n<p><a href=\"http://www.intel.com/Assets/en_US/PDF/manual/253668.pdf\" rel=\"nofollow noreferrer\">Intel\u00ae 64 and IA-32 Architectures</a></p>\n<blockquote>\n<p id=\"so_39053600_42857017_5\">8.2.3.4 Loads May Be Reordered with Earlier Stores to Different Locations</p>\n</blockquote>\n<p>I.e. x86_64 code:</p>\n<pre><code>STORE-A(seq_cst);\nSTORE-C(release); \nLOAD-B(seq_cst);\n</code></pre>\n<p>Can be reordered to:</p>\n<pre><code>STORE-A(seq_cst);\nLOAD-B(seq_cst);\nSTORE-C(release); \n</code></pre>\n<p>This can happen because between <code>c.store</code> and <code>b.load</code> isn't <code>mfence</code>:</p>\n<p><strong>x86_64 - GCC 7.0</strong>: <a href=\"https://godbolt.org/g/dRGTaO\" rel=\"nofollow noreferrer\">https://godbolt.org/g/dRGTaO</a></p>\n<p>C++ &amp; asm - code:</p>\n<pre><code>#include &lt;atomic&gt;\n\n// Atomic load-store\nvoid test() {\n    std::atomic&lt;int&gt; a, b, c;\n    a.store(2, std::memory_order_seq_cst);          // movl 2,[a]; mfence;\n    c.store(4, std::memory_order_release);          // movl 4,[c];\n    int tmp = b.load(std::memory_order_seq_cst);    // movl [b],[tmp];\n}\n</code></pre>\n<p>It can be reordered to:</p>\n<pre><code>#include &lt;atomic&gt;\n\n// Atomic load-store\nvoid test() {\n    std::atomic&lt;int&gt; a, b, c;\n    a.store(2, std::memory_order_seq_cst);          // movl 2,[a]; mfence;\n    int tmp = b.load(std::memory_order_seq_cst);    // movl [b],[tmp];\n    c.store(4, std::memory_order_release);          // movl 4,[c];\n}\n</code></pre>\n<hr>\n<p>Also, Sequential Consistency in x86/x86_64 can be implemented in four ways: <a href=\"http://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html\" rel=\"nofollow noreferrer\">http://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html</a></p>\n<blockquote id=\"so_39053600_42857017_6\">\n<ol>\n<li><code>LOAD</code> (without fence) and <code>STORE</code> + <code>MFENCE</code></li>\n<li><code>LOAD</code> (without fence) and <code>LOCK XCHG</code></li>\n<li><code>MFENCE</code> + <code>LOAD</code> and <code>STORE</code> (without fence)</li>\n<li><code>LOCK XADD</code> ( 0 ) and <code>STORE</code> (without fence)</li>\n</ol>\n</blockquote>\n<ul>\n<li>1 and 2 ways: <code>LOAD</code> and (<code>STORE</code>+<code>MFENCE</code>)/(<code>LOCK XCHG</code>) - we reviewed above</li>\n<li>3 and 4 ways: (<code>MFENCE</code>+<code>LOAD</code>)/<code>LOCK XADD</code> and <code>STORE</code> - allow next reordering:</li>\n</ul>\n<p><code>STORE-A(seq_cst);</code> <code>LOAD-C(acq_rel);</code> can be reordered to <code>LOAD-C(acq_rel);</code> <code>STORE-A(seq_cst);</code></p>\n<hr>\n<ol start=\"2\">\n<li><strong>On PowerPC</strong></li>\n</ol>\n<p><code>STORE-A(seq_cst);</code> <code>LOAD-C(relaxed);</code> can be reordered to <code>LOAD-C(relaxed);</code> <code>STORE-A(seq_cst);</code></p>\n<p>Allows Store-Load reordering (<strong>Table 5 - PowerPC</strong>): <a href=\"http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf\" rel=\"nofollow noreferrer\">http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf</a></p>\n<blockquote>\n<p id=\"so_39053600_42857017_7\">Stores Reordered After Loads</p>\n</blockquote>\n<p>I.e. PowerPC code:</p>\n<pre><code>STORE-A(seq_cst);\nSTORE-C(relaxed); \nLOAD-C(relaxed); \nLOAD-B(seq_cst);\n</code></pre>\n<p>Can be reordered to:</p>\n<pre><code>LOAD-C(relaxed);\nSTORE-A(seq_cst);\nSTORE-C(relaxed); \nLOAD-B(seq_cst);\n</code></pre>\n<p><strong>PowerPC - GCC 4.8</strong> : <a href=\"https://godbolt.org/g/xowFD3\" rel=\"nofollow noreferrer\">https://godbolt.org/g/xowFD3</a></p>\n<p>C++ &amp; asm - code:</p>\n<pre><code>#include &lt;atomic&gt;\n\n// Atomic load-store\nvoid test() {\n    std::atomic&lt;int&gt; a, b, c;       // addr: 20, 24, 28\n    a.store(2, std::memory_order_seq_cst);          // li r9&lt;-2; sync; stw r9-&gt;[a];\n    c.store(4, std::memory_order_relaxed);          // li r9&lt;-4; stw r9-&gt;[c];\n    c.load(std::memory_order_relaxed);              // lwz r9&lt;-[c];\n    int tmp = b.load(std::memory_order_seq_cst);    // sync; lwz r9&lt;-[b]; ... isync;\n}\n</code></pre>\n<p>By dividing <code>a.store</code> into two parts - it can be reordered to:</p>\n<pre><code>#include &lt;atomic&gt;\n\n// Atomic load-store\nvoid test() {\n    std::atomic&lt;int&gt; a, b, c;       // addr: 20, 24, 28\n    //a.store(2, std::memory_order_seq_cst);            // part-1: li r9&lt;-2; sync;\n    c.load(std::memory_order_relaxed);              // lwz r9&lt;-[c];\n    a.store(2, std::memory_order_seq_cst);          // part-2: stw r9-&gt;[a];\n    c.store(4, std::memory_order_relaxed);          // li r9&lt;-4; stw r9-&gt;[c];\n    int tmp = b.load(std::memory_order_seq_cst);    // sync; lwz r9&lt;-[b]; ... isync;\n}\n</code></pre>\n<p>Where load-from-memory <code>lwz r9&lt;-[c];</code> executed earlier than store-to-memory <code>stw r9-&gt;[a];</code>.</p>\n<hr>\n<p>Also on PowerPC can be such reordering:</p>\n<p><code>STORE-A(seq_cst);</code> <code>STORE-C(relaxed);</code> can reordered to <code>STORE-C(relaxed);</code> <code>STORE-A(seq_cst);</code></p>\n<p>Because PowerPC has weak memory ordering model - allows Store-Store reordering (<strong>Table 5 - PowerPC</strong>): <a href=\"http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf\" rel=\"nofollow noreferrer\">http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.06.07c.pdf</a></p>\n<blockquote>\n<p id=\"so_39053600_42857017_8\">Stores Reordered After Stores</p>\n</blockquote>\n<p>I.e. on PowerPC operations Store can be reordered with other Store, then previous example can be reordered such as:</p>\n<pre><code>#include &lt;atomic&gt;\n\n// Atomic load-store\nvoid test() {\n    std::atomic&lt;int&gt; a, b, c;       // addr: 20, 24, 28\n    //a.store(2, std::memory_order_seq_cst);            // part-1: li r9&lt;-2; sync;\n    c.load(std::memory_order_relaxed);              // lwz r9&lt;-[c];\n    c.store(4, std::memory_order_relaxed);          // li r9&lt;-4; stw r9-&gt;[c];\n    a.store(2, std::memory_order_seq_cst);          // part-2: stw r9-&gt;[a];\n    int tmp = b.load(std::memory_order_seq_cst);    // sync; lwz r9&lt;-[b]; ... isync;\n}\n</code></pre>\n<p>Where store-to-memory <code>stw r9-&gt;[c];</code> executed earlier than store-to-memory <code>stw r9-&gt;[a];</code>.</p>\n</hr></hr></hr></hr></hr>", "LastEditorUserId": "1558037", "LastActivityDate": "2017-07-30T22:40:40.977", "Score": "3", "CreationDate": "2017-03-17T12:00:00.170", "ParentId": "39053600", "CommentCount": "2", "LastEditDate": "2017-07-30T22:40:40.977", "OwnerUserId": "1558037"}, "39053893": {"Id": "39053893", "PostTypeId": "2", "Body": "<p>The <code>std::memory_order_seq_cst</code> guarantees there is no reordering by either compiler nor cpu. In this case the same memory order as if only one instruction where executed at a time.</p>\n<p>But the compiler optimization confuses the issues, if you turn off -O3 then the fence is <a href=\"https://godbolt.org/g/VYQ7F2\" rel=\"nofollow\">there</a>.</p>\n<p>The compiler can see that in your test program with -O3 that there are no consequence of the mfence as the program is too simple.</p>\n<p>If you ran it on an Arm on the other hand like <a href=\"https://gcc.godbolt.org/#compilers:!((compiler:armhfg482,options:'-std%3Dc%2B%2B11+-O3',source:'%23include+%3Catomic%3E%0A%0A//+Type+your+code+here,+or+load+an+example.%0Avoid+test()+%7B%0A++++std::atomic%3Cint%3E+a,+b%3B%0A++++b.store(1,+std::memory_order_release)%3B+//+can+be+executed+after+LOAD%0A++++a.load(std::memory_order_seq_cst)%3B+//+can+be+executed+before+STORE%0A%7D')),filterAsm:(commentOnly:!t,directives:!t,labels:!t),version:3\" rel=\"nofollow\">this</a> you can see the barriers <code>dmb ish</code>.</p>\n<p>So if your program is more complex you might see the <code>mfence</code> in this part of the code but not if the compiler can analyse and reason that it is not needed.</p>\n", "LastEditorUserId": "4013258", "LastActivityDate": "2016-08-21T09:33:53.237", "Score": "0", "CreationDate": "2016-08-20T12:00:16.297", "ParentId": "39053600", "CommentCount": "2", "LastEditDate": "2016-08-21T09:33:53.237", "OwnerUserId": "4013258"}});