post_cb({"6230278": {"ParentId": "6230180", "CommentCount": "1", "Body": "<p>Introsort has actually O(n log(n)) worst-case running time, not O(n^2).\nAlso see <a href=\"http://www.sgi.com/tech/stl/sort.html#2\" rel=\"nofollow\">this remark</a> at the SGI STL Specs:</p>\n<blockquote>\n<p id=\"so_6230180_6230278_0\">Earlier versions of sort used the\n  quicksort algorithm, using a pivot\n  chosen by median of three. Quicksort\n  has O(N log(N)) average complexity,\n  but quadratic worst-case complexity.\n  The current implementation of sort, however, uses the introsort\n  algorithm <em>whose\n  worst case complexity is O(N log(N))</em>.\n  Introsort is very similar to\n  median-of-three quicksort, and is at\n  least as fast as quicksort on average.</p>\n</blockquote>\n", "OwnerUserId": "530339", "PostTypeId": "2", "Id": "6230278", "Score": "2", "CreationDate": "2011-06-03T17:03:48.940", "LastActivityDate": "2011-06-03T17:03:48.940"}, "6230493": {"ParentId": "6230180", "PostTypeId": "2", "CommentCount": "2", "Body": "<p>If your standard library makes no guarantees beyond ISO 14882, then there seems to be no formal bound on the worst-case behavior of <code>sort()</code> \u2014 only the average complexity is listed.  There's a footnote in the standard which mentions you should use <code>stable_sort()</code> or <code>partial_sort()</code> instead of <code>sort()</code> if you care:</p>\n<p><a href=\"http://www.kuzbass.ru:8086/docs/isocpp/lib-algorithms.html#lib.alg.sorting\" rel=\"nofollow\">http://www.kuzbass.ru:8086/docs/isocpp/lib-algorithms.html#lib.alg.sorting</a></p>\n<blockquote>\n<p id=\"so_6230180_6230493_0\">25.3.1.1 - sort [lib.sort]</p>\n<pre><code>template&lt;class RandomAccessIterator&gt;\nvoid sort(RandomAccessIterator first, RandomAccessIterator last)\n\ntemplate&lt;class RandomAccessIterator, class Compare&gt;\nvoid sort(RandomAccessIterator first, RandomAccessIterator last, Compare comp)\n</code></pre>\n<ol>\n<li><p id=\"so_6230180_6230493_1\">Effects: Sorts the elements in the range [first, last).</p></li></ol></blockquote>\n<li><p>Complexity: Approximately N log N (where N == last - first) comparisons on the average.*</p></li>\n<p>[Footnote: If the worst case behavior is important stable_sort() (lib.stable.sort) or partial_sort() (lib.partial.sort) should be used. --- end footnote]</p>\n<p>Specific library implementations probably make stronger guarantees beyond the standard.  And it can certainly be useful to look at the code directly.  Then again, it depends on how portable you want this to be.</p>\n", "OwnerUserId": "211160", "LastEditorUserId": "319403", "LastEditDate": "2011-06-03T19:33:28.617", "Id": "6230493", "Score": "3", "CreationDate": "2011-06-03T17:24:24.417", "LastActivityDate": "2011-06-03T19:33:28.617"}, "6230257": {"ParentId": "6230180", "PostTypeId": "2", "CommentCount": "4", "Body": "<p>The use of quicksort and introsort (which is a variant of the former, with guaranteed <code>O(n log n)</code> performance achieved by switching to heapsort on worst case inputs) in place of other theoretically better algorithms like mergesort is due to the fact that the average case is the same, and the constants much lower (in the constants you can include the fact that it can be sorted in place, so there are no reallocations, and copies). And the worst case is bad, but quite improvable. In general, it is assumed that the performance of <code>sort</code> is <code>O( n log n )</code>. </p>\n<p>If you are concerned about the hidden constants, then the question is not theoretical, but rather a question of performance. When trying to optimize you are better off <em>measuring</em> the algorithm on your actual data, analyzing the results of the measurement, and then determining where the time is spent and if it can be improved. But that is a completely different problem from the theoretical one.</p>\n", "OwnerUserId": "36565", "LastEditorUserId": "36565", "LastEditDate": "2011-06-03T17:10:19.763", "Id": "6230257", "Score": "5", "CreationDate": "2011-06-03T17:01:44.567", "LastActivityDate": "2011-06-03T17:10:19.763"}, "6230241": {"ParentId": "6230180", "CommentCount": "2", "Body": "<p><a href=\"http://en.wikipedia.org/wiki/Sorting_algorithm\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Sorting_algorithm</a> lists several sorting algorithms with n^2 performance. It has one with n! performance. It also lists several non-comparison sorts which have performance based on other factors.</p>\n", "OwnerUserId": "749284", "PostTypeId": "2", "Id": "6230241", "Score": "0", "CreationDate": "2011-06-03T17:00:49.753", "LastActivityDate": "2011-06-03T17:00:49.753"}, "6230276": {"ParentId": "6230180", "CommentCount": "3", "Body": "<p>Yes it is a variation of quicksort, using heapsort for suspected pathological quicksort input. It looks at recursion depth and when it falls too deep it sorts using heapsort removing any pathological behavior. This guarantees N log N.  The constant overhead of N log N (qsort vs heapsort) is not something to worry about. </p>\n<p>Insertion sort is used when there are very few elements (about 16). </p>\n", "OwnerUserId": "451600", "PostTypeId": "2", "Id": "6230276", "Score": "1", "CreationDate": "2011-06-03T17:03:36.060", "LastActivityDate": "2011-06-03T17:03:36.060"}, "bq_ids": {"n4140": {"so_6230180_6230493_1": {"section_id": 1286, "quality": 0.6666666666666666, "length": 4}}, "n3337": {"so_6230180_6230493_1": {"section_id": 1281, "quality": 0.6666666666666666, "length": 4}}, "n4659": {"so_6230180_6230493_1": {"section_id": 1409, "quality": 0.6666666666666666, "length": 4}}}, "6230180": {"CommentCount": "8", "AcceptedAnswerId": "6230257", "PostTypeId": "1", "LastEditorUserId": "688653", "CreationDate": "2011-06-03T16:54:42.470", "LastActivityDate": "2011-06-03T19:33:28.617", "LastEditDate": "2011-06-03T17:03:47.943", "ViewCount": "1042", "FavoriteCount": "0", "Title": "Can sort() in C++ have a n^2 performance?", "Id": "6230180", "Score": "4", "Body": "<p>When trying to estimated the performance of a program, I always treated sort() function as a worst-performance-n^2 function. However, I came across a Wikipedia page:</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Sort_%28C++%29\" rel=\"nofollow\">sort(C++)</a></p>\n<p>Which states that the GNU C Library sort() uses some hybrid sorting algorithm called Introsort first, then do insertion sort. The corresponding page to Introsort claims that this algorithm has a worst case performance of nlogn. However, since I am not familiar with this algorithm, I still have the following worries about sort():</p>\n<p>1) Can the hybrid algorithm used by GNU sort() guarantee a O(nlogn) performance? If so, how big can the constant overhead of the nlogn be?</p>\n<p>2) Are there any other implementations that could cause sort() to perform worse than this (or better, which would be great)?</p>\n<p>EDIT: Reply to Kevin: The sort() mentioned is std::sort().</p>\n<p>Thanks!</p>\n", "Tags": "<c++><algorithm><sorting><gnu>", "OwnerUserId": "688653", "AnswerCount": "5"}});