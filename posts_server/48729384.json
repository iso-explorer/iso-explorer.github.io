post_cb({"48736011": {"Id": "48736011", "PostTypeId": "2", "Body": "<p>On most modern 64-bit architecture, <code>int</code> is 4 bytes and <code>ptrdiff_t</code> is 8 bytes.  If your program uses a lot of integers, using <code>ptrdiff_t</code> instead of <code>int</code> could <em>double</em> your program's memory requirement.</p>\n<p>Also consider that modern CPUs are frequently bottlenecked by memory performance.  Using 8-byte integers also means your CPU cache now has half as many elements as before, so now it must wait for the slow main memory more often (which can easily take several hundred cycles).</p>\n<p>In many cases, the cost of executing \"32-to-64-bit conversion\" operations is completely dwarfed by memory performance.</p>\n<p>So this is a practical reason <code>int</code> is still popular on 64-bit machines.</p>\n<ul>\n<li>Now you may argue about two dozen different integer types and portability and standard committees and everything, but the truth is that for a lot of C++ programs written out there, there's a \"canonical\" architecture they're thinking of, which is frequently the only architecture they're ever concerned about.  (If you're writing a 3D graphics routine for a Windows game, you're sure it won't run on an IBM mainframe.)  So for them, the question boils down to: \"Do I need a 4-byte integer or an 8-byte one here?\"</li>\n</ul>\n", "LastEditorUserId": "2876838", "LastActivityDate": "2018-02-11T20:23:32.427", "Score": "11", "CreationDate": "2018-02-11T20:18:24.007", "ParentId": "48729384", "CommentCount": "7", "OwnerUserId": "2876838", "LastEditDate": "2018-02-11T20:23:32.427"}, "48730529": {"Id": "48730529", "PostTypeId": "2", "Body": "<p>Most programs do not live and die on the edge of a few CPU cycles, and <code>int</code> is very easy to write. However, if you are performance-sensitive, I suggest using the fixed-width integer types defined in <code>&lt;cstdint&gt;</code>, such as <code>int32_t</code> or <code>uint64_t</code>.\nThese have the benefit of being very clear in their intended behavior in regards to being signed or unsigned, as well as their size in memory. This header also includes the fast variants such as <code>int_fast32_t</code>, which are <em>at least</em> the stated size, but might be more, if it helps performance.</p>\n", "LastEditorUserId": "265140", "LastActivityDate": "2018-02-12T10:12:34.310", "Score": "16", "CreationDate": "2018-02-11T10:28:16.393", "ParentId": "48729384", "CommentCount": "8", "OwnerUserId": "6730520", "LastEditDate": "2018-02-12T10:12:34.310"}, "48735509": {"Id": "48735509", "PostTypeId": "2", "Body": "<h3>Pro</h3>\n<p>Easier to type, I guess?  But you can always <code>typedef</code>.</p>\n<p>Many APIs use int, including parts of the standard library.  This has historically caused problems, for example during the transition to 64-bit file sizes.</p>\n<p>Because of the default type promotion rules, types narrower than int could be widened to int or unsigned int unless you add explicit casts in a lot of places, and a lot of different types could be narrower than int on some implementation somewhere. So, if you care about portability, it\u2019s a minor headache.</p>\n<h3>Con</h3>\n<p>I also use <code>ptrdiff_t</code> for indices, most of the time.  (I agree with Google that unsigned indices are a bug attractor.)  For other kinds of math, there\u2019s <code>int_fast64_t</code>. <code>int_fast32_t</code>, and so on, which will also be as good as or better than <code>int</code>. Almost no real-world systems, with the exception of a few defunct Unices from last century, use ILP64, but there are plenty of CPUs where you would want 64-bit math.  And a compiler is technically allowed, by standard, to break your program if your <code>int</code> is greater than 32,767.</p>\n<p>That said, any C compiler worth its salt will be tested on a lot of code that adds an <code>int</code> to a pointer within an inner loop.  So it can\u2019t do anything too dumb.  Worst-case scenario <em>on present-day hardware</em> is that it needs an extra instruction to sign-extend a 32-bit signed value to 64 bits.  But, if what you really want is the fastest pointer math, the fastest math for values with magnitude between 32 kibi and 2 gibi, or  the least wasted memoey, you should say what you mean, not make the compiler guess.</p>\n", "LastEditorUserId": "4474419", "LastActivityDate": "2018-02-11T21:07:25.327", "Score": "2", "CreationDate": "2018-02-11T19:25:37.373", "ParentId": "48729384", "CommentCount": "4", "OwnerUserId": "4474419", "LastEditDate": "2018-02-11T21:07:25.327"}, "48734531": {"Id": "48734531", "PostTypeId": "2", "Body": "<p>I come at this from the perspective of an old timer (pre C++)... It was understood back in the day that <code>int</code> was the native word of the platform and was likely to give the best performance.</p>\n<p>If you needed something bigger, then you'd use it and pay the price in performance. If you needed something smaller (limited memory, or specific need for a fixed size), same thing.. otherwise use <code>int</code>. And yeah, if your value was in the range where int on one target platform could accommodate it and int on another target platform could not.. then we had our compile time size specific defines (prior to them becoming standardized we made our own).</p>\n<p>But now, present day, processors and compilers are much more sophisticated and these rules don't apply so easily. It is also harder to predict what the performance impact of your choice will be on some unknown future platform or compiler ...  How do we really know that uint64_t for example will perform better or worse than uint32_t on any particular future target? Unless you're a processor/compiler guru, you don't...</p>\n<p>So... maybe it's old fashioned, but unless I am writing code for a constrained environment like Arduino, etc. I still use <code>int</code> for general purpose values that I know will be within <code>int</code> size on all reasonable targets for the application I am writing.  And the compiler takes it from there...  These days that generally means 32 bits signed.  Even if one assumes that 16 bits is the minimum integer size, it covers most use cases.. and the use cases for numbers larger than that are easily identified and handled with appropriate types.</p>\n", "LastEditorUserId": "2945815", "LastActivityDate": "2018-02-12T18:22:44.043", "Score": "36", "CreationDate": "2018-02-11T17:49:47.220", "ParentId": "48729384", "CommentCount": "8", "OwnerUserId": "2945815", "LastEditDate": "2018-02-12T18:22:44.043"}, "48729384": {"ViewCount": "16950", "Body": "<p>Many style guides such as the Google one recommend using <code>int</code> as a default integer when indexing arrays for instance. With the rise of 64-bit platforms where most of the time an <code>int</code> is only 32 bits which is not the natural width of the platform. As a consequence, I see no reason, apart from the simple same, to keep that choice. We clearly see that where compiling the following code:</p>\n<pre><code>double get(const double* p, int k) {\n  return p[k];\n}\n</code></pre>\n<p>which gets compiled into</p>\n<pre><code>movslq %esi, %rsi\nvmovsd (%rdi,%rsi,8), %xmm0\nret\n</code></pre>\n<p>where the first instruction promotes the 32 bits integer into a 64 bits integer. If the code is transformed into</p>\n<pre><code>double get(const double* p, std::ptrdiff_t k) {\n  return p[k];\n}\n</code></pre>\n<p>the generated assembly is now</p>\n<pre><code>vmovsd (%rdi,%rsi,8), %xmm0\nret\n</code></pre>\n<p>which clearly shows that the CPU feels more at home with <code>std::ptrdiff_t</code> than with an <code>int</code>. Many C++ users have moved to <code>std::size_t</code> but I don't want to use unsigned integers unless I really need modulo <code>2^n</code> behaviour.</p>\n<p>In most cases, using <code>int</code> does not hurt performance as the undefined behaviour or signed integer overflows allow the compiler to internally promote any <code>int</code> to a <code>std::ptrdiff_t</code> in loops that deal with indices, but we clearly see from above that the compiler does not feel at home with <code>int</code>. Also, using <code>std::ptrdiff_t</code> on a 64-bit platform would make overflows less likely to happen as I see more and more people getting trapped by <code>int</code> overflows when they have to deal with integers larger than <code>2^31 - 1</code> which become really common these days.</p>\n<p>From what I have seen, the only thing that makes <code>int</code> stand apart seems to be the fact that literals such as <code>5</code> are <code>int</code>, but I don't see where it might cause any problem if we move to <code>std::ptrdiff_t</code> as a default integer.</p>\n<p>My question is the following. I am on the verge of making <code>std::ptrdiff_t</code> as the defacto standard integer for all the code written in my small company. Is there any reason why it could be a bad choice?</p>\n<p>PS: <em>I agree with the fact that the name <code>std::ptrdiff_t</code> is ugly which is the reason why I have typedef'ed it to <code>il::int_t</code> which look a bit better.</em> </p>\n<p>PS: <em>As I know that many people will recommend me to use <code>std::size_t</code> as a default integer, I really want to make it clear that I don't want to use an unsigned integer as my default integer. The use of <code>std::size_t</code> as a default integer in the STL has been a mistake as acknowledged by Bjarne Stroustrup and the standard committee in this video <a href=\"https://www.youtube.com/watch?v=Puio5dly9N8\" rel=\"noreferrer\">https://www.youtube.com/watch?v=Puio5dly9N8</a> at time 42:38 and 1:02:50.</em></p>\n<p>PS: <em>In terms of performance, on any 64-bit platform that I know of, <code>+</code>, <code>-</code> and <code>*</code> gets compiled the same way for both <code>int</code> and <code>std::ptrdiff_t</code>. So there is no difference in speed. If you divide by a compile-time constant, the speed is the same. It's only when you divide <code>a/b</code> when you know nothing about <code>b</code> that using 32 bits integer on a 64-bit platform gives you a slight advantage in performance. But this case is so rare as I don't see as a choice from moving away from <code>std::ptrdiff_t</code>. When we deal with vectorized code, here there is a clear difference, and the smaller, the better, but that's a different story, and there would be no reason to stick with <code>int</code>. In those cases, I would recommend going to the fixed size types of C++.</em></p>\n", "Title": "Is there still a reason to use `int` in C++ code?", "CreationDate": "2018-02-11T07:38:36.153", "LastActivityDate": "2018-02-18T12:26:48.780", "CommentCount": "56", "FavoriteCount": "54", "PostTypeId": "1", "LastEditDate": "2018-02-18T12:26:48.780", "LastEditorUserId": "956198", "Id": "48729384", "ClosedDate": "2018-02-13T17:51:51.937", "Score": "179", "OwnerUserId": "3763545", "Tags": "<c++>", "AnswerCount": "10"}, "bq_ids": {"n4140": {"so_48729384_48750155_0": {"length": 19, "quality": 0.5588235294117647, "section_id": 6142}}, "n3337": {"so_48729384_48750155_0": {"length": 19, "quality": 0.5588235294117647, "section_id": 5906}}}, "48733004": {"Id": "48733004", "PostTypeId": "2", "Body": "<p>I don't think that there's <strong>real</strong> reason for using <code>int</code>.</p>\n<p>How to choose the integer type?</p>\n<ul>\n<li>If it is for bit operations, you can use an unsigned type, otherwise use a signed one</li>\n<li>If it is for memory-related thing (index, container size, etc.), for which you don't know the upper bound, use <code>std::ptrdiff_t</code> (the only problem is when size is larger than <code>PTRDIFF_MAX</code>, which is rare in practice)</li>\n<li>Otherwise use <code>intXX_t</code> or <code>int(_least)/(_fast)XX_t</code>.</li>\n</ul>\n<p>These rules cover all the possible usages for <code>int</code>, and they give a better solution:</p>\n<ul>\n<li><code>int</code> is not good for storing memory related things, as its range can be smaller than an index can be (this is not a theoretical thing: for 64-bit machines, <code>int</code> is usually 32-bit, so with <code>int</code>, you can only handle 2 billion elements)</li>\n<li><code>int</code> is not good for storing \"general\" integers, as its range may be smaller than needed (undefined behavior happens if range is not enough), or on the contrary, its range may be much larger than needed (so memory is wasted)</li>\n</ul>\n<p>The only reason one could use an <code>int</code>, if one does a calculation, and knows that the range fit into [-32767;32767] (the standard only guarantees this range. Note however, that implementations are free to provide bigger sized <code>int</code>s, and they usually do so. Currently <code>int</code> is 32-bit on a lot of platforms).</p>\n<p>As the mentioned <code>std</code> types are a little bit tedious to write, one could <code>typedef</code> them to be shorter (I use <code>s8</code>/<code>u8</code>/.../<code>s64</code>/<code>u64</code>, and <code>spt</code>/<code>upt</code> (\"(un)signed pointer sized type\") for <code>ptrdiff_t</code>/<code>size_t</code>. I've been using these typedefs for 15 years, and I've never written a single <code>int</code> since...).</p>\n", "LastEditorUserId": "8157187", "LastActivityDate": "2018-02-11T21:03:49.133", "Score": "4", "CreationDate": "2018-02-11T15:18:20.283", "ParentId": "48729384", "CommentCount": "11", "OwnerUserId": "8157187", "LastEditDate": "2018-02-11T21:03:49.133"}, "48770670": {"Id": "48770670", "PostTypeId": "2", "Body": "<p>I guess 99% of cases there is no reason to use <code>int</code>(or signed integer of other sizes). However, there are still situations, when using <code>int</code> is a good option.</p>\n<hr>\n<p>A) Performance:</p>\n<p>One difference between <code>int</code> and <code>size_t</code> is that <code>i++</code> can be undefined behavior for <code>int</code> - if <code>i</code> is <code>MAX_INT</code>. This actually might be a good thing because compiler could use this undefined behavior to speed things up.</p>\n<p>For example in this <a href=\"https://stackoverflow.com/q/46496295/5769463\">question</a> the difference was about factor 2 between exploiting the undefined behavior and using compiler flag <a href=\"https://gcc.gnu.org/onlinedocs/gcc/Code-Gen-Options.html\" rel=\"nofollow noreferrer\"><code>-fwrapv</code></a> which prohibits this exploit.</p>\n<p>If my working-horse-for-loop becomes twice as fast by using <code>int</code>s - sure I will use it</p>\n<hr>\n<p>B) Less error prone code</p>\n<p>Reversed for-loops with <code>size_t</code> look strange and is a source for errors (I hope I got it right):</p>\n<pre><code>for(size_t i = N-1; i &lt; N; i--){...}\n</code></pre>\n<p>By using</p>\n<pre><code>for(int i = N-1; i &gt;= 0; i--){...}\n</code></pre>\n<p>you will deserve the gratitude of less experienced C++-programmers, who will have to manage your code some day.</p>\n<hr>\n<p>C) Design using signed indices </p>\n<p>By using <code>int</code> as indices you one could signal wrong values/out of range with negative values, something that comes handy and can lead to a clearer code.</p>\n<ol>\n<li><p>\"find index of an element in array\" could return <code>-1</code> if element is not present. For detecting this \"error\"  you don't have to know the size of the array.</p></li>\n<li><p>binary search could return positive index if element is in the array, and <code>-index</code> for the position where the element would be inserted into array (and is not in the array).</p></li>\n</ol>\n<p>Clearly, the same information could be encoded with positive index-values, but the code becomes somewhat less intuitive.</p>\n<hr>\n<p>Clearly, there are also reasons to choose <code>int</code> over <code>std::ptrdiff_t</code> - one of them is memory bandwidth. There are a lot of memory-bound algorithms, for them it is important to reduce the amount of memory transfered from RAM to cache.</p>\n<p>If you know, that all numbers are less then <code>2^31</code> that would be an advantage to use <code>int</code> because otherwise a half of memory transfer would be writing only <code>0</code> of which you already know, that they are there.</p>\n<p>An example are compressed sparse row (crs) matrices - their indices are stored as <code>ints</code> and not <code>long long</code>. Because many operations with sparse matrices are memory bound, there is really a different between using 32 or 64 bits.</p>\n</hr></hr></hr></hr>", "LastEditorUserId": "5769463", "LastActivityDate": "2018-02-17T19:15:57.000", "Score": "2", "CreationDate": "2018-02-13T15:53:13.117", "ParentId": "48729384", "CommentCount": "3", "OwnerUserId": "5769463", "LastEditDate": "2018-02-17T19:15:57.000"}, "48734054": {"Id": "48734054", "PostTypeId": "2", "Body": "<p>My advice to you is not to look at assembly language output too much, not to worry too much about exactly what size each variable is, and not to say things like \"the compiler feels at home with\".  (I truly don't know what you mean by that last one.)</p>\n<p>For garden-variety integers, the ones that most programs are full of, plain <code>int</code> is supposed to be a good type to use.  It's supposed to be the natural word size of the machine.  It's supposed to be efficient to use, neither wasting unnecessary memory nor inducing lots of extra conversions when moving between memory and computation registers.</p>\n<p>Now, it's true that there are plenty of more specialized uses for which plain <code>int</code> is no longer appropriate.  In particular, sizes of objects, counts of elements, and indices into arrays are almost always <code>size_t</code>.  But that doesn't mean all integers should be <code>size_t</code>!</p>\n<p>It's also true that mixtures of signed and unsigned types, and mixtures of different-size types, can cause problems. But most of those are well taken care of by modern compilers and the warnings they emit for unsafe combinations.  So as long as you're using a modern compiler and paying attention to its warnings, you don't need to pick an unnatural type just to try to avoid type mismatch problems.</p>\n", "LastEditorUserId": "3923896", "LastActivityDate": "2018-02-11T19:28:15.187", "Score": "5", "CreationDate": "2018-02-11T17:03:30.710", "ParentId": "48729384", "CommentCount": "3", "OwnerUserId": "3923896", "LastEditDate": "2018-02-11T19:28:15.187"}, "48730787": {"Id": "48730787", "PostTypeId": "2", "Body": "<p>No formal reason to use <code>int</code>. It doesn't correspond to anything sane as per standard. For indices you almost always want signed pointer-sized integer.</p>\n<p>That said, typing <code>int</code> feels like you just said hey to Ritchie and typing <code>std::ptrdiff_t</code> feels like Stroustrup just kicked you in the butt. Coders are people too, don't bring too much ugliness into their life. I would prefer to use <s><code>long</code> or</s> some easily typed typedef like <code>index</code> instead of <code>std::ptrdiff_t</code>.</p>\n", "LastEditorUserId": "9009404", "LastActivityDate": "2018-02-12T22:08:43.520", "Score": "14", "CreationDate": "2018-02-11T11:01:36.397", "ParentId": "48729384", "CommentCount": "9", "OwnerUserId": "9009404", "LastEditDate": "2018-02-12T22:08:43.520"}, "48730597": {"Id": "48730597", "PostTypeId": "2", "Body": "<p>There was a discussion on the C++ Core Guidelines what to use:</p>\n<p><a href=\"https://github.com/isocpp/CppCoreGuidelines/pull/1115\" rel=\"noreferrer\">https://github.com/isocpp/CppCoreGuidelines/pull/1115</a></p>\n<p>Herb Sutter wrote that <code>gsl::index</code> will be added (in the future maybe <code>std::index</code>), which will be defined as <code>ptrdiff_t</code>.</p>\n<blockquote>\n<p id=\"so_48729384_48730597_0\">hsutter commented on 26 Dec 2017 \u2022</p>\n<p id=\"so_48729384_48730597_1\">(Thanks to many WG21 experts for their comments and feedback into this\n  note.)</p>\n<p id=\"so_48729384_48730597_2\">Add the following typedef to GSL</p>\n<p id=\"so_48729384_48730597_3\"><code>namespace gsl { using index = ptrdiff_t; }</code></p>\n<p id=\"so_48729384_48730597_4\">and recommend <code>gsl::index</code> for all container indexes/subscripts/sizes.</p>\n<p id=\"so_48729384_48730597_5\"><strong>Rationale</strong></p>\n<p id=\"so_48729384_48730597_6\">The Guidelines recommend using a signed type for subscripts/indices.\n  See ES.100 through ES.107. C++ already uses signed integers for array\n  subscripts.</p>\n<p id=\"so_48729384_48730597_7\">We want to be able to teach people to write \"new clean modern code\"\n  that is simple, natural, warning-free at high warning levels, and\n  doesn\u2019t make us write a \"pitfall\" footnote about simple code.</p>\n<p id=\"so_48729384_48730597_8\">If we don\u2019t have a short adoptable word like <code>index</code> that is competitive\n  with <code>int</code> and <code>auto</code>, people will still use <code>int</code> and <code>auto</code> and get their\n  bugs. For example, they will write <code>for(int i=0; i&lt;v.size(); ++i)</code> or\n  <code>for(auto i=0; i&lt;v.size(); ++i)</code> which have 32-bit size bugs on widely\n  used platforms, and <code>for(auto i=v.size()-1; i&gt;=0; ++i)</code> which just\n  doesn't work. I don\u2019t think we can teach <code>for(ptrdiff_t i = ...</code> with a\n  straight face, or that people would accept it.</p>\n<p id=\"so_48729384_48730597_9\">If we had a saturating arithmetic type, we might use that. Otherwise,\n  the best option is <code>ptrdiff_t</code> which has nearly all the advantages of a\n  saturating arithmetic unsigned type, except only that <code>ptrdiff_t</code> still\n  makes the pervasive loop style <code>for(ptrdiff_t i=0; i&lt;v.size(); ++i)</code>\n  emit signed/unsigned mismatches on <code>i&lt;v.size()</code> (and similarly for\n  <code>i!=v.size()</code>) for today's STL containers. (If a future STL changes its\n  size_type to be signed, even this last drawback goes away.)</p>\n<p id=\"so_48729384_48730597_10\">However, it would be hopeless (and embarrassing) to try to teach\n  people to routinely write <code>for (ptrdiff_t i = ... ; ... ; ...)</code>. (Even\n  the Guidelines currently use it in only one place, and that's a \"bad\"\n  example that is unrelated to indexing`.)</p>\n<p id=\"so_48729384_48730597_11\">Therefore we should provide <code>gsl::index</code> (which can later be proposed\n  for consideration as <code>std::index</code>) as a typedef for <code>ptrdiff_t</code>, so we can\n  hopefully (and not embarrassingly) teach people to routinely write for\n  <code>(index i = ... ; ... ; ...)</code>.</p>\n<p id=\"so_48729384_48730597_12\"><strong>Why not just tell people to write <code>ptrdiff_t</code>?</strong> Because we believe it\n  would be embarrassing to tell people that's what you have to do in\n  C++, and even if we did people won't do it. Writing <code>ptrdiff_t</code> is too\n  ugly and unadoptable compared to <code>auto</code> and <code>int</code>. The point of adding the\n  name <code>index</code> is to make it as easy and attractive as possible to use a\n  correctly sized signed type.</p>\n</blockquote>\n<p>Edit: More rationale from Herb Sutter</p>\n<blockquote>\n<p id=\"so_48729384_48730597_13\"><strong>Is <code>ptrdiff_t</code> big enough?</strong> Yes. Standard containers are already required\n  to have no more elements than can be represented by <code>ptrdiff_t</code>, because\n  subtracting two iterators must fit in a difference_type.</p>\n<p id=\"so_48729384_48730597_14\"><strong>But is <code>ptrdiff_t</code> really big enough, if I have a built-in array of <code>char</code>\n  or <code>byte</code> that is bigger than half the size of the memory address space\n  and so has more elements than can be represented in a <code>ptrdiff_t</code>?</strong> Yes.\n  C++ already uses signed integers for array subscripts. So use <code>index</code> as\n  the default option for the vast majority of uses including all\n  built-in arrays. (If you do encounter the extremely rare case of an\n  array, or array-like type, that is bigger than half the address space\n  and whose elements are <code>sizeof(1)</code>, and you're careful about avoiding\n  truncation issues, go ahead and use a <code>size_t</code> for indexes into that\n  very special container only. Such beasts are very rare in practice,\n  and when they do arise often won't be indexed directly by user code.\n  For example, they typically arise in a memory manager that takes over\n  system allocation and parcels out individual smaller allocations that\n  its users use, or in an MPEG or similar which provides its own\n  interface; in both cases the <code>size_t</code> should only be needed internally\n  within the memory manager or the MPEG class implementation.)</p>\n</blockquote>\n", "LastEditorUserId": "2504757", "LastActivityDate": "2018-02-17T21:19:45.203", "Score": "105", "CreationDate": "2018-02-11T10:37:34.807", "ParentId": "48729384", "CommentCount": "14", "OwnerUserId": "2504757", "LastEditDate": "2018-02-17T21:19:45.203"}, "48750155": {"PostTypeId": "2", "Body": "<p>This is somewhat opinion-based, but alas, the question somewhat begs for it, too.</p>\n<p>First of all, you talk about integers and indices as if they were the same thing, which is not the case. For any such thing as <em>\"integer of sorts, not sure what size\"</em>, simply using <code>int</code> is of course, most of the time, still appropriate. This works fine most of the time, for most applications, and the compiler is comfortable with it. As a default, that's fine.</p>\n<p>For array indices, it's a different story.</p>\n<p>There is to date one single formally correct thing, and that's <code>std::size_t</code>. In the future, there may be a <code>std::index_t</code> which makes the intent clearer on the source level, but so far there is not.<br>\n<code>std::ptrdiff_t</code> as an index \"works\" but is just as incorrect as <code>int</code> since it allows for negative indices.<br>\nYes, this happens what Mr. Sutter deems correct, but I beg to differ. Yes, on an assembly language instruction level, this is supported just fine, but I still object. The standard says:</br></br></p>\n<blockquote>\n<p id=\"so_48729384_48750155_0\">8.3.4/6: <code>E1[E2]</code> is identical to <code>*((E1)+(E2))</code> [...] Because of the conversion rules that apply to <code>+</code>, if <code>E1</code> is an array and <code>E2</code> an integer, then <code>E1[E2]</code> refers to the <code>E2</code>-th member of <code>E1</code>.<br>\n  5.7/5: [...] If both the pointer operand and the result point to elements of the same array object, or one past the last element of the array object [...] otherwise, <strong>the behavior is undefined</strong>.</br></p>\n</blockquote>\n<p>An array subscription refers to the <em><code>E2</code>-th member of <code>E1</code></em>. There is no such thing as a negative-th element of an array. But more importantly, the pointer arithmetic with a negative additive expression <em>invokes undefined behavior</em>.</p>\n<p>In other words: signed indices of whatever size are <em>a wrong choice</em>. Indices are unsigned. Yes, signed indices <em>work</em>, but they're still wrong.</p>\n<p>Now, although <code>size_t</code> is by definition the correct choice (an unsigned integer type that is large enough to contain the size of any object), it may be debatable whether it is <em>truly</em> good choice for the average case, or as a default.</p>\n<p>Be honest, when was the last time you created an array with 10<sup>19</sup> elements?</p>\n<p>I am personally using <code>unsigned int</code> as a default because the 4 billion elements that this allows for is way enough for (almost) every application, and it already pushes the average user's computer rather close to its limit (if merely subscribing an array of integers, that assumes 16GB of contiguous memory allocated). I personally deem defaulting to 64-bit indices as ridiculous.  </p>\n<p>If you are programming a relational database or a filesystem, then yes, you will <em>need</em> 64-bit indices. But for the average \"normal\" program, 32-bit indices are just good enough, and they only consume half as much storage.</p>\n<p>When keeping around considerably more than a handful of indices, and if I can afford (because arrays are not larger than 64k elements), I even go down to <code>uint16_t</code>. No, I'm not joking there.</p>\n<p>Is storage really such a problem? It's ridiculous to greed about two or four bytes saved, isn't it! Well, no...  </p>\n<p>Size can be a problem for pointers, so sure enough it can be for indices as well. The x32 ABI does not exist for no reason. You will not notice the overhead of needlessly large indices if you have only a handful of them in total (just like pointers, they will be in registers anyway, nobody will notice whether they're 4 or 8 bytes in size).</p>\n<p>But think for example of a slot map where you store an index for every element (depending on the implementation, <em>two</em> indices per element). Oh heck, it sure does make a bummer of a difference whether you hit L2 every time, or whether you have a cache miss on every access! Bigger is not always better.</p>\n<p>At the end of the day, you must ask yourself what you pay for, and what you get in return. With that in mind, my style recommendation would be:</p>\n<p>If it costs you \"nothing\" because you only have e.g. one pointer and a few indices to keep around, then just use what's formally correct (that'd be <code>size_t</code>). Formally correct is good, correct always works, it's readable and intellegible, and correct is... <em>never wrong</em>.</p>\n<p>If, however, it <em>does cost</em> you (you have maybe several hundred or thousand or ten thousand indices), and what you get back is worth nothing (because e.g. you cannot even store 2<sup>20</sup> elements, so whether you <em>could</em> subscribe 2<sup>32</sup> or 2<sup>64</sup> makes no difference), you should think twice about being too wasteful.</p>\n", "LastActivityDate": "2018-02-12T15:41:54.453", "Id": "48750155", "CommentCount": "1", "CreationDate": "2018-02-12T15:41:54.453", "ParentId": "48729384", "Score": "13", "OwnerUserId": "572743"}});