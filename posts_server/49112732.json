post_cb({"bq_ids": {"n4140": {"so_49112732_49115450_4": {"length": 21, "quality": 1.0, "section_id": 1149}, "so_49112732_49115450_1": {"length": 5, "quality": 0.7142857142857143, "section_id": 5824}, "so_49112732_49115450_0": {"length": 4, "quality": 0.8, "section_id": 5824}}, "n3337": {"so_49112732_49115450_4": {"length": 21, "quality": 1.0, "section_id": 1146}, "so_49112732_49115450_1": {"length": 5, "quality": 0.7142857142857143, "section_id": 5595}, "so_49112732_49115450_0": {"length": 4, "quality": 0.8, "section_id": 5595}}, "n4659": {"so_49112732_49115450_4": {"length": 21, "quality": 1.0, "section_id": 1243}, "so_49112732_49115450_1": {"length": 5, "quality": 0.7142857142857143, "section_id": 7285}, "so_49112732_49115450_0": {"length": 4, "quality": 0.8, "section_id": 7285}}}, "49112732": {"ViewCount": "192", "Body": "<p>I'm trying to figure out the most relaxed (and correct) memory order for shared pointer destructor. What I have in mind for now is as follows:</p>\n<pre><code>~shared_ptr() {\n   if (p) {\n     if (p-&gt;cnt.fetch_sub(1, std::memory_order_release) == 1) {\n       p-&gt;cnt.load(std::memory_order_acquire);\n       delete p;\n     }\n   }\n }\n</code></pre>\n<p>Basically, I'm thinking that all previous <code>fetch_sub()</code> should happen-before <code>delete p;</code>, and by <code>p-&gt;cnt.load(std::memory_order_acquire);</code>, I construct a release sequence that ensures this.</p>\n<p>I'm new to C++ memory model, and not quite confident. Is my above reasoning correct, and the memory order I specified correct and most relaxed?</p>\n", "AcceptedAnswerId": "49115450", "Title": "Memory order in shared pointer destructor", "CreationDate": "2018-03-05T14:30:25.443", "Id": "49112732", "CommentCount": "7", "FavoriteCount": "1", "PostTypeId": "1", "LastActivityDate": "2018-03-06T09:56:23.733", "Score": "4", "OwnerUserId": "1348273", "Tags": "<c++><c++11><shared-ptr><atomic><memory-order>", "AnswerCount": "1"}, "49115450": {"Id": "49115450", "PostTypeId": "2", "Body": "<p>In <strong>theory</strong>, you may have the most efficient code, since there is no more synchronization than necessary.</p>\n<p>But in <strong>practice</strong>, there are almost no CPU that provides instruction that would map perfectly to acquire/release memory order (maybe future <a href=\"https://en.wikipedia.org/wiki/ARM_architecture#ARMv8.3-A\" rel=\"nofollow noreferrer\">ARMv8.3-A</a> will). So you will have to check for each target the generated code.</p>\n<p>For example on a x86_64 <code>fetch_sub(std::memory_order_acq_rel)</code> and <code>fetch_sub(std::memory_order_release)</code> will result in the exact same instruction.</p>\n<p>So while in theory your code looks like optimal, in practice, you get a code that is less optimal than if you had opted to a simpler approach:</p>\n<pre><code>std::atomic&lt;int&gt; cnt;\nint* p;\nvoid optimal_in_therory() {\n     if (cnt.fetch_sub(1, std::memory_order_release) == 1) {\n       cnt.load(std::memory_order_acquire);\n       delete p;\n   }\n}\nvoid optimal_in_practice_on_x86_64() {\n     if (cnt.fetch_sub(1, std::memory_order_acq_rel) == 1) {\n       delete p;\n   }\n}\n</code></pre>\n<p>Assembly:</p>\n<pre><code>optimal_in_therory():\n  lock sub DWORD PTR cnt[rip], 1\n  je .L4\n  rep ret\n.L4:\n  mov eax, DWORD PTR cnt[rip]  ;Unnecessary extra load\n  mov rdi, QWORD PTR p[rip]\n  mov esi, 4\n  jmp operator delete(void*, unsigned long)\noptimal_in_practice_on_x86_64():\n  lock sub DWORD PTR cnt[rip], 1\n  je .L7\n  rep ret\n.L7:\n  mov rdi, QWORD PTR p[rip]\n  mov esi, 4\n  jmp operator delete(void*, unsigned long)\n</code></pre>\n<p><em>One day I will live in Theory, because in Theory every thing goes well</em> -Pierre Desproges</p>\n<hr>\n<p><strong>Why does the compiler keep this extra-load?</strong></p>\n<p>According to the standard optimizers are allowed to elide redundant load performed on non volatile atomics. For example if in your code you added three extra-loads:</p>\n<pre><code>cnt.load(std::memory_order_acquire);\ncnt.load(std::memory_order_acquire);\ncnt.load(std::memory_order_acquire);\n</code></pre>\n<p>With GCC or Clang the three loads would appear in the assembly:</p>\n<pre><code>mov eax, DWORD PTR cnt[rip]\nmov eax, DWORD PTR cnt[rip]\nmov eax, DWORD PTR cnt[rip]\n</code></pre>\n<p>This is a realy bad pessimization. <em>My opinion</em> is that it is kept as-is because of an historical confusion between \"volatility\" and \"atomicity\". While almost all programmers know that a volatile does not have the properties of an atomic variable, many code are still written with the idea that an atomic has the propertie of a volatile: \"an atomic access is an observable behaviour\". According to the standard it is not (an explicit <a href=\"https://timsong-cpp.github.io/cppwp/n4659/smartptr#util.smartptr.shared.assign-3\" rel=\"nofollow noreferrer\">example note about this fact in the standard</a>). This is a recurring question on SO.</p>\n<p>So your code is realy the optimal code in theory, and it is pessimized because compilers optimize code as if atomics were also volatiles.</p>\n<p>The work around could be to replace the load by an atomic_thread_fence as proposed by Kieth in its comment. I am not an hardware expert but I imagine that such a fence could cause more memory \"synchronization\" than necessary (or at least in theory ;)).</p>\n<p><strong>Why I believe your code is the optimal in theory?</strong></p>\n<p>The last shared_ptr of a single object must call the destructor of that object without itself causing a data race. The desctructor may access the value the object, so the desctructor call must happen after the \"invalidation\" of the pointer to the object.</p>\n<p>So <code>delete p;</code> must \"happen after\" the destructor call of all others shared pointers that were sharing the same pointed object.</p>\n<p>In the standard <em>happens before</em> is defined by the following paragraph:</p>\n<p><em>[intro.races]/9:</em></p>\n<blockquote>\n<p id=\"so_49112732_49115450_0\">An evaluation A inter-thread happens before an evaluation B if:</p>\n<ul>\n<li>A synchronizes with B, or [...]</li>\n</ul>\n</blockquote>\n<ul>\n<li>any combination with \"sequenced before\" and it is a transitive rule.</li>\n</ul>\n<p><em>[intro.races]/10:</em></p>\n<blockquote>\n<p id=\"so_49112732_49115450_1\">An evaluation A happens before an evaluation B (or, equivalently, B happens after A) if:</p>\n<ul>\n<li><p id=\"so_49112732_49115450_2\">A is sequenced before B, or</p></li>\n<li><p id=\"so_49112732_49115450_3\">A inter-thread happens before B.</p></li>\n</ul>\n</blockquote>\n<p>So there must be a \"synchronize with\" relation between the <code>fetch_sub</code> that is sequenced before <code>delete p</code> and the other <code>fetch_sub</code>.</p>\n<p>According to <a href=\"https://timsong-cpp.github.io/cppwp/n4659/atomics.order#2\" rel=\"nofollow noreferrer\">[atomics.order]/2</a>:</p>\n<blockquote>\n<p id=\"so_49112732_49115450_4\">An atomic operation A that performs a release operation on an atomic object M synchronizes with an atomic operation B that performs an acquire operation on M and takes its value from any side effect in the release sequence headed by A.</p>\n</blockquote>\n<p>So <code>delete p</code> must be sequenced after an acquire operation which load a value which is in the release sequence of all the other <code>fetch_sub</code>.</p>\n<p>According to <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#5\" rel=\"nofollow noreferrer\">[expr.races]/5</a> the last <code>fetch_sub</code> (in the modification order of cnt) will belong to the release sequence of all the other release <code>fetch_sub</code> because a <code>fetch_sub</code> is a <em>read-modify-write</em> operation, as is <code>fetch_add</code> (supposing no other operations happen on <code>cnt</code>). </p>\n<p>So <code>delete p</code> will happen after all the other fetch_sub, and it is only before <code>delete p</code> is called that a \"synchronization\" will be produced. Precisely not more that what is necessary.</p>\n</hr>", "LastEditorUserId": "5632316", "LastActivityDate": "2018-03-06T09:56:23.733", "Score": "4", "CreationDate": "2018-03-05T16:47:09.530", "ParentId": "49112732", "CommentCount": "5", "OwnerUserId": "5632316", "LastEditDate": "2018-03-06T09:56:23.733"}});