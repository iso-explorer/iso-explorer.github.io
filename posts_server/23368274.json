post_cb({"32408436": {"ParentId": "23368274", "LastEditDate": "2015-09-05T05:20:16.460", "CommentCount": "0", "CreationDate": "2015-09-05T00:47:24.207", "OwnerUserId": "4474419", "LastEditorUserId": "4474419", "PostTypeId": "2", "Id": "32408436", "Score": "0", "Body": "<p>The other answers, which say to use <code>atomic</code> and not <code>volatile</code>, are correct when portability matters.  If you\u2019re asking this question, and it\u2019s a good question, that\u2019s the practical answer for you, not, \u201cBut, if the standard library doesn\u2019t provide one, you can implement a lock-free, wait-free data structure yourself!\u201d  Nevertheless, if the standard library doesn\u2019t provide one, you can implement a lock-free data structure yourself that works on a particular compiler and a particular architecture, provided that there\u2019s only one writer.  (Also, somebody has to implement those atomic primitives in the standard library.)  If I\u2019m wrong about this, I\u2019m sure someone will kindly inform me.</p>\n<p>If you absolutely need an algorithm guaranteed to be lock-free on all platforms, you might be able to build one with <code>atomic_flag</code>.  If even that doesn\u2019t suffice, and you need to roll your own data structure, you can do that.</p>\n<p>Since there\u2019s only one writer thread, your CPU might guarantee that certain operations on your data will still work atomically even if you just use normal accesses instead of locks or even compare-and-swaps.  This is not safe <em>according to the language standard</em>, because C++ has to work on architectures where it isn\u2019t, but it can be safe, for example, <em>on an x86 CPU</em> if you guarantee that the variable you\u2019re updating fits into a single cache line that it doesn\u2019t share with anything else, and you might be able to ensure this with nonstandard extensions such as <code>__attribute__ (( aligned (x) ))</code>.</p>\n<p>Similarly, your compiler might provide some guarantees: <code>g++</code> in particular makes guarantees about how the compiler will not assume that the memory referenced by a <code>volatile*</code> hasn\u2019t changed unless the current thread could have changed it.  It will actually re-read the variable from memory each time you dereference it.  That is in no way <em>sufficient</em> to ensure thread-safety, but it can be handy if another thread is updating the variable.</p>\n<p>A real-world example might be: the writer thread maintains some kind of pointer (on its own cache line) which points to a consistent view of the data structure that will remain valid through all future updates.  It updates its data with the RCU pattern, making sure to use a release operation (implemented in an architecture-specific way) after updating its copy of the data and before making the pointer to that data globally visible, so that any other thread that sees the updated pointer is guaranteed to see the updated data as well.  The reader then makes a local copy (not <code>volatile</code>) of the current value of the pointer, getting a view of the data which will stay valid even after the writer thread updates again, and works with that.  You want to use <code>volatile</code> on the single variable that notifies the readers of the updates, so they can see those updates even if the compiler \u201cknows\u201d your thread couldn\u2019t have changed it.  In this framework, the shared data just needs to be constant, and readers will use the RCU pattern.  That\u2019s one of the two ways I\u2019ve seen <code>volatile</code> be useful in the real world (the other being when you don\u2019t want to optimize out your timing loop).</p>\n<p>There also needs to be some way, in this scheme, for the program to know when nobody\u2019s using an old view of the data structure any longer.  If that\u2019s a count of readers, that count needs to be atomically modified in a single operation at the same time as the pointer is read (so getting the current view of the data structure involves an atomic CAS).  Or this might be a periodic tick when all the threads are guaranteed to be done with the data they\u2019re working with now.  It might be a generational data structure where the writer rotates through pre-allocated buffers.</p>\n<p>Also observe that a lot of things your program might do could implicitly serialize the threads: those atomic hardware instructions lock the processor bus and force other CPUs to wait, those memory fences could stall your threads, or your threads might be waiting in line to allocate memory from the heap.</p>\n", "LastActivityDate": "2015-09-05T05:20:16.460"}, "32398046": {"ParentId": "23368274", "CommentCount": "0", "Body": "<p>TL;DR: Use <code>std::atomic&lt;int&gt;</code> with a mutex around it if you read multiple times.</p>\n<p>Depends on how strong guarantees you want.</p>\n<p>First <code>volatile</code> is a compiler hint and you shouldn't count on it doing something helpful.</p>\n<p>If you use int you can suffer for memory aliasing. Say you have something like</p>\n<pre><code>struct {\n  int x;\n  bool q;\n}\n</code></pre>\n<p>Depending on how this is aligned in memory and the exact implementation of CPU and memory bus it's possible that writing to q will actually overwrite x when the page is copied from the cpu cache back to ram. So unless you know how much to allocate around your int it's not guaranteed that your writer will be able to write without being overwritten by some other thread.\nAlso even if you write you depend on the processor for reloading the data to the cache of other cores so there's no guarantee that your other thread will see a new value.</p>\n<p><code>std::atomic&lt;int&gt;</code> basically guarantees that you will always allocate sufficient memory, properly aligned so that you don't suffer from aliasing. Depending on the memory order requested you will also disable a bunch of optimizations, like caching, so everything will run slightly slower.</p>\n<p>This still doesn't grantee that if your read the var multiple times you'll get the value. The only way to do that is to put a mutex around it to block the writer from changing it.</p>\n<p>Still better find a library that already solves the problem you have and it has already been tested by others to make sure it works well.</p>\n", "OwnerUserId": "241013", "PostTypeId": "2", "Id": "32398046", "Score": "-3", "CreationDate": "2015-09-04T12:26:46.833", "LastActivityDate": "2015-09-04T12:26:46.833"}, "23368274": {"CommentCount": "0", "CreationDate": "2014-04-29T14:57:49.040", "PostTypeId": "1", "AcceptedAnswerId": "32384355", "LastEditorUserId": "93647", "LastActivityDate": "2015-09-08T22:33:35.020", "LastEditDate": "2015-09-08T22:33:35.020", "ViewCount": "443", "FavoriteCount": "1", "Title": "how to declare and use \"one writer, many readers, one process, simple type\" variable?", "Id": "23368274", "Score": "13", "Body": "<p>I have really simple question. I have simple type variable (like int). I have one process, one writer thread, several \"readonly\" threads. How should I declare variable?</p>\n<ul>\n<li><code>volatile int</code></li>\n<li><code>std::atomic&lt;int&gt;</code></li>\n<li><code>int</code></li>\n</ul>\n<p>I expect that when \"writer\" thread modifies value all \"reader\" threads should see fresh value ASAP.</p>\n<p>It's ok to read and write variable at the same time, but I expect reader to obtain either old value or new value, not some \"intermediate\" value.</p>\n<p>I'm using single-CPU Xeon E5 v3 machine. I do not need to be portable, I run the code only on this server, i compile with <code>-march=native -mtune=native</code>. Performance is very important so I do not want to add \"synchronization overhead\" unless absolutely required.</p>\n<hr>\n<p>If I just use <code>int</code> and one thread writes value is it possible that in another thread I do not see \"fresh\" value for a while?</p>\n</hr>", "Tags": "<c++><multithreading><low-latency>", "OwnerUserId": "93647", "AnswerCount": "9"}, "32354705": {"ParentId": "23368274", "LastEditDate": "2015-09-04T13:11:00.310", "CommentCount": "0", "CreationDate": "2015-09-02T13:35:36.467", "OwnerUserId": "4342498", "LastEditorUserId": "4342498", "PostTypeId": "2", "Id": "32354705", "Score": "5", "Body": "<p>If you have unsynchronized access to a variable where you have one or more writers then your program has <a href=\"https://en.wikipedia.org/wiki/Undefined_behavior\" rel=\"nofollow\">undefined behavior</a>.  Some how you have to guarantee that while a write is happening no other write or read can happen.  This is called <a href=\"https://en.wikipedia.org/wiki/Synchronization_(computer_science)\" rel=\"nofollow\">synchronization</a>.   How you achieve this synchronization depends on the application.</p>\n<p>For something like this where we have one writer and and several readers and are using a <a href=\"http://en.cppreference.com/w/cpp/concept/TriviallyCopyable\" rel=\"nofollow\">TriviallyCopyable</a> datatype then a <code>std::atomic&lt;&gt;</code> will work.  The atomic variable will make sure under the hood that only one thread can access the variable at the same time.</p>\n<p>If you do not have a TriviallyCopyable type or you do not want to use a <code>std::atomic</code> You could also use a conventional <a href=\"http://en.cppreference.com/w/cpp/thread/mutex\" rel=\"nofollow\"><code>std::mutex</code></a> and a <a href=\"http://en.cppreference.com/w/cpp/thread/lock_guard\" rel=\"nofollow\"><code>std::lock_guard</code></a> to control access</p>\n<pre><code>{ // enter locking scope\n    std::lock_guard lock(mutx); // create lock guard which locks the mutex\n    some_variable = some_value; // do work\n} // end scope lock is destroyed and mutx is released\n</code></pre>\n<p>An important thing to keep in mind with this approach is that you want to keep the <code>// do work</code> section as short as possible as while the mutex is locked no other thread can enter that section.</p>\n<p>Another option would be to use a <a href=\"http://en.cppreference.com/w/cpp/thread/shared_timed_mutex\" rel=\"nofollow\"><code>std::shared_timed_mutex</code></a>(C++14) or <a href=\"http://en.cppreference.com/w/cpp/thread/shared_mutex\" rel=\"nofollow\"><code>std::shared_mutex</code></a>(C++17) which will allow multiple readers to share the mutex but when you need to write you can still look the mutex and write the data.</p>\n<p>You do not want to use <code>volatile</code> to control synchronization as <a href=\"http://en.cppreference.com/w/cpp/thread/shared_mutex\" rel=\"nofollow\">jalf</a> states in <a href=\"http://herbsutter.com/\" rel=\"nofollow\">this answer</a>:</p>\n<blockquote>\n<p id=\"so_23368274_32354705_0\">For thread-safe accesses to shared data, we need a guarantee that:</p>\n<ul>\n<li>the read/write actually happens (that the compiler won't just store the value in a register instead and defer updating main memory until\n  much later)</li>\n<li>that no reordering takes place. Assume that we use a <code>volatile</code> variable as a flag to indicate whether or not some data is ready to be\n  read. In our code, we simply set the flag after preparing the data, so\n  all looks fine. But what if the instructions are reordered so the flag\n  is set first?</li>\n</ul>\n<p id=\"so_23368274_32354705_1\"><code>volatile</code> does guarantee the first point. It also guarantees that no\n  reordering occurs between different <code>volatile</code> reads/writes. All\n  <code>volatile</code> memory accesses will occur in the order in which they're\n  specified. That is all we need for what <code>volatile</code> is intended for:\n  manipulating I/O registers or memory-mapped hardware, but it doesn't\n  help us in multithreaded code where the <code>volatile</code> object is often\n  only used to synchronize access to non-volatile data. Those accesses\n  can still be reordered relative to the <code>volatile</code> ones.</p>\n</blockquote>\n<p>As always if you measure the performance and the performance is lacking then you can try a different solution but make sure to remeasure and compare after changing.</p>\n<p>Lastly <a href=\"http://herbsutter.com/\" rel=\"nofollow\">Herb Sutter</a> has an excellent presentation he did at <a href=\"http://cppandbeyond.com/\" rel=\"nofollow\">C++ and Beyond 2012</a> called <a href=\"http://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/\" rel=\"nofollow\">Atomic Weapons</a> that:</p>\n<blockquote>\n<p id=\"so_23368274_32354705_2\">This is a two-part talk that covers the C++ memory model, how locks and atomics and fences interact and map to hardware, and more. Even though we\u2019re talking about C++, much of this is also applicable to Java and .NET which have similar memory models, but not all the features of C++ (such as relaxed atomics).</p>\n</blockquote>\n", "LastActivityDate": "2015-09-04T13:11:00.310"}, "32396160": {"ParentId": "23368274", "CommentCount": "3", "Body": "<p>I'll complete a little bit the previous answers.</p>\n<p>As exposed previously, just using int or eventually volatile int is not enough for various reason (even with the memory order constraint of Intel processors.)</p>\n<p>So, yes, you should use atomic types for that, but you need extra considerations: atomic types guarantee coherent access but if you have visibility concerns you need to specify memory barrier (memory order.)</p>\n<p>Barriers will enforce visibility and coherency between threads, on Intel and most modern architectures, it will enforce cache synchronizations so updates are visible for every cores. The problem is that it may be expensive if you're not careful enough.</p>\n<p>Possible memory order are:</p>\n<ul>\n<li><strong>relaxed</strong>: no special barrier, only coherent read/write are enforce;</li>\n<li><strong>sequential</strong> consistency: strongest possible constraint (the default);</li>\n<li><strong>acquire</strong>: enforce that no loads after the current one are reordered before and add the required barrier to ensure that released stores are visible;</li>\n<li><strong>consume</strong>: a simplified version of acquire that mostly only constraint reordering;</li>\n<li><strong>release</strong>: enforce that all stores before are complete before the current one and that memory writes are done and visible to loads performing an acquire barrier.</li>\n</ul>\n<p>So, if you want to be sure that updates to the variable are visible to readers, you need to flag your store with a (at least) a release memory order and, on the reader side you need an acquire memory order (again, at least.) Otherwise, readers may not see the actual version of the integer (it'll see a coherent version at least, that is the old or the new one, but not an ugly mix of the two.)</p>\n<p>Of course, the default behavior (full consistency) will also give you the correct behavior, but at the expense of a lot of synchronization. In short, each time you add a barrier it forces cache synchronization which is almost as expensive as several cache misses (and thus reads/writes in main memory.)</p>\n<p>So, in short you should declare your int as atomic and use the following code for store and load:</p>\n<pre><code>// Your variable\nstd::atomic&lt;int&gt; v;\n\n// Read\nx = v.load(std::memory_order_acquire);\n\n// Write\nv.store(x, std::memory_order_release);\n</code></pre>\n<p>And just to complete, sometimes (and more often that you think) you don't really need the sequential consistency (even the partial release/acquire consistency) since visibility of updates are pretty relative. When dealing with concurrent operations, updates take place not when write is performed but when others see the change, <strong>reading the old value is probably not a problem !</strong></p>\n<p>I strongly recommend reading articles related to relativistic programming and RCU, here are some interesting links:</p>\n<ul>\n<li><strong>Relativistic Programming wiki:</strong> <a href=\"http://wiki.cs.pdx.edu/rp/\" rel=\"nofollow\">http://wiki.cs.pdx.edu/rp/</a></li>\n<li><strong>Structured Deferral: Synchronization via Procrastination:</strong> <a href=\"https://queue.acm.org/detail.cfm?id=2488549\" rel=\"nofollow\">https://queue.acm.org/detail.cfm?id=2488549</a></li>\n<li><strong>Introduction to RCU Concepts:</strong> <a href=\"http://www.rdrop.com/~paulmck/RCU/RCU.LinuxCon.2013.10.22a.pdf\" rel=\"nofollow\">http://www.rdrop.com/~paulmck/RCU/RCU.LinuxCon.2013.10.22a.pdf</a></li>\n</ul>\n", "OwnerUserId": "2323035", "PostTypeId": "2", "Id": "32396160", "Score": "2", "CreationDate": "2015-09-04T10:45:59.080", "LastActivityDate": "2015-09-04T10:45:59.080"}, "32384355": {"ParentId": "23368274", "LastEditDate": "2015-09-08T20:44:01.120", "CommentCount": "2", "CreationDate": "2015-09-03T19:54:02.927", "OwnerUserId": "3818191", "LastEditorUserId": "3818191", "PostTypeId": "2", "Id": "32384355", "Score": "-2", "Body": "<blockquote>\n<p id=\"so_23368274_32384355_0\">I have simple type variable (like int).\n  I have one process, one writer thread, several \"readonly\" threads. How\n  should I declare variable?</p>\n<p id=\"so_23368274_32384355_1\">volatile int \n  std::atomic \n  int</p>\n</blockquote>\n<p><strong>Use std::atomic with memory_order_relaxed for the store and load</strong> </p>\n<p>It's quick, and from your description of your problem, safe.  E.g. </p>\n<pre><code>void func_fast()\n{\n    std::atomic&lt;int&gt; a; \n    a.store(1, std::memory_order_relaxed);\n}\n</code></pre>\n<p>Compiles to: </p>\n<pre><code>func_fast():\n    movl    $1, -24(%rsp)\n    ret\n</code></pre>\n<p>This assumes you don't need to guarantee that any other data is seen to be written before the integer is updated, and therefore the slower and more complicated synchronisation is unnecessary.  </p>\n<p>If you use the atomic naively like this: </p>\n<pre><code>void func_slow()\n{\n    std::atomic&lt;int&gt; b;\n    b = 1; \n}\n</code></pre>\n<p>You get an MFENCE instruction with no memory_order* specification which is massive slower (100 cycles more more vs just 1 or 2 for the bare MOV).</p>\n<pre><code>func_slow():\n    movl    $1, -24(%rsp)\n    mfence\n    ret\n</code></pre>\n<p>See <a href=\"http://goo.gl/svPpUa\" rel=\"nofollow\">http://goo.gl/svPpUa</a> </p>\n<p>(Interestingly on Intel the use of memory_order_release and _acquire for this code results in the same assembly language.  Intel guarantees that writes and reads happen in order when using the standard MOV instruction).</p>\n", "LastActivityDate": "2015-09-08T20:44:01.120"}, "32361334": {"ParentId": "23368274", "CommentCount": "2", "Body": "<p>Here is my attempt at bounty:\n - a. General answer already given above says 'use atomics'. This is correct answer. volatile is not enough.\n  -a. If you dislike the answer, and you are on Intel, and you have properly aligned int, and you love unportable solutions, you can do away with simple volatile, using Intel strong memory ordering gurantees.</p>\n", "OwnerUserId": "5245033", "PostTypeId": "2", "Id": "32361334", "Score": "0", "CreationDate": "2015-09-02T19:13:53.600", "LastActivityDate": "2015-09-02T19:13:53.600"}, "32394808": {"ParentId": "23368274", "LastEditDate": "2017-05-23T11:52:12.970", "CommentCount": "0", "CreationDate": "2015-09-04T09:40:22.483", "OwnerUserId": "2083998", "LastEditorUserId": "-1", "PostTypeId": "2", "Id": "32394808", "Score": "1", "Body": "<p>Let's start from int at <code>int</code>. In general, when used on single processor, single core machine this should be sufficient, assuming int size same or smaller than CPU word (like 32bit int on 32bit CPU). In this case, assuming correctly aligned address word addresses (high level language should assure this by default) the write/read operations should be atomic. This is guaranteed by Intel as stated in [1] . However, in C++ specification simultaneous reading and writing from different threads is undefined behaviour.</p>\n<p>$1.10</p>\n<blockquote>\n<p id=\"so_23368274_32394808_0\">6 Two expression evaluations conflict if one of them modifies a memory location (1.7) and the other one accesses or modifies the same memory location.</p>\n</blockquote>\n<p>Now <code>volatile</code>. This keyword disables almost every optimization. This is the reason why it was used. For example, sometimes when optimizing the compiler can come to idea, that variable you only read in one thread is constant there and simply replace it with it's initial value. This solves such problems. However, it does not make access to variable atomic. Also, in most cases, it is simply unnecessary, because use of proper multithreading tools, like mutex or memory barrier, will achieve same effect as volatile on it's own, as described for instance in [2]</p>\n<p>While this may be sufficient for most uses, there are other operations that are not guaranteed to be atomic. Like incrementation is a one. This is when <code>std::atomic</code> comes in. It has those operations defined, like here for mentioned incrementations in [3]. It is also well defined when reading and writing from different threads [4].</p>\n<p>In addition, as stated in answers in [5], there exists a lot of other factors that may influence (negatively) atomicity of operations. From loosing cache coherency between multiple cores to some hardware details are the factors that may change how operations are performed.</p>\n<p>To summarize, <code>std::atomic</code> is created to support accesses from different threads and it is highly recommended to use it when multithreading.</p>\n<p>[1] <a href=\"http://www.intel.com/Assets/PDF/manual/253668.pdf\" rel=\"nofollow noreferrer\">http://www.intel.com/Assets/PDF/manual/253668.pdf</a> see section 8.1.1.</p>\n<p>[2] <a href=\"https://www.kernel.org/doc/Documentation/volatile-considered-harmful.txt\" rel=\"nofollow noreferrer\">https://www.kernel.org/doc/Documentation/volatile-considered-harmful.txt</a></p>\n<p>[3] <a href=\"http://en.cppreference.com/w/cpp/atomic/atomic/operator_arith\" rel=\"nofollow noreferrer\">http://en.cppreference.com/w/cpp/atomic/atomic/operator_arith</a></p>\n<p>[4] <a href=\"http://en.cppreference.com/w/cpp/atomic/atomic\" rel=\"nofollow noreferrer\">http://en.cppreference.com/w/cpp/atomic/atomic</a></p>\n<p>[5] <a href=\"https://stackoverflow.com/questions/54188/are-c-reads-and-writes-of-an-int-atomic\">Are C++ Reads and Writes of an int Atomic?</a></p>\n", "LastActivityDate": "2015-09-04T09:40:22.483"}, "23368393": {"ParentId": "23368274", "CommentCount": "6", "Body": "<p>Just use <code>std::atomic</code>.</p>\n<p>Don't use <code>volatile</code>, and don't use it as it is; that doesn't give the necessary synchronisation. Modifying it in one thread and accessing it from another without synchronisation will give undefined behaviour.</p>\n", "OwnerUserId": "204847", "PostTypeId": "2", "Id": "23368393", "Score": "9", "CreationDate": "2014-04-29T15:02:21.373", "LastActivityDate": "2014-04-29T15:02:21.373"}, "32405471": {"ParentId": "23368274", "LastEditDate": "2015-09-08T12:24:20.957", "CommentCount": "3", "CreationDate": "2015-09-04T19:43:44.660", "OwnerUserId": "5129715", "LastEditorUserId": "5129715", "PostTypeId": "2", "Id": "32405471", "Score": "1", "Body": "<p>Unfortunately it depends.</p>\n<p>When a variable is read and written in multiple threads, there may be 2 failures.</p>\n<p>1) tearing.  Where half the data is pre-change and half the data is post change.</p>\n<p>2) stale data.  Where the data read has some older value.</p>\n<p>int, volatile int and std:atomic all don't tear.</p>\n<p>Stale data is a different issue. However, all values have existed, can be concieved as correct.</p>\n<p>volatile.  This tells the compiler neither to cache the data, nor to re-order operations around it.  This improves the coherence between threads by ensuring all operations in a thread are either before the variable, at the variable, or after.</p>\n<p>This means that</p>\n<pre><code>volatile int x;\nint y;\ny =5;\nx = 7;\n</code></pre>\n<p>the instruction for x = 7 will be written after y = 5;</p>\n<p>Unfortunately, the CPU is also capable of re-ordering operations.  This can mean that another thread sees x ==7 before y =5</p>\n<p>std::atomic x; would allow a guarantee that after seeing x==7, another thread would see y ==5. (Assuming other threads are not modifying y)</p>\n<p>So all reads of <code>int</code>, <code>volatile int</code>, <code>std::atomic&lt;int&gt;</code> would show previous valid values of x.  Using <code>volatile</code> and <code>atomic</code> increase the ordering of values.</p>\n<p>See <a href=\"https://www.kernel.org/doc/Documentation/memory-barriers.txt\" rel=\"nofollow\">kernel.org barriers</a></p>\n", "LastActivityDate": "2015-09-08T12:24:20.957"}, "bq_ids": {"n4140": {"so_23368274_32394808_0": {"section_id": 5817, "quality": 0.9375, "length": 15}}, "n3337": {"so_23368274_32394808_0": {"section_id": 5588, "quality": 0.9375, "length": 15}}, "n4659": {"so_23368274_32394808_0": {"section_id": 7278, "quality": 0.875, "length": 14}}}});