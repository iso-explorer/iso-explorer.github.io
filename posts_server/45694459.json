post_cb({"45694459": {"CommentCount": "24", "ViewCount": "205", "PostTypeId": "1", "LastEditorUserId": "6651824", "CreationDate": "2017-08-15T14:00:43.953", "LastActivityDate": "2017-09-01T21:41:16.927", "Title": "Using an atomic read-modify-write operation in a release sequence", "LastEditDate": "2017-08-17T10:54:28.713", "Id": "45694459", "Score": "4", "Body": "<p>Say, I create an object of type <code>Foo</code> in thread #1 and want to be able to access it in thread #3.<br>\nI can try something like:</br></p>\n<pre><code>std::atomic&lt;int&gt; sync{10};\nFoo *fp;\n\n// thread 1: modifies sync: 10 -&gt; 11\nfp = new Foo;\nsync.store(11, std::memory_order_release);\n\n// thread 2a: modifies sync: 11 -&gt; 12\nwhile (sync.load(std::memory_order_relaxed) != 11);\nsync.store(12, std::memory_order_relaxed);\n\n// thread 3\nwhile (sync.load(std::memory_order_acquire) != 12);\nfp-&gt;do_something();\n</code></pre>\n<ul>\n<li>The store/release in thread #1 orders <code>Foo</code> with the update to 11</li>\n<li>thread #2a non-atomically increments the value of <code>sync</code> to 12</li>\n<li>the <em>synchronizes-with</em> relationship between thread #1 and #3 is only established when #3 loads 11</li>\n</ul>\n<p><a href=\"https://i.stack.imgur.com/9k7yd.png\" rel=\"nofollow noreferrer\"><img alt=\"Synchronization of Foo\" src=\"https://i.stack.imgur.com/9k7yd.png\"/></a></p>\n<p>The scenario is broken because thread #3 spins until it loads 12, which may arrive out of order (wrt 11) and <code>Foo</code> is not ordered with 12 (due to the relaxed operations in thread #2a).<br>\nThis is somewhat counter-intuitive since the modification order of <code>sync</code> is 10 \u2192 11 \u2192 12</br></p>\n<p>The standard says (\u00a7 1.10.1-6):</p>\n<blockquote>\n<p id=\"so_45694459_45694459_0\">an atomic store-release synchronizes with a load-acquire that takes its value from the store (29.3). [ Note: Except in the specified cases, reading a later value does not necessarily ensure visibility as described below. Such a requirement would sometimes interfere with efficient implementation. \u2014end note ]</p>\n</blockquote>\n<p>It also says in (\u00a7 1.10.1-5):</p>\n<blockquote>\n<p id=\"so_45694459_45694459_1\">A release sequence headed by a release operation A on an atomic object M is a maximal contiguous subsequence of side effects in the modification order of M, where the first operation is A, and every subsequent operation<br>\n  -   is performed by the same thread that performed A, or<br>\n  -   is an atomic read-modify-write operation.</br></br></p>\n</blockquote>\n<p>Now, thread #2a is modified to use an atomic read-modify-write operation:</p>\n<pre><code>// thread 2b: modifies sync: 11 -&gt; 12\nint val;\nwhile ((val = 11) &amp;&amp; !sync.compare_exchange_weak(val, 12, std::memory_order_relaxed));\n</code></pre>\n<p>If this release sequence is correct, <code>Foo</code> is synchronized with thread #3 when it loads either 11 or 12.\nMy questions about the use of an atomic read-modify-write are:  </p>\n<ul>\n<li>Does the scenario with thread #2b constitute a correct release sequence ?</li>\n</ul>\n<p>And if so:</p>\n<ul>\n<li>What are the specific properties of a read-modify-write operation that ensure this scenario is correct ?</li>\n</ul>\n", "Tags": "<c++><multithreading><c++11><atomic>", "OwnerUserId": "6651824", "AnswerCount": "1"}, "46008290": {"ParentId": "45694459", "CommentCount": "2", "Body": "<p><em>Does the scenario with thread #2b constitute a correct release sequence ?</em></p>\n<p><strong>Yes</strong>, per your quote from the standard.</p>\n<p><em>What are the specific properties of a read-modify-write operation that ensure this scenario is correct?</em></p>\n<p>Well, the somewhat circular answer is that the only important specific property is that \"The C++ standard defines it so\".</p>\n<p>As a practical matter, one may ask <em>why</em> the standard defines it like this. I don't think you'll find that the answer has a deep theoretical basis: I think the committee could have also defined it such that the RMW <strong>doesn't</strong> participate in the release sequence, or (perhaps with more difficulty) have defined so that <strong>both</strong> the RMW and the separate <code>mo_relaxed</code> load and store participate in the release sequence, without compromising the \"soundness\" of the model.</p>\n<p>They already give a performance related as to why they didn't choose the latter approach:</p>\n<blockquote>\n<p id=\"so_45694459_46008290_0\">Such a requirement would sometimes interfere with efficient implementation.</p>\n</blockquote>\n<p>In particular, on any hardware platform that allowed load-store reordering, it would imply that even <code>mo_relaxed</code> loads and/or stores might require barriers! Such platforms exist today. Even on more strongly ordered platforms, it may inhibit compiler optimizations.</p>\n<p>So why didn't they take then take other \"consistent\" approach of not requiring RMW <code>mo_relaxed</code> to participate in the release sequence? Probably because existing hardware implementations of RMW operations provide such guarantees and the nature of RMW operations makes it likely that this will be true in the future. In particular, as Peter points in the comments above, RMW operations, even with <code>mo_relaxed</code> are conceptually and practically<sup>1</sup> stronger than separate loads and stores: they would be quite useless if they didn't have a consistent total order.</p>\n<p>Once you accept that is how hardware works, it makes sense from a performance angle to align the standard: if you didn't, you'd have people using more restrictive orderings such as <code>mo_acq_rel</code> just to get the release sequence guarantees, but on real hardware that has weakly ordered CAS, this doesn't come for free.</p>\n<hr>\n<p><sup>1</sup> The \"practically\" part means that even the weakest forms of RMW instructions are usually relatively \"expensive\" operations taking a dozen cycles or more on modern hardware, while <code>mo_relaxed</code> loads and stores generally just compile to plain loads and stores in the target ISA.</p>\n</hr>", "OwnerUserId": "149138", "PostTypeId": "2", "Id": "46008290", "Score": "2", "CreationDate": "2017-09-01T21:41:16.927", "LastActivityDate": "2017-09-01T21:41:16.927"}, "bq_ids": {"n4140": {"so_45694459_46008290_0": {"section_id": 5821, "quality": 1.0, "length": 7}, "so_45694459_45694459_0": {"section_id": 5821, "quality": 0.8709677419354839, "length": 27}, "so_45694459_45694459_1": {"section_id": 5820, "quality": 0.9629629629629629, "length": 26}}, "n3337": {"so_45694459_46008290_0": {"section_id": 5592, "quality": 1.0, "length": 7}, "so_45694459_45694459_0": {"section_id": 5592, "quality": 0.8709677419354839, "length": 27}, "so_45694459_45694459_1": {"section_id": 5591, "quality": 0.9629629629629629, "length": 26}}, "n4659": {"so_45694459_46008290_0": {"section_id": 7282, "quality": 1.0, "length": 7}, "so_45694459_45694459_0": {"section_id": 7282, "quality": 0.8709677419354839, "length": 27}, "so_45694459_45694459_1": {"section_id": 7281, "quality": 0.9629629629629629, "length": 26}}}});