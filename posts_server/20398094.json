post_cb({"20398094": {"CommentCount": "0", "ViewCount": "137", "CreationDate": "2013-12-05T10:55:22.650", "LastActivityDate": "2017-11-23T19:33:54.047", "Title": "atomic<T>.load() with std::memory_order_release", "AcceptedAnswerId": "20399497", "PostTypeId": "1", "Id": "20398094", "Score": "2", "Body": "<p>When writing C++11 code that uses the newly introduced thread-synchronization primitives to make use of the relaxed memory ordering, you usually see either</p>\n<pre><code>std::atomic&lt;int&gt; vv;\nint i = vv.load(std::memory_order_acquire);\n</code></pre>\n<p>or</p>\n<pre><code>vv.store(42, std::memory_order_release);\n</code></pre>\n<p>It is clear to me why this makes sense.</p>\n<p>My questions are: Do the combinations <code>vv.store(42, std::memory_order_acquire)</code> and <code>vv.load(std::memory_order_release)</code> also make sense? In which situation could one use them? What are the semantics of these combinations?</p>\n", "Tags": "<multithreading><c++11><atomicity>", "OwnerUserId": "1171688", "AnswerCount": "3"}, "20399600": {"ParentId": "20398094", "CommentCount": "0", "Body": "<p>These combinations do not make any sense, and they are not allowed either.</p>\n<p>An acquire operation synchronizes previous non-atomic writes or side effects with a release operation so that when the acquire (load) is realized, all other stores (effects) that happened before the release (store) are also visible (for threads that acquire <em>the same</em> atomic that was released).</p>\n<p>Now, if you <em>could do</em> (and would do) an acquire store and a release load, what should it do? What store should the acquire operation synchronize with? Itself?</p>\n", "OwnerUserId": "572743", "PostTypeId": "2", "Id": "20399600", "Score": "3", "CreationDate": "2013-12-05T12:06:29.507", "LastActivityDate": "2013-12-05T12:06:29.507"}, "20399497": {"ParentId": "20398094", "CommentCount": "0", "Body": "<p>That's simply not allowed. The C++ (11) standard has requirements on what memory order constraints you can put on load/store operations.</p>\n<p>For load (\u00a729.6.5):</p>\n<blockquote>\n<p id=\"so_20398094_20399497_0\"><em>Requires:</em> The order argument shall not be <code>memory_order_release</code> nor <code>memory_order_acq_rel</code>.</p>\n</blockquote>\n<p>For store:</p>\n<blockquote>\n<p id=\"so_20398094_20399497_1\"><em>Requires:</em> The order argument shall not be <code>memory_order_consume</code>, <code>memory_order_acquire</code>, nor <code>memory_order_acq_rel</code>.</p>\n</blockquote>\n", "OwnerUserId": "635608", "PostTypeId": "2", "Id": "20399497", "Score": "4", "CreationDate": "2013-12-05T12:02:15.633", "LastActivityDate": "2013-12-05T12:02:15.633"}, "bq_ids": {"n4140": {"so_20398094_20399497_1": {"section_id": 1188, "quality": 0.75, "length": 6}, "so_20398094_20399497_0": {"section_id": 1192, "quality": 0.7142857142857143, "length": 5}}, "n3337": {"so_20398094_20399497_1": {"section_id": 1186, "quality": 0.75, "length": 6}, "so_20398094_20399497_0": {"section_id": 1190, "quality": 0.7142857142857143, "length": 5}}, "n4659": {"so_20398094_20399497_1": {"section_id": 1269, "quality": 0.75, "length": 6}, "so_20398094_20399497_0": {"section_id": 1273, "quality": 0.7142857142857143, "length": 5}}}, "47462339": {"ParentId": "20398094", "CommentCount": "0", "Body": "<p>The C/C++/LLVM memory model is sufficient for synchronization\nstrategies that ensure data is ready to be accessed before accessing\nit. While that covers most common synchronization primitives, useful\nproperties can be obtained by building consistent models on weaker\nguarantees.</p>\n<p>The biggest example is the <a href=\"https://en.wikipedia.org/wiki/Seqlock\" rel=\"nofollow noreferrer\">seqlock</a>.\nIt relies on \"speculatively\" reading data that may not be in a\nconsistent state. Because reads are allowed to race with writes,\nreaders don't block writers -- a property which is used in the Linux\nkernel to allow the system clock to be updated even if a user process\nis repeatedly reading it. Another strength of the seqlock is that on\nmodern SMP arches it scales perfectly with the number of readers:\nbecause the readers don't need to take any locks, they only need\nshared access to the cache lines.</p>\n<p>The ideal implementation of a seqlock would use something like a\n\"release load\" in the reader, which is not available in any major\nprogramming language. The kernel works around this with <a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/include/linux/seqlock.h?h=v4.14#n133\" rel=\"nofollow noreferrer\">a full read\nfence</a>,\nwhich scales well across architectures, but <a href=\"http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf\" rel=\"nofollow noreferrer\">doesn't achieve optimal\nperformance</a>.</p>\n", "OwnerUserId": "3007411", "PostTypeId": "2", "Id": "47462339", "Score": "1", "CreationDate": "2017-11-23T19:33:54.047", "LastActivityDate": "2017-11-23T19:33:54.047"}});