post_cb({"41331215": {"CommentCount": "1", "ViewCount": "911", "CreationDate": "2016-12-26T12:21:44.483", "LastActivityDate": "2017-04-27T12:40:17.700", "Title": "What are the constraints on the user using STL's parallel algorithms?", "FavoriteCount": "7", "PostTypeId": "1", "Id": "41331215", "OwnerUserId": "1120273", "Body": "<p>At the Jacksonville meeting the proposal <a href=\"http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0024r2.html\" rel=\"noreferrer\">P0024r2</a> effectively adopting the specifications from the <a href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4354.pdf\" rel=\"noreferrer\">Parallelism TS</a> was accepted into the <a href=\"http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2016/n4604.pdf\" rel=\"noreferrer\">C++17 (draft)</a>. This proposal adds overloads for many of the algorithms taking an <em>execution policy</em> argument to indicate what kind of parallelism should be considered. There are three execution policies already defined in <code>&lt;execution&gt;</code> (20.19.2 [execution]):</p>\n<ul>\n<li><code>std::execution::sequenced_policy</code> (20.19.4 [execpol.seq]) with a <code>constexpr</code> object <code>std::execution::seq</code> (20.19.7 [parallel.execpol.objects]) to indicate sequential execution similar to calling the algorithms without an execution policy.</li>\n<li><code>std::execution::parallel_policy</code> (20.19.5 [execpol.par]) with a <code>constexpr</code> object <code>std::execution::par</code> (20.19.7 [parallel.execpol.objects]) to indicate execution of algorithms potentially using multiple threads.</li>\n<li><code>std::execution::parallel_unsequenced_policy</code> (20.19.6 [execpol.vec]) with a <code>constexpr</code> object <code>std::execution::par_unseq</code> (20.19.7 [parallel.execpol.objects])to indicate execution of algorithms potentially using vector execution and/or multiple threads.</li>\n</ul>\n<p>The STL algorithms generally take user-defined objects (iterators, function objects) as arguments. <strong>What are the constraints on user-defined objects to make them usable with the parallel algorithms using the standard execution policies?</strong></p>\n<p>For example, when using an algorithm like in the example below, what are the implications for <code>FwdIt</code> and <code>Predicate</code>?</p>\n<pre><code>template &lt;typename FwdIt, typename Predicate&gt;\nFwdIt call_remove_if(FwdIt begin, FwdIt end, Predicate predicate) {\n    return std::remove_if(std::execution::par, begin, end, predicate);\n}\n</code></pre>\n", "Tags": "<c++><stl><c++1z>", "Score": "30", "AnswerCount": "1"}, "bq_ids": {"n4659": {"so_41331215_41333175_0": {"section_id": 1337, "quality": 0.9473684210526315, "length": 18}, "so_41331215_41333175_2": {"section_id": 1336, "quality": 1.0, "length": 28}, "so_41331215_41333175_1": {"section_id": 1342, "quality": 0.9629629629629629, "length": 26}}}, "41333175": {"ParentId": "41331215", "PostTypeId": "2", "CommentCount": "0", "Body": "<p>The short answer is that the <em>element access functions</em> (essentially the operations required by the algorithms on the various arguments; see below for details) used with algorithms using the execution policy <code>std::execution::parallel</code> are not allowed to cause data races or dead-locks. The element access functions used with algorithms using the execution policy <code>std::execution::parallel_unsequenced_policy</code> additionally can't use any blocking synchronisation. </p>\n<h1>The Details</h1>\n<p>The description is based on the ballot document N4604. I haven't verified if some of the clauses were modified in response to national body comments (a cursory check seems to imply that there were no edits so far).</p>\n<p>Section 25.2 [algorithms.parallel] specifies the semantics of the parallel algorithms. There are multiple constraints which do not apply to the algorithms not taking an execution policy, broken down in multiple sections:</p>\n<ol>\n<li><p>In 25.2.2 [algorithms.parallel.user] constrains what predicate functions can do to their arguments:</p>\n<blockquote>\n<p id=\"so_41331215_41333175_0\">Function objects passed into parallel algorithms as objects of type <code>Predicate</code>, <code>BinaryPredicate</code>, <code>Compare</code>, and <code>BinaryOperation</code> shall not directly or indirectly modify objects via their arguments.</p>\n</blockquote>\n<p>The way the clause is written it seems that the objects themselves <em>can</em> be modified as long as the other constraints (see below) are obeyed. Note that this constraint is independent of the execution policy and, thus, applies even when using <code>std::execution::sequenced_policy</code>. The full answer is more complicated than that and it seems the specification is currently unintentionally over constrained (see the last paragraph below).</p></li>\n<li><p>In 25.2.3 [algorithms.parallel.exec] adds constraints on <em>element access functions</em> (see below) which are specific to the different execution policies:</p>\n<ul>\n<li>When using <code>std::execution::sequenced_policy</code> the element access functions are all invoked from the same thread, i.e., the execution is not interleaved in any form.</li>\n<li>When using <code>std::execution::parallel_policy</code> different threads may invoke the element access functions concurrently from different threads. Invoking element access functions from different threads is not allowed to cause data races or to cause dead-locks. However, invocations of element access from the same thread are [indeterminately] sequence, i.e., there are no interleaved invocations of element access function from the same thread. For example, if a <code>Predicate</code> used with <code>std::execution::par</code> counts how often it is called, the corresponding count will need to be appropriately synchronized.</li>\n<li><p>When using <code>std::execution::parallel_unsequenced_policy</code> the invocation of element access functions can be interleaved both between different thread as well as within one thread of execution. That is, use of a blocking synchronization primitive (like a <code>std::mutex</code>) may cause dead-lock as the same thread may try to synchronize multiple times (and, e.g., try to lock the same mutex multiple times). When using standard library functions for element access functions the constraint in the standard is (25.2.3 [algorithms.parallel.exec] paragraph 4):</p>\n<blockquote>\n<p id=\"so_41331215_41333175_1\">A standard library function is vectorization-unsafe if it is specified to synchronize with another function invocation, or another function invocation is specified to synchronize with it, and if it is not a memory allocation or deallocation function. Vectorization-unsafe standard library functions may not be invoked by user code called from <code>execution::parallel_unsequenced_policy</code> algorithms.</p>\n</blockquote></li>\n<li><p>What happens when using implementation defined execution policies is, unsurprisingly, implementation defined.</p></li>\n</ul></li>\n<li><p>In 25.2.4 [algorithm.parallel.exception] the use of exceptions thrown from element access functions is sort of constrained: when an element access function throws an exception, <code>std::terminate()</code> is called. That is, it is legal to throw an exception but it is unlikely that the outcome is desirable. Note that <code>std::terminate()</code> will be called even when using <code>std::execution::sequenced_policy</code>.</p></li>\n</ol>\n<h1>Element Access Functions</h1>\n<p>The constraints above use the term <em>element access function</em>. This term is defined in 25.2.1 [algorithm.parallel.defns] paragraph 2. There are four groups of functions classified as element access functions:</p>\n<blockquote id=\"so_41331215_41333175_2\">\n<ul>\n<li>All operations of the categories of the iterators that the algorithm is instantiated with.</li>\n<li>Operations on those sequence elements that are required by its specification.</li>\n<li>User-provided function objects to be applied during the execution of the algorithm, if required by the specification.</li>\n<li>Operations on those function objects required by the specification.</li>\n</ul>\n</blockquote>\n<p>Essentially, element access functions are all the operations which the standard explicitly refers to in the specification of the algorithms or the concepts used with these algorithms. Functions not mentioned and, e.g., detected to be present (e.g., using SFINAE) are not constrained and, effectively, can't be called from the parallel algorithms imposing synchronisation constraints on their use.</p>\n<h1>The Problem</h1>\n<p>It is slightly concerning that there seems to be no guarantee that the objects the [mutating] element access functions are applied to are different between different threads. In particular, I can't see any guarantee that the iterator operations applied to an iterator object can not be applied to the same iterator object from two different threads! The implication is that, e.g., <code>operator++()</code> on an iterator object would need to somehow synchronise its state. I can't see how, e.g., <code>operator==()</code> could do something useful if the object is modified in a different thread. It seems unintentional that operations on the same object need to be synchronised as it doesn't make any sense to apply [mutating] element access functions concurrently to an object. However, I can't see any text stating that different objects are used (I guess, I need to raise a defect for this).</p>\n", "OwnerUserId": "1120273", "LastEditorUserId": "1938163", "LastEditDate": "2017-04-27T12:40:17.700", "Id": "41333175", "Score": "17", "CreationDate": "2016-12-26T15:20:54.707", "LastActivityDate": "2017-04-27T12:40:17.700"}});