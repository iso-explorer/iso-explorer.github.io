post_cb({"bq_ids": {"n4140": {"so_41955493_41955881_0": {"length": 89, "quality": 0.8317757009345794, "section_id": 3161}}, "n3337": {"so_41955493_41955881_0": {"length": 71, "quality": 0.6635514018691588, "section_id": 3034}}, "n4659": {"so_41955493_41955881_0": {"length": 91, "quality": 0.8504672897196262, "section_id": 3923}}}, "41955881": {"Id": "41955881", "PostTypeId": "2", "Body": "<p>When you write</p>\n<pre><code>auto unevaluted_x = []() { return foo(); };\n...\nauto x = unevaluted_x();\n</code></pre>\n<p>Each time you want to get the value (when you call <code>unevaluated_x</code>) it's calculated, wasting computational resources. So, to get rid of this excessive work, it's a good idea to keep track whether or not the lambda has already been called (maybe in other thread, or in a very different place in the codebase). To do so, we need some wrapper around lambda:</p>\n<pre><code>template&lt;typename Callable, typename Return&gt;\nclass memoized_nullary {\npublic:\n    memoized_nullary(Callable f) : function(f) {}\n    Return operator() () {\n        if (calculated) {\n            return result;\n        }\n        calculated = true;\n        return result = function();\n    }\nprivate:\n    bool calculated = false;\n    Return result;\n    Callable function;\n};\n</code></pre>\n<p>Please note that this code is just an example and is not thread safe.</p>\n<p>But instead of reinventing the wheel, you could just use <code>std::shared_future</code>:</p>\n<pre><code>auto x = std::async(std::launch::deferred, []() { return foo(); }).share();\n</code></pre>\n<p>This requires less code to write and supports some other features (like, check whether the value has already been calculated, thread safety, etc).</p>\n<p>There's the following text in the standard [futures.async, (3.2)]:</p>\n<blockquote>\n<p id=\"so_41955493_41955881_0\">If <code>launch::deferred</code> is set in policy, stores <code>DECAY_COPY(std::forward&lt;F&gt;(f))</code> and <code>DECAY_COPY(std::forward&lt;Args&gt;(args))...</code> in the shared state. These copies of <code>f</code> and <code>args</code> constitute\n  a deferred function. Invocation of the deferred function evaluates <code>INVOKE(std::move(g), std::move(xyz))</code> where <code>g</code> is the stored value of <code>DECAY_COPY(std::forward&lt;F&gt;(f))</code> and <code>xyz</code> is\n  the stored copy of <code>DECAY_COPY(std::forward&lt;Args&gt;(args))....</code> Any return value is stored\n  as the result in the shared state. Any exception propagated from the execution of the deferred\n  function is stored as the exceptional result in the shared state. The shared state is not made\n  ready until the function has completed. <strong>The first call to a non-timed waiting function (30.6.4)\n  on an asynchronous return object referring to this shared state shall invoke the deferred function\n  in the thread that called the waiting function</strong>. Once evaluation of <code>INVOKE(std::move(g),std::move(xyz))</code> begins, the function is no longer considered deferred. [ Note: If this policy is\n  specified together with other policies, such as when using a policy value of <code>launch::async | launch::deferred</code>, implementations should defer invocation or the selection of the policy when\n  no more concurrency can be effectively exploited. \u2014end note ]</p>\n</blockquote>\n<p>So, you have a guarantee the calculation will not be called before it's needed.</p>\n", "LastEditorUserId": "1989995", "LastActivityDate": "2017-01-31T13:30:04.780", "Score": "12", "CreationDate": "2017-01-31T11:00:35.457", "ParentId": "41955493", "CommentCount": "6", "OwnerUserId": "1989995", "LastEditDate": "2017-01-31T13:30:04.780"}, "41956454": {"Id": "41956454", "PostTypeId": "2", "Body": "<p>There are a few things going on here.</p>\n<p><code>Applicative order</code> evaluation means evaluating arguments before passing them into a function.\n<code>Normal order</code> evaluation mean passing the arguments into a function before evaluating them.</p>\n<p>Normal order evaluation has the benefit that some arguments are never evaluated and the drawback that some arguments get evaluated over and over again.</p>\n<p><code>Lazy</code> evaluation usually means <code>normal order + memoization</code>. Postpone evaluation in the hope that you don't have to evaluate at all, but if you do need to, remember the result so you only have to do it once. The important part is evaluating a term never or once, memoization is the easiest mechanism to provide this.</p>\n<p>The <code>promise/future</code> model is different again. The idea here is to start an evaluation going, probably in another thread, as soon as you have enough information available. You then leave looking at the result for as long as possible to improve the chances that it's already available.</p>\n<hr>\n<p>The <code>promise/future</code> model has some interesting synergy with lazy evaluation. The strategy goes:</p>\n<ol>\n<li>Postpone evaluation until the result will definitely be needed</li>\n<li>Start the evaluation going in another thread</li>\n<li>Do some other stuff</li>\n<li>The background thread completes and stores the result somewhere</li>\n<li>The initial thread retrieves the result</li>\n</ol>\n<p>Memoization can be neatly introduced when the result is produced by the background thread.</p>\n<p>Despite the synergy between the two, they're not the same concept.</p>\n</hr>", "LastActivityDate": "2017-01-31T11:30:54.557", "CommentCount": "3", "CreationDate": "2017-01-31T11:30:54.557", "ParentId": "41955493", "Score": "4", "OwnerUserId": "3726169"}, "41955493": {"ViewCount": "1616", "Body": "<p>I just read:</p>\n<p><a href=\"https://stackoverflow.com/a/40919871/1593077\">Lazy Evaluation in C++</a></p>\n<p>and noticed it's kind of old and most of the answers regard pre-2011 C++. These days we have syntactic lambdas, which can even deduce the return type, so lazy evaluation seems to boil down to just passing them around: Instead of</p>\n<pre><code>auto x = foo();\n</code></pre>\n<p>you execute</p>\n<pre><code>auto unevaluted_x = []() { return foo(); };\n</code></pre>\n<p>and then evaluate when/where you need to:</p>\n<pre><code>auto x = unevaluted_x();\n</code></pre>\n<p>Seems like there's nothing more to it. However, one of the <a href=\"https://stackoverflow.com/a/40919871/1593077\">answers there</a> suggests using <a href=\"http://en.cppreference.com/w/cpp/thread/future\" rel=\"nofollow noreferrer\">futures</a> with asynchronous launching. Can someone lay out why/if futures are significant for lazy-evaluation work, in C++ or more abstractly? It seems as though futures may very well be evaluated eagerly, but simply, say, on another thread, and perhaps with less priority than whatever created them; and anyway, it should be implementation-dependent, right? </p>\n<p>Also, are there other modern C++ constructs which are useful to keep in mind in the context of lazy evaluation?</p>\n", "Title": "Lazy evaluation in C++14/17 - just lambdas or also futures etc.?", "CreationDate": "2017-01-31T10:41:13.400", "LastActivityDate": "2017-01-31T13:30:04.780", "CommentCount": "1", "FavoriteCount": "3", "PostTypeId": "1", "LastEditDate": "2017-05-23T12:00:32.043", "LastEditorUserId": "-1", "Id": "41955493", "Score": "13", "OwnerUserId": "1593077", "Tags": "<c++><c++11><lambda><lazy-evaluation><std-future>", "AnswerCount": "2"}});