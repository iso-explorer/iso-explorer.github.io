post_cb({"bq_ids": {"n4140": {"so_38706287_39160364_0": {"length": 27, "quality": 0.84375, "section_id": 5466}}, "n3337": {"so_38706287_39160364_1": {"length": 19, "quality": 0.9047619047619048, "section_id": 5695}, "so_38706287_39160364_0": {"length": 28, "quality": 0.875, "section_id": 5252}}, "n4659": {"so_38706287_39160364_0": {"length": 27, "quality": 0.84375, "section_id": 6900}}}, "39160364": {"Id": "39160364", "PostTypeId": "2", "Body": "<p>The underlying type of plain enums is implementation-defined:</p>\n<p>C++03 standard 7.2/5</p>\n<blockquote>\n<p id=\"so_38706287_39160364_0\">The underlying type of an enumeration is an integral type that can represent all the enumerator values defined in the enumeration. It is implementation-defined which integral type is used as the underlying type for an enumeration except that the underlying type shall not be larger than int unless the value of an enumerator cannot fit in an int or unsigned int</p>\n</blockquote>\n<p>The underlying time of struct bitfield enums is also implementation-defined:</p>\n<p>C++03 standard 9.6/3</p>\n<blockquote>\n<p id=\"so_38706287_39160364_1\">A bit-field shall have integral or enumeration type (3.9.1). It is implementation-defined whether a plain (neither explicitly signed nor unsigned) char, short, int or long bit-field is signed or unsigned.</p>\n</blockquote>\n<p>So because the type of both <code>X::En y:16</code> and <code>X::En</code> are implementation-defined, the implicit conversion between them is also implementation-defined, which I think explains the ADL difference that you're seeing across compilers.</p>\n", "LastActivityDate": "2016-08-26T07:11:01.047", "CommentCount": "0", "CreationDate": "2016-08-26T07:11:01.047", "ParentId": "38706287", "Score": "1", "OwnerUserId": "55935"}, "38706287": {"ViewCount": "93", "Body": "<p>g++ fails to compile following code snippet:</p>\n<pre><code>namespace X {\n  enum En {A, B};\n  bool test(En e);\n}\n\nbool check() {\n  union {\n    struct {\n      X::En y:16;\n      X::En z:16; \n    } x;\n    int z;\n  } zz;\n  return test(zz.x.y);\n}\n</code></pre>\n<p>The error it gives is following</p>\n<blockquote>\n<p id=\"so_38706287_38706287_0\">In function 'bool check()': 15 : error: 'test' was not declared in\n  this scope return test(zz.x.y); ^ 15 : note: suggested alternative: 3\n  : note: 'X::test' bool test(En e); ^~~~ Compilation failed</p>\n</blockquote>\n<p>If i make <code>y</code> a regular member, rather than a bitfield, code compiles successfully. Calling a name-spaced <code>test</code> works as well. Clang compiles the program as-is without any complains.</p>\n<p>Putting bitfield business aside  (I do not love it at all, but codebase has it) and not focusing on whether I have a guarantee of fitting an enum into the 16-bit member or not, is there something special regarding bitfields which prevents ADL from kicking in as I expect it?</p>\n", "Title": "g++, bitfields and ADL", "CreationDate": "2016-08-01T19:03:40.640", "LastActivityDate": "2016-08-26T07:11:01.047", "CommentCount": "3", "FavoriteCount": "3", "PostTypeId": "1", "LastEditDate": "2016-08-01T19:24:05.343", "LastEditorUserId": "501557", "Id": "38706287", "Score": "7", "OwnerUserId": "5245033", "Tags": "<c++><argument-dependent-lookup>", "AnswerCount": "1"}});