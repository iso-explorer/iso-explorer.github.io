post_cb({"bq_ids": {"n4140": {"so_24152858_24155873_0": {"length": 42, "quality": 0.875, "section_id": 5787}}, "n3337": {"so_24152858_24155873_0": {"length": 42, "quality": 0.875, "section_id": 5560}}, "n4659": {"so_24152858_24155873_0": {"length": 41, "quality": 0.8541666666666666, "section_id": 7244}}}, "24152922": {"Id": "24152922", "PostTypeId": "2", "Body": "<p>Writing to separate memory locations will work correctly, however 'false sharing' may cause performance problems depending on the patterns of data accesses and the specific architecture.</p>\n<p><a href=\"http://docs.oracle.com/cd/E19205-01/819-5270/aewcy/index.html\" rel=\"nofollow\">Oracle's OpenMP API docs</a> have a good description of false sharing:</p>\n<blockquote>\n<p id=\"so_24152858_24152922_0\">6.2.1 What Is False Sharing?</p>\n<p id=\"so_24152858_24152922_1\">Most high performance processors, such as UltraSPARC processors,\n  insert a cache buffer between slow memory and the high speed registers\n  of the CPU. Accessing a memory location causes a slice of actual\n  memory (a cache line) containing the memory location requested to be\n  copied into the cache. Subsequent references to the same memory\n  location or those around it can probably be satisfied out of the cache\n  until the system determines it is necessary to maintain the coherency\n  between cache and memory.</p>\n<p id=\"so_24152858_24152922_2\">However, simultaneous updates of individual elements in the same cache\n  line coming from different processors invalidates entire cache lines,\n  even though these updates are logically independent of each other.\n  Each update of an individual element of a cache line marks the line as\n  invalid. Other processors accessing a different element in the same\n  line see the line marked as invalid. They are forced to fetch a more\n  recent copy of the line from memory or elsewhere, even though the\n  element accessed has not been modified. This is because cache\n  coherency is maintained on a cache-line basis, and not for individual\n  elements. As a result there will be an increase in interconnect\n  traffic and overhead. Also, while the cache-line update is in\n  progress, access to the elements in the line is inhibited.</p>\n<p id=\"so_24152858_24152922_3\">This situation is called false sharing. If this occurs frequently,\n  performance and scalability of an OpenMP application will suffer\n  significantly.</p>\n<p id=\"so_24152858_24152922_4\">False sharing degrades performance when all of the following\n  conditions occur.</p>\n<ul>\n<li>Shared data is modified by multiple processors.</li>\n<li>Multiple processors update data within the same cache line.</li>\n<li>This updating occurs very frequently (for example, in a tight loop).</li>\n</ul>\n<p id=\"so_24152858_24152922_5\">Note that shared data that is read-only in a loop does not lead to\n  false sharing.</p>\n</blockquote>\n", "LastEditorUserId": "12711", "LastActivityDate": "2014-06-11T06:15:59.097", "Score": "2", "CreationDate": "2014-06-11T00:29:31.863", "ParentId": "24152858", "CommentCount": "1", "OwnerUserId": "12711", "LastEditDate": "2014-06-11T06:15:59.097"}, "24155873": {"Id": "24155873", "PostTypeId": "2", "Body": "<p>Before C++11, the Standard didn't address threading at all.  Now it does.  This rule is found in section 1.7:</p>\n<blockquote>\n<p id=\"so_24152858_24155873_0\">A memory location is either an object of scalar type or a maximal sequence of adjacent bit-\ufb01elds all having non-zero width.  [ Note:  Various features of the language,  such as references and virtual functions,  might involve  additional  memory  locations  that  are  not  accessible  to  programs  but  are  managed  by  the  implementation.  \u2014 end note ] Two or more threads of execution (1.10) can update and access separate memory locations without interfering with each other.</p>\n</blockquote>\n<p>An array is not a scalar, but its elements are.  So each element is a distinct memory location, and therefore distinct elements are eligible for being used by different threads simultaneously with no need for locking or synchronization (as long as at most one thread accessed any given element).</p>\n<p>However, you will cause a great deal of extra work for the cache coherency protocol if data stored in the same cache line are written by different threads.  Consider adding padding, or interchanging data layout so that all variables used by a thread are stored adjacently.  (array of structures instead of structure of arrays)</p>\n", "LastActivityDate": "2014-06-11T06:20:32.320", "CommentCount": "0", "CreationDate": "2014-06-11T06:20:32.320", "ParentId": "24152858", "Score": "1", "OwnerUserId": "103167"}, "24152858": {"ViewCount": "77", "Body": "<p>I have an array of size n and n threads, each i<sup>th</sup> thread can read / write only to i<sup>th</sup> cell of an array. I do not use any memory locks. Is this safe for C++ Boost threads ? How is this related to the cache in the processors, there are stored chunks of memory, not single values.  I guess that cores of processor share cache and there is no duplication of data chunks within cache, therefore when many modification of the same chunk (however on various positions) occurs there is no conflict between versions.</p>\n", "Title": "Is modification of various cells of an array by many threads safe in c++ (boost)", "CreationDate": "2014-06-11T00:19:16.993", "LastActivityDate": "2014-06-11T06:20:32.320", "CommentCount": "3", "LastEditDate": "2014-06-11T00:26:03.097", "PostTypeId": "1", "LastEditorUserId": "1204143", "Id": "24152858", "Score": "2", "OwnerUserId": "155011", "Tags": "<c++><arrays><multithreading><boost>", "AnswerCount": "3"}, "24152882": {"Id": "24152882", "PostTypeId": "2", "Body": "<p>On any modern processor, writing to separate memory locations (even if adjacent) will pose no hazard. Otherwise, threading would be much, much harder.</p>\n<p>Indeed, it is a relatively common idiom to have threads \"fill out\" the elements of an array: this is precisely what typical threaded implementations of linear algebra programs do, for example.</p>\n", "LastActivityDate": "2014-06-11T00:23:09.117", "CommentCount": "1", "CreationDate": "2014-06-11T00:23:09.117", "ParentId": "24152858", "Score": "2", "OwnerUserId": "1204143"}});