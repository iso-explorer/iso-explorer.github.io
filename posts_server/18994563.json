post_cb({"18994637": {"ParentId": "18994563", "PostTypeId": "2", "CommentCount": "15", "Body": "<p>For unsigned integer out-of-range conversion, the result is defined; for signed integers, it's implementation-defined.</p>\n<blockquote>\n<h3>C++11(ISO/IEC 14882:2011) \u00a74.7 Integral conversions  [conv.integral/2]</h3>\n<p id=\"so_18994563_18994637_0\">If the destination type is unsigned, the resulting value is the least unsigned integer congruent to the source integer (modulo 2^n where n is the number of bits used to represent the unsigned type). [ Note: In a two\u2019s complement representation, this conversion is conceptual and there is no change in the bit pattern (if there is no truncation). \u2014end note ]</p>\n<p id=\"so_18994563_18994637_1\">If the destination type is signed, the value is unchanged if it can be represented in the destination type (and bit-field width); otherwise, the value is implementation-defined.</p>\n</blockquote>\n<p>This text remains the same for C++14.</p>\n", "OwnerUserId": "1009479", "LastEditorUserId": "1505939", "LastEditDate": "2017-07-26T01:26:08.190", "Id": "18994637", "Score": "5", "CreationDate": "2013-09-25T01:13:21.270", "LastActivityDate": "2017-07-26T01:26:08.190"}, "45331761": {"ParentId": "18994563", "PostTypeId": "2", "CommentCount": "0", "Body": "<p>The Standard requires that implementations document, somehow, how they will determine what value to use when an integer is converted to a signed type which is too small to accommodate it.  It does not specify the form such documentation will take.  A conforming implementation's documentation could specify in readable print that values will be truncated and two's-complement sign extended, and then in impossibly small print specify \"...except when a program is compiled on the fifth Tuesday of a month, in which case out-of-range conversions will yield the value 24601\".  Such documentation would, of course, be less than helpful, but the Standard does not concern itself with \"quality of implementation\" issues.</p>\n<p>In practice, implementations that define the behavior in any fashion other than 100% consistent truncation and two's-complement sign extension are extremely rare; I would not be particularly surprised if in fact 100% of conforming C99 and C11 implementations that are intended for production code default to working in that fashion.  Unfortunately, neither <code>&lt;limits.h&gt;</code> nor any other standard header defines any means via which implementations can indicate that they follow the essentially-universal convention.</p>\n<p>To be sure, it's unlikely that code which expects the common behavior will be tripped up by the behavior of any conforming compiler.  It's plausible, however, that compilers might offer a non-conforming mode, since that could make certain kinds of code more efficient.  For example, given:</p>\n<pre><code>int32_t x,i;\nint16_t *p;\n...\nx = ++p[i];\n</code></pre>\n<p>If <code>int</code> is larger than 16 bits, behavior would be defined in case <code>p[i]</code> was 32767 before the code executed.  The increment would yield -32768, the value would be converted to <code>int16_t</code> in Implementation-Defined fashion (which is guaranteed to yield -32768 unless an implementation documents something else), and that value would then be stored to both <code>x</code> and <code>p[i]</code>.</p>\n<p>On processors like the ARM which always do arithmetic using 32 bits, truncating the value stored to <code>p[i]</code> would cost nothing, but truncating the value written to <code>x</code> would require an instruction (or, for some older ARM models, two instructions).  Allowing <code>x</code> to receive +32768 in that case would improve efficiency on such processors.  Such an option would not affect the behavior of most programs, but it would be helpful if the Standard defined a means via which code which relied upon behavior could say, e.g.</p>\n<pre><code>#ifdef __STDC_UNUSUAL_INT_TRUNCATION\n#error This code relies upon truncating integer type conversions\n#endif\n</code></pre>\n<p>so that those programs that would be affected could guard against accidental compilation in such modes.  As yet the Standard doesn't define any such test macro.</p>\n", "OwnerUserId": "363751", "LastEditorUserId": "363751", "LastEditDate": "2017-07-26T16:03:46.073", "Id": "45331761", "Score": "1", "CreationDate": "2017-07-26T15:46:13.330", "LastActivityDate": "2017-07-26T16:03:46.073"}, "18994563": {"CommentCount": "4", "ViewCount": "2780", "PostTypeId": "1", "LastEditorUserId": "1505939", "CreationDate": "2013-09-25T01:05:06.210", "LastActivityDate": "2017-07-26T16:03:46.073", "Title": "Is signed to unsigned conversion, and back, defined behaviour for integers?", "OwnerDisplayName": "user334856", "LastEditDate": "2017-07-26T01:21:44.440", "Id": "18994563", "Score": "9", "Body": "<pre><code>#include &lt;cstdint&gt;\n#include &lt;iostream&gt;\n\nint main() {\n  uint32_t i = -64;\n  int32_t j = i;\n\n  std::cout &lt;&lt; j;\n  return 0;\n}\n</code></pre>\n<p>Most compilers I've tried will create programs that output <code>-64</code>, but is this defined behaviour? </p>\n<ul>\n<li>Is the assignment of a signed integer to and unsigned integer <code>uint32_t i = -64;</code> defined behaviour?</li>\n<li>Is the signed integer assignment <code>int32_t j = i;</code>, when <code>i</code> equals <code>4294967232</code>, defined behaviour?</li>\n</ul>\n", "Tags": "<c++><c++11><integer><type-conversion><undefined-behavior>", "AnswerCount": "2"}, "bq_ids": {"n4140": {"so_18994563_18994637_1": {"section_id": 32, "quality": 0.9285714285714286, "length": 13}, "so_18994563_18994637_0": {"section_id": 31, "quality": 0.90625, "length": 29}}, "n3337": {"so_18994563_18994637_1": {"section_id": 29, "quality": 0.9285714285714286, "length": 13}, "so_18994563_18994637_0": {"section_id": 28, "quality": 0.90625, "length": 29}}, "n4659": {"so_18994563_18994637_1": {"section_id": 32, "quality": 0.7857142857142857, "length": 11}, "so_18994563_18994637_0": {"section_id": 31, "quality": 0.90625, "length": 29}}}});