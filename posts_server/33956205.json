post_cb({"33957647": {"ParentId": "33956205", "PostTypeId": "2", "CommentCount": "13", "Body": "<blockquote>\n<p id=\"so_33956205_33957647_0\">Do I need to qualify <code>updateAvailable</code> as <code>volatile</code>?</p>\n</blockquote>\n<p>As <em>volatile</em> doesn't correlate with threading model in C++, you should use atomics for make your program strictly standard-confirmant:</p>\n<p>On <code>C++11</code> or newer <em>preferable</em> way is to use <code>atomic&lt;bool&gt;</code> with <code>memory_order_relaxed</code> store/load:</p>\n<pre><code>atomic&lt;bool&gt; updateAvailable;\n\n//Writer\n....\nupdateAvailable.store(true, std::memory_order_relaxed); //set (under mutex locked)\n\n// Reader\n\nif(updateAvailable.load(std::memory_order_relaxed)) // check\n{\n    ...\n    updateAvailable.store(false, std::memory_order_relaxed); // clear (under mutex locked)\n    ....\n}\n</code></pre>\n<p>gcc since 4.7 supports similar functionality with in its <a href=\"https://gcc.gnu.org/onlinedocs/gcc-4.7.4/gcc/_005f_005fatomic-Builtins.html\" rel=\"nofollow\">atomic builtins</a>.</p>\n<p>As for gcc 4.6, it seems there is not strictly-confirmant way to evade fences when access <code>updateAvailable</code> variable. Actually, memory fence is usually much faster than 10-100ms order of time. So you can use its own <a href=\"https://gcc.gnu.org/onlinedocs/gcc-4.6.4/gcc/Atomic-Builtins.html#Atomic-Builtins\" rel=\"nofollow\">atomic builtins</a>:</p>\n<pre><code>int updateAvailable = 0;\n\n//Writer\n...\n__sync_fetch_and_or(&amp;updateAvailable, 1); // set to non-zero\n....\n\n//Reader\nif(__sync_fetch_and_and(&amp;updateAvailable, 1)) // check, but never change\n{\n    ...\n    __sync_fetch_and_and(&amp;updateAvailable, 0); // clear\n    ...\n}\n</code></pre>\n<blockquote>\n<p id=\"so_33956205_33957647_1\">Is it safe regarding data consistency?</p>\n</blockquote>\n<p>Yes, it is safe. Your reason is absolutely correct here:</p>\n<blockquote>\n<p id=\"so_33956205_33957647_2\">the shared resource is never touched/read in the Reader fast path.</p>\n</blockquote>\n<hr>\n<p><strong>This is NOT double-check locking!</strong></p>\n<p>It is explicitely stated in the question itself.</p>\n<p>In case when <code>updateAvailable</code> is false, <em>Reader</em> thread uses variable <code>myDataCache</code> which is <strong>local</strong> to the thread (no other threads use it). With double-check locking scheme all threads use <em>shared</em> object directly.</p>\n<p><strong>Why memory fences/barriers are NOT NEEDED here</strong></p>\n<p>The only variable, accessed concurrently, is <code>updateAvailable</code>. <code>myData</code> variable is accessed with mutex protection, which provides all needed fences. <code>myDataCache</code> is <strong>local</strong> to the Reader thread.</p>\n<p>When Reader thread sees <code>updateAvailable</code> variable to be <em>false</em>, it uses <code>myDataCache</code> variable, which is changed <strong>by the thread itself</strong>. <em>Program order</em> garantees correct visibility of changes in that case.</p>\n<p>As for visibility garantees for variable <code>updateAvailable</code>, C++11 standard provide such garantees for atomic variable even without fences. 29.3 p13 says:</p>\n<blockquote>\n<p id=\"so_33956205_33957647_3\">Implementations should make atomic stores visible to atomic loads within a reasonable amount of time.</p>\n</blockquote>\n<p>Jonathan Wakely has confirmed, that this paragraph is applied even to <code>memory_order_relaxed</code> accesses <a href=\"http://chat.stackoverflow.com/transcript/message/27204632#27204632\">in chat</a>.</p>\n</hr>", "OwnerUserId": "3440745", "LastEditorUserId": "3440745", "LastEditDate": "2015-12-01T07:59:24.360", "Id": "33957647", "Score": "1", "CreationDate": "2015-11-27T12:39:38.683", "LastActivityDate": "2015-12-01T07:59:24.360"}, "33957562": {"ParentId": "33956205", "CommentCount": "2", "Body": "<p>Use C++ atomics and make <code>updateAvailable</code> an <code>std::atomic&lt;bool&gt;</code>. The reason for this is that it's not just the CPU that can see an old version of the variable but especially the compiler which doesn't see the side effect of another thread and thus never bothers to refetch the variable so you never see the updated value in the thread. Additionally, this way you get a guaranteed atomic read, which you don't have if you just read the value.</p>\n<p>Other than that, you could potentially get rid of the lock, if for example the producer only ever produces data when <code>updateAvailable</code> is false, you can get rid of the mutex because the <code>std::atomic&lt;&gt;</code> enforces proper ordering of the reads and writes. If that's not the case, you'll still need the lock.</p>\n", "OwnerUserId": "350272", "PostTypeId": "2", "Id": "33957562", "Score": "2", "CreationDate": "2015-11-27T12:34:44.480", "LastActivityDate": "2015-11-27T12:34:44.480"}, "33963185": {"ParentId": "33956205", "PostTypeId": "2", "CommentCount": "6", "Body": "<p>You do have to use a memory fence here. Without the fence, there is no guarantee updates will be <strong>ever</strong> seen on the other thread. In C++03 you have the option of either using platform-specific ASM code (<code>mfence</code> on Intel, no idea about ARM) or use OS-provided atomic set/get functions.</p>\n", "OwnerUserId": "5245033", "LastEditorUserId": "5245033", "LastEditDate": "2015-11-27T18:48:53.087", "Id": "33963185", "Score": "2", "CreationDate": "2015-11-27T18:40:34.670", "LastActivityDate": "2015-11-27T18:48:53.087"}, "33956205": {"CommentCount": "17", "CreationDate": "2015-11-27T11:17:08.367", "PostTypeId": "1", "AcceptedAnswerId": "33957647", "LastEditorUserId": "234513", "LastActivityDate": "2015-12-01T07:59:24.360", "LastEditDate": "2015-11-30T17:13:05.443", "ViewCount": "557", "FavoriteCount": "2", "Title": "Do I need a memory barrier for a change notification flag between threads?", "Id": "33956205", "Score": "5", "Body": "<p>I need a very fast (in the sense \"low cost for reader\", not \"low latency\") change notification mechanism between threads in order to update a read cache:</p>\n<p><strong>The situation</strong></p>\n<p>Thread <code>W</code> (Writer) updates a data structure (<code>S</code>) (in my case a setting in a map) only once in a while.</p>\n<p>Thread <code>R</code> (Reader) maintains a cache of <code>S</code> and does read this very frequently. When Thread <code>W</code> updates <code>S</code> Thread <code>R</code> needs to be notified of the update in reasonable time (10-100ms).</p>\n<p>Architecture is ARM, x86 and x86_64. I need to support <code>C++03</code> with gcc 4.6 and higher.</p>\n<p><strong>Code</strong></p>\n<p>is something like this:</p>\n<pre><code>// variables shared between threads\nbool updateAvailable;\nSomeMutex dataMutex;\nstd::string myData;\n\n// variables used only in Thread R\nstd::string myDataCache;\n\n// Thread W\nSomeMutex.Lock();\nmyData = \"newData\";\nupdateAvailable = true;\nSomeMutex.Unlock();\n\n// Thread R\n\nif(updateAvailable)\n{\n    SomeMutex.Lock();\n    myDataCache = myData;\n    updateAvailable = false;\n    SomeMutex.Unlock();\n}\n\ndoSomethingWith(myDataCache);\n</code></pre>\n<p><strong>My Question</strong></p>\n<p>In Thread <code>R</code> no locking or barriers occur in the \"fast path\" (no update available). \nIs this an error? What are the consequences of this design?</p>\n<p>Do I need to qualify <code>updateAvailable</code> as <code>volatile</code>?</p>\n<p>Will <code>R</code> get the update <em>eventually</em>?</p>\n<p><strong>My understanding so far</strong></p>\n<p><em>Is it safe regarding data consistency?</em></p>\n<p>This looks a bit like \"Double Checked Locking\". According to <a href=\"http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html\" rel=\"nofollow\">http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html</a> a memory barrier can be used to fix it in C++.</p>\n<p>However the major difference here is that the shared resource is never touched/read in the Reader fast path. When updating the cache, the consistency is guaranteed by the mutex.</p>\n<p><em>Will <code>R</code> get the update?</em></p>\n<p>Here is where it gets tricky. As I understand it, the CPU running Thread <code>R</code> could cache <code>updateAvailable</code> indefinitely, effectively moving the Read way way before the actual <code>if</code> statement.</p>\n<p>So the update could take until the next cache flush, for example when another thread or process is scheduled.</p>\n", "Tags": "<c++><multithreading><c++03><lock-free>", "OwnerUserId": "234513", "AnswerCount": "3"}, "bq_ids": {"n4140": {"so_33956205_33957647_3": {"section_id": 1159, "quality": 1.0, "length": 11}}, "n3337": {"so_33956205_33957647_3": {"section_id": 1157, "quality": 1.0, "length": 11}}, "n4659": {"so_33956205_33957647_3": {"section_id": 1253, "quality": 1.0, "length": 11}}}});