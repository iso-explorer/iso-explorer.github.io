post_cb({"21350564": {"Id": "21350564", "PostTypeId": "2", "Body": "<p>Memory allocated at compile time simply means there will be no further allocation at run time -- no calls to malloc, new, or other dynamic allocation methods. You'll have a fixed amount of memory usage even if you don't need all of that memory all of the time.</p>\n<blockquote>\n<p id=\"so_21350478_21350564_0\">Isn't memory allocation by definition a runtime concept ?</p>\n</blockquote>\n<p>The memory is not <em>in use</em> prior to run time, but immediately prior to execution starting its allocation is handled by the system.</p>\n<blockquote>\n<p id=\"so_21350478_21350564_1\">If I make a 1KB statically allocated variable in my C/C++ code, will that increase the size of the executable by the same amount ?</p>\n</blockquote>\n<p>Simply declaring the static will not increase the size of your executable more than a few bytes. Declaring it with an initial value that is non-zero will (in order to hold that initial value). Rather, the linker simply adds this 1KB amount to the memory requirement that the system's loader creates for you immediately prior to execution.</p>\n", "LastActivityDate": "2014-01-25T12:32:31.403", "CommentCount": "4", "CreationDate": "2014-01-25T12:32:31.403", "ParentId": "21350478", "Score": "24", "OwnerUserId": "749284"}, "21356682": {"Id": "21356682", "PostTypeId": "2", "Body": "<p>If you learn assembly programming, you will see that you have to carve out segments for the data, the stack, and code, etc. The data segment is where your strings and numbers live. The code segment is where your code lives. These segments are built into the executable program. Of course the stack size is important as well... you wouldn't want a <em>stack overflow</em>!</p>\n<p>So if your data segment is 500 bytes, your program has a 500 byte area. If you change the data segment to 1500 bytes, the size of the program will be 1000 bytes larger. The data is assembled into the actual program.</p>\n<p>This is what is going on when you compile higher level languages. The actual data area is allocated when it is compiled into an executable program, increasing the size of the program. The program can request memory on the fly, as well, and this is dynamic memory. You can request memory from the RAM and the CPU will give it to you to use, you can let go of it, and your garbage collector will release it back to the CPU. It can even be swapped to a hard disk, if necessary, by a good memory manager. These features are what high level languages provide you.</p>\n", "LastEditorUserId": "63550", "LastActivityDate": "2014-01-26T21:06:36.087", "Score": "2", "CreationDate": "2014-01-25T21:48:18.353", "ParentId": "21350478", "CommentCount": "0", "OwnerUserId": "470868", "LastEditDate": "2014-01-26T21:06:36.087"}, "21354303": {"Id": "21354303", "PostTypeId": "2", "Body": "<p>Memory can be allocated in many ways:</p>\n<ul>\n<li>in application heap (whole heap is allocated for your app by OS when the program starts)</li>\n<li>in operating system heap (so you can grab more and more)</li>\n<li>in garbage collector controlled heap (same as both above)</li>\n<li>on stack (so you can get a stack overflow)</li>\n<li>reserved in code/data segment of your binary (executable)</li>\n<li>in remote place (file, network - and you receive a handle not a pointer to that memory)</li>\n</ul>\n<p>Now your question is what is \"memory allocated at compile time\". Definitely it is just an incorrectly phrased saying, which is supposed to refer to either binary segment allocation or stack allocation, or in some cases even to a heap allocation, but in that case the allocation is hidden from programmer eyes by invisible constructor call. Or probably the person who said that just wanted to say that memory is not allocated on heap, but did not know about stack or segment allocations.(Or did not want to go into that kind of detail). </p>\n<p>But in most cases person just wants to say that <strong>the amount of memory being allocated is known at compile time</strong>.</p>\n<p>The binary size will only change when the memory is reserved in the code or data segment of your app.</p>\n", "LastEditorUserId": "1424877", "LastActivityDate": "2014-01-26T07:23:38.023", "Score": "4", "CreationDate": "2014-01-25T18:11:58.413", "ParentId": "21350478", "CommentCount": "1", "OwnerUserId": "1968972", "LastEditDate": "2014-01-26T07:23:38.023"}, "21350543": {"Id": "21350543", "PostTypeId": "2", "Body": "<p>An executable describes what space to allocate for static variables.  This allocation is done by the system, when you run the executable.  So your 1kB static variable won't increase the size of the executable with 1kB:</p>\n<pre><code>static char[1024];\n</code></pre>\n<p>Unless of course you specify an initializer:</p>\n<pre><code>static char[1024] = { 1, 2, 3, 4, ... };\n</code></pre>\n<p>So, in addition to 'machine language' (i.e. CPU instructions), an executable contains a description of the required memory layout.</p>\n", "LastEditorUserId": "1350209", "LastActivityDate": "2014-01-26T04:10:57.640", "Score": "8", "CreationDate": "2014-01-25T12:30:06.563", "ParentId": "21350478", "CommentCount": "0", "OwnerUserId": "1971013", "LastEditDate": "2014-01-26T04:10:57.640"}, "bq_ids": {"n4140": {"so_21350478_21350570_0": {"length": 17, "quality": 0.7727272727272727, "section_id": 3289}}, "n3337": {"so_21350478_21350570_0": {"length": 17, "quality": 0.7727272727272727, "section_id": 3159}}, "n4659": {"so_21350478_21350570_0": {"length": 17, "quality": 0.7727272727272727, "section_id": 4051}}}, "21350570": {"Id": "21350570", "PostTypeId": "2", "Body": "<p>Memory allocated at compile-time means the compiler resolves at compile-time where certain things will be allocated inside the process memory map. </p>\n<p>For example, consider a global array:</p>\n<pre><code>int array[100];\n</code></pre>\n<p>The compiler knows at compile-time the size of the array and the size of an <code>int</code>, so it knows the entire size of the array at compile-time. Also a global variable has static storage duration by default: it is allocated in the static memory area of the process  memory space (.data/.bss section). Given that information, <strong>the compiler decides during compilation in what address of that static memory area the array will be</strong>.</p>\n<p><em>Of course that memory addresses are virtual addresses. The program assumes that it has its own entire memory space (From 0x00000000 to 0xFFFFFFFF for example). That's why the compiler could do assumptions like \"Okay, the array will be at address 0x00A33211\". At runtime that addresses are translated to real/hardware addresses by the MMU and OS.</em></p>\n<p>Value initialized static storage things are a bit different. For example:</p>\n<pre><code>int array[] = { 1 , 2 , 3 , 4 };\n</code></pre>\n<p>In our first example, the compiler only decided where the array will be allocated, storing that information in the executable.<br>\nIn the case of value-initialized things, the compiler also injects the initial value of the array into the executable, and adds code which tells the program loader that after the array allocation at program start, the array should be filled with these values.</br></p>\n<p>Here are two examples of the assembly generated by the compiler (GCC4.8.1 with x86 target):</p>\n<p>C++ code:</p>\n<pre><code>int a[4];\nint b[] = { 1 , 2 , 3 , 4 };\n\nint main()\n{}\n</code></pre>\n<p>Output assembly:</p>\n<pre><code>a:\n    .zero   16\nb:\n    .long   1\n    .long   2\n    .long   3\n    .long   4\nmain:\n    pushq   %rbp\n    movq    %rsp, %rbp\n    movl    $0, %eax\n    popq    %rbp\n    ret\n</code></pre>\n<p>As you can see, the values are directly injected into the assembly. In the array <code>a</code>, the compiler generates a zero initialization of 16 bytes, because the Standard says that static stored things should be initialized to zero by default:</p>\n<blockquote>\n<p id=\"so_21350478_21350570_0\">8.5.9 (Initializers) [Note]:<br>\n  Every object of static storage duration is zero-initialized at\n  program startup before any other initial- ization takes place. In some\n  cases, additional initialization is done later.</br></p>\n</blockquote>\n<p>I always suggest people to disassembly their code to see what the compiler really does with the C++ code. This applies from storage classes/duration (like this question) to advanced compiler optimizations. You could instruct your compiler to generate the assembly, but there are wonderful tools to do this on the Internet in a friendly manner. My favourite is <a href=\"http://gcc.godbolt.org/\">GCC Explorer</a>.</p>\n", "LastEditorUserId": "1155000", "LastActivityDate": "2014-01-28T23:39:41.880", "Score": "161", "CreationDate": "2014-01-25T12:33:23.507", "ParentId": "21350478", "CommentCount": "28", "OwnerUserId": "1609356", "LastEditDate": "2014-01-28T23:39:41.880"}, "21350478": {"ViewCount": "24268", "Body": "<p>In programming languages like C and C++, people often refer to static and dynamic memory allocation. I understand the concept but the phrase \"All memory was allocated (reserved) during compile time\" always confuses me.</p>\n<p>Compilation, as I understand it, converts high level C/C++ code to machine language and outputs an executable file. How is memory \"allocated\" in a compiled file ? Isn't memory always allocated in the RAM with all the virtual memory management stuff ? </p>\n<p>Isn't memory allocation by definition a runtime concept ?</p>\n<p>If I make a 1KB statically allocated variable in my C/C++ code, will that increase the size of the executable by the same amount ?</p>\n<p>This is one of the pages where the phrase is used under the heading \"Static allocation\". </p>\n<p><a href=\"http://blogs.msdn.com/b/abhinaba/archive/2009/01/16/back-to-basics-memory-allocation-a-walk-down-the-history.aspx\">Back To Basics: Memory allocation, a walk down the history</a></p>\n", "AcceptedAnswerId": "21350570", "Title": "What does \"Memory allocated at compile time\" really mean?", "CreationDate": "2014-01-25T12:24:05.513", "Id": "21350478", "CommentCount": "1", "FavoriteCount": "54", "PostTypeId": "1", "LastEditDate": "2014-03-05T08:32:00.560", "LastEditorUserId": "1251376", "LastActivityDate": "2015-04-20T13:18:33.993", "Score": "127", "OwnerUserId": "1592638", "Tags": "<c++><c><memory><memory-management><terminology>", "AnswerCount": "12"}, "21355609": {"Id": "21355609", "PostTypeId": "2", "Body": "<p>The core of your question is this: \"How is memory \"allocated\" in a compiled file? Isn't memory always allocated in the RAM with all the virtual memory management stuff? Isn't memory allocation by definition a runtime concept?\"</p>\n<p>I think the problem is that there are two different concepts involved in memory allocation.  At its basic, memory allocation is the process by which we say \"this item of data is stored in this specific chunk of memory\". In a modern computer system, this involves a two step process:</p>\n<ul>\n<li>Some system is used to decide the virtual address at which the item will be stored</li>\n<li>The virtual address is mapped to a physical address</li>\n</ul>\n<p>The latter process is purely run time, but the former can be done at compile time, if the data have a known size and a fixed number of them is required. Here's basically how it works:</p>\n<ul>\n<li><p>The compiler sees a source file containing a line that looks a bit like this:</p>\n<pre><code>int c;\n</code></pre></li>\n<li><p>It produces output for the assembler that instructs it to reserve memory for the variable 'c'.  This might look like this:</p>\n<pre><code>global _c\nsection .bss\n_c: resb 4\n</code></pre></li>\n<li><p>When the assembler runs, it keeps a counter that tracks offsets of each item from the start of a memory 'segment' (or 'section'). This is like the parts of a very large 'struct' that contains everything in the entire file it doesn't have any actual memory allocated to it at this time, and could be anywhere. It notes in a table that <code>_c</code> has a particular offset (say 510 bytes from the start of the segment) and then increments its counter by 4, so the next such variable will be at (e.g.) 514 bytes. For any code that needs the address of <code>_c</code>, it just puts 510 in the output file, and adds a note that the output needs the address of the segment that contains <code>_c</code> adding to it later.</p></li>\n<li><p>The linker takes all of the assembler's output files, and examines them. It determines an address for each segment so that they won't overlap, and adds the offsets necessary so that instructions still refer to the correct data items.  In the case of uninitialized memory like that occupied by <code>c</code> (the assembler was told that the memory would be uninitialized by the fact that the compiler put it in the '.bss' segment, which is a name reserved for uninitialized memory), it includes a header field in its output that tells the operating system how much needs to be reserved. It may be relocated (and usually is) but is usually designed to be loaded more efficiently at one particular memory address, and the OS will try to load it at this address. At this point, we have a pretty good idea what the virtual address is that will be used by <code>c</code>.</p></li>\n<li><p>The physical address will not actually be determined until the program is running. However, from the programmer's perspective the physical address is actually irrelevant\u2014we'll never even find out what it is, because the OS doesn't usually bother telling anyone, it can change frequently (even while the program is running), and a main purpose of the OS is to abstract this away anyway.</p></li>\n</ul>\n", "LastEditorUserId": "441899", "LastActivityDate": "2014-01-26T05:27:27.397", "Score": "11", "CreationDate": "2014-01-25T20:06:11.007", "ParentId": "21350478", "CommentCount": "0", "OwnerUserId": "441899", "LastEditDate": "2014-01-26T05:27:27.397"}, "21356026": {"Id": "21356026", "PostTypeId": "2", "Body": "<p>I think you need to step back a bit.  Memory allocated at compile time....  What can that mean?  Can it mean that memory on chips that have not yet been manufactured, for computers that have not yet been designed, is somehow being reserved?  No.  No, time travel, no compilers that can manipulate the universe.</p>\n<p>So, it must mean that the compiler generates instructions to allocate that memory somehow at runtime.  But if you look at it in from the right angle, the compiler generates all instructions, so what can be the difference.  The difference is that the compiler decides, and at runtime, your code can not change or modify its decisions.  If it decided it needed 50 bytes at compile time, at runtime, you can't make it decide to allocate 60 -- that decision has already been made.</p>\n", "LastEditorUserId": "234954", "LastActivityDate": "2014-01-25T23:17:29.027", "Score": "2", "CreationDate": "2014-01-25T20:45:00.297", "ParentId": "21350478", "CommentCount": "4", "OwnerUserId": "234954", "LastEditDate": "2014-01-25T23:17:29.027"}, "21350583": {"Id": "21350583", "PostTypeId": "2", "Body": "<p>Memory allocated in compile time means that when you load the program, some part of the memory will be immediately allocated and the size and (relative) position of this allocation is determined at compile time.</p>\n<pre><code>char a[32];\nchar b;\nchar c;\n</code></pre>\n<p>Those 3 variables are \"allocated at compile time\", it means that the compiler calculates their size (which is fixed) at compile time. The variable <code>a</code> will be an offset in memory, let's say, pointing to address 0, <code>b</code> will point at address 33 and <code>c</code> at 34 (supposing no alignment optimization). So, <em>allocating 1Kb of static data will not increase the size of your code</em>, since it will just change an offset inside it. <em>The actual space will be allocated at load time</em>.</p>\n<p>Real memory allocation always happens in run time, because the kernel needs to keep track of it and to update its internal data structures (how much memory is allocated for each process, pages and so on). The difference is that the compiler already knows the size of each data you are going to use and this is allocated as soon as your program is executed.</p>\n<p>Remember also that we are talking about <em>relative addresses</em>. The real address where the variable will be located will be different. At load time the kernel will reserve some memory for the process, lets say at address <code>x</code>, and all the hard coded addresses contained in the executable file will be incremented by <code>x</code> bytes, so that variable <code>a</code> in the example will be at address <code>x</code>, b at address <code>x+33</code> and so on.</p>\n", "LastEditorUserId": "1025899", "LastActivityDate": "2014-01-26T18:04:11.610", "Score": "17", "CreationDate": "2014-01-25T12:34:18.737", "ParentId": "21350478", "CommentCount": "1", "OwnerUserId": "1025899", "LastEditDate": "2014-01-26T18:04:11.610"}, "21354626": {"Id": "21354626", "PostTypeId": "2", "Body": "<p>On many platforms, all of the global or static allocations within each module will be consolidated by the compiler into three or fewer consolidated allocations (one for uninitialized data (often called \"bss\"), one for initialized writable data (often called \"data\"), and one for constant data (\"const\")), and all of the global or static allocations of each type within a program will be consolidated by the linker into one global for each type.  For example, assuming <code>int</code> is four bytes, a module has the following as its only static allocations:</p>\n<pre><code>int a;\nconst int b[6] = {1,2,3,4,5,6};\nchar c[200];\nconst int d = 23;\nint e[4] = {1,2,3,4};\nint f;\n</code></pre>\n<p>it would tell the linker that it needed 208 bytes for bss, 16 bytes for \"data\", and 28 bytes for \"const\".  Further, any reference to a variable would be replaced with an area selector and offset, so a, b, c, d, and e, would be replaced by bss+0, const+0, bss+4, const+24, data+0, or bss+204, respectively.</p>\n<p>When a program is linked, all of the bss areas from all the modules are be concatenated together; likewise the data and const areas.  For each module, the address of any bss-relative variables will be increased by the size of all preceding modules' bss areas (again, likewise with data and const).  Thus, when the linker is done, any program will have one bss allocation, one data allocation, and one const allocation.</p>\n<p>When a program is loaded, one of four things will generally happen depending upon the platform:</p>\n<ol>\n<li><p>The executable will indicate how many bytes it needs for each kind of data and--for the initialized data area, where the initial contents may be found.  It will also include a list of all the instructions which use a bss-, data-, or const- relative address.  The operating system or loader will allocate the appropriate amount of space for each area and then add the starting address of that area to each instruction which needs it.</p></li>\n<li><p>The operating system will allocate a chunk of memory to hold all three kinds of data, and give the application a pointer to that chunk of memory.  Any code which uses static or global data will dereference it relative to that pointer (in many cases, the pointer will be stored in a register for the lifetime of an application).</p></li>\n<li><p>The operating system will initially not allocate any memory to the application, except for what holds its binary code, but the first thing the application does will be to request a suitable allocation from the operating system, which it will forevermore keep in a register.</p></li>\n<li><p>The operating system will initially not allocate space for the application, but the application will request a suitable allocation on startup (as above).  The application will include a list of instructions with addresses that need to be updated to reflect where memory was allocated (as with the first style), but rather than having the application patched by the OS loader, the application will include enough code to patch itself.</p></li>\n</ol>\n<p>All four approaches have advantages and disadvantages.  In every case, however, the compiler will consolidate an arbitrary number of static variables into a fixed small number of memory requests, and the linker will consolidate all of those into a small number of consolidated allocations.  Even though an application will have to receive a chunk of memory from the operating system or loader, it is the compiler and linker which are responsible for allocating individual pieces out of that big chunk to all the individual variables that need it.</p>\n", "LastEditorUserId": "363751", "LastActivityDate": "2015-04-20T13:18:33.993", "Score": "13", "CreationDate": "2014-01-25T18:38:34.587", "ParentId": "21350478", "CommentCount": "0", "OwnerUserId": "363751", "LastEditDate": "2015-04-20T13:18:33.993"}, "21351578": {"Id": "21351578", "PostTypeId": "2", "Body": "<p>You are right. Memory is actually allocated (paged) at load time, i.e. when the executable file is brought into (virtual) memory. Memory can also be initialized on that moment. The compiler just creates memory map. [By the way, stack and heap spaces are also allocated at load time !]</p>\n", "LastEditorUserId": "1275574", "LastActivityDate": "2014-01-25T17:05:26.757", "Score": "3", "CreationDate": "2014-01-25T14:10:36.400", "ParentId": "21350478", "CommentCount": "0", "OwnerUserId": "1196549", "LastEditDate": "2014-01-25T17:05:26.757"}, "21350680": {"Id": "21350680", "PostTypeId": "2", "Body": "<p>Adding variables on the stack that take up N bytes doesn't (necessarily) increase the bin's size by N bytes. It will, in fact, add but a few bytes most of the time.<br>\nLet's start off with an example of how adding a 1000 chars to your code <em>will</em> increase the bin's size in a linear fashion.</br></p>\n<p>If the 1k is a string, of a thousand chars, which is declared like so</p>\n<pre><code>const char *c_string = \"Here goes a thousand chars...999\";//implicit \\0 at end\n</code></pre>\n<p>and you then were to <code>vim your_compiled_bin</code>, you'd actually be able to see that string in the bin somewhere. In that case, yes: the executable will be 1 k bigger, because it contains the string in full.<br>\nIf, however you allocate an array of <code>int</code>s, <code>char</code>s or <code>long</code>s on the stack and assign it in a loop, something along these lines</br></p>\n<pre><code>int big_arr[1000];\nfor (int i=0;i&lt;1000;++i) big_arr[i] = some_computation_func(i);\n</code></pre>\n<p>then, no: it won't increase the bin... by <code>1000*sizeof(int)</code><br>\nAllocation at compile time means what you've now come to understand it means (based on your comments): the compiled bin contains information the system requires to know how much memory what function/block will need  when it gets executed, along with information on the stack size your application requires. That's what the system will allocate when it executes your bin, and your program becomes a process (well, the executing of your bin is the process that... well, you get what I'm saying).<br>\nOf course, I'm not painting the full picture here: The bin contains information about how big a stack the bin will actually be needing. Based on this information (among other things), the system will reserve a chunk of memory, called the stack, that the program gets sort of free reign over. Stack memory still is allocated by the system, when the process (the result of your bin being executed) is initiated. The process then manages the stack memory for you. When a function or loop (any type of block) is invoked/gets executed, the variables local to that block are pushed to the stack, and they are removed (the stack memory is <em>\"freed\"</em> so to speak) to be used by other functions/blocks. So declaring <code>int some_array[100]</code> will only add a few bytes of additional information to the bin, that tells the system that function X will be requiring <code>100*sizeof(int)</code> + some book-keeping space extra.</br></br></p>\n", "LastEditorUserId": "1230836", "LastActivityDate": "2014-01-29T15:01:09.407", "Score": "15", "CreationDate": "2014-01-25T12:45:32.343", "ParentId": "21350478", "CommentCount": "9", "OwnerUserId": "1230836", "LastEditDate": "2014-01-29T15:01:09.407"}, "21496588": {"Id": "21496588", "PostTypeId": "2", "Body": "<p>I would like to explain these concepts with the help of few diagrams.</p>\n<p>This is true that memory cannot be allocated at compile time, for sure.\nBut, then what happens in fact at compile time.</p>\n<p>Here comes the explanation.\nSay, for example a program has four variables x,y,z and k.\nNow, at compile time it simply makes a memory map, where the location of these variables with respect to each other is ascertained.\nThis diagram will illustrate it better.</p>\n<p>Now imagine, no program is running in memory.\nThis I show by a big empty rectangle.</p>\n<p><img alt=\"empty field\" src=\"https://i.stack.imgur.com/6OTAC.png\"/></p>\n<p>Next, the first instance of this program is executed.\nYou can visualize it as follows.\nThis is the time when actually memory is allocated.</p>\n<p><img alt=\"first instance\" src=\"https://i.stack.imgur.com/pw2Aa.png\"/></p>\n<p>When second instance of this program is running, the memory would look like as follows.</p>\n<p><img alt=\"second instance\" src=\"https://i.stack.imgur.com/EwkFI.png\"/></p>\n<p>And the third ..</p>\n<p><img alt=\"third instance\" src=\"https://i.stack.imgur.com/vXb2f.png\"/></p>\n<p>So on and so forth.</p>\n<p>I hope this visualization explains this concept well.</p>\n", "LastActivityDate": "2014-02-01T09:59:24.933", "CommentCount": "3", "CreationDate": "2014-02-01T09:59:24.933", "ParentId": "21350478", "Score": "2", "OwnerUserId": "3258051"}});