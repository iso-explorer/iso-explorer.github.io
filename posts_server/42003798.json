post_cb({"42003798": {"ViewCount": "206", "Body": "<p>Suppose I wanted to copy the contents of a device register into a variable that would be read by multiple threads.  Is there a good general way of doing this?  Here are examples of two possible methods of doing this:</p>\n<pre><code>#include &lt;atomic&gt;\n\nvolatile int * const Device_reg_ptr = reinterpret_cast&lt;int *&gt;(0x666);\n\n// This variable is read by multiple threads.\nstd::atomic&lt;int&gt; device_reg_copy;\n\n// ...\n\n// Method 1\nconst_cast&lt;volatile std::atomic&lt;int&gt; &amp;&gt;(device_reg_copy)\n  .store(*Device_reg_ptr, std::memory_order_relaxed);\n\n// Method 2\ndevice_reg_copy.store(*Device_reg_ptr, std::memory_order_relaxed);\nstd::atomic_thread_fence(std::memory_order_release);\n</code></pre>\n<p>More generally, in the face of possible whole program optimization, how does one correctly control the latency of memory writes in one thread being visible in other threads?</p>\n<p>EDIT:  In your answer, please consider the following scenario:</p>\n<ul>\n<li>The code is running on a CPU in an embedded system.</li>\n<li>A single application is running on the CPU.</li>\n<li>The application has far fewer threads than the CPU has processor cores.</li>\n<li>Each core has a massive number of registers.</li>\n<li>The application is small enough that whole program optimization is successfully used when building its executable.</li>\n</ul>\n<p>How do we make sure that a store in one thread does not remain invisible to other threads indefinitely?</p>\n", "Title": "How do I make memory stores in one thread \"promptly\" visible in other threads?", "CreationDate": "2017-02-02T13:43:22.737", "LastActivityDate": "2017-02-02T20:05:16.577", "CommentCount": "6", "LastEditDate": "2017-02-02T16:46:04.537", "PostTypeId": "1", "LastEditorUserId": "2793551", "Id": "42003798", "Score": "1", "OwnerUserId": "2793551", "Tags": "<c++><multithreading><c++11><atomic><stdatomic>", "AnswerCount": "2"}, "bq_ids": {"n4140": {"so_42003798_42011343_0": {"length": 11, "quality": 0.9166666666666666, "section_id": 1159}}, "n3337": {"so_42003798_42011343_0": {"length": 11, "quality": 0.9166666666666666, "section_id": 1157}}, "n4659": {"so_42003798_42011343_0": {"length": 11, "quality": 0.9166666666666666, "section_id": 1253}}}, "42004151": {"Id": "42004151", "PostTypeId": "2", "Body": "<p>If you would like to update the value of <code>device_reg_copy</code> in atomic fashion, then <code>device_reg_copy.store(*Device_reg_ptr, std::memory_order_relaxed);</code> suffices. </p>\n<p>There is no need to apply <code>volatile</code> to atomic variables, it is unnecessary.</p>\n<p><code>std::memory_order_relaxed</code> store is supposed to incur the least amount of synchronization overhead. On x86 it is just a plain <code>mov</code> instruction.</p>\n<p>However, if you would like to update it in such a way, that the effects of any <em>preceding</em> stores become visible to other threads along with the new value of <code>device_reg_copy</code>, then use <code>std::memory_order_release</code> store, i.e. <code>device_reg_copy.store(*Device_reg_ptr, std::memory_order_release);</code>. The readers need to load <code>device_reg_copy</code> as <code>std::memory_order_acquire</code> in this case. Again, on x86 <code>std::memory_order_release</code> store is a plain <code>mov</code>.</p>\n<p>Whereas if you use the most expensive <code>std::memory_order_seq_cst</code> store, it does insert the memory barrier for you on x86.</p>\n<p>This is why they say that x86 memory model is a bit too strong for C++11: plain <code>mov</code> instruction is <code>std::memory_order_release</code> on stores and <code>std::memory_order_acquire</code> on loads. There is no <em>relaxed</em> store or load on x86.</p>\n<p>I cannot recommend enough <a href=\"https://mechanical-sympathy.blogspot.co.uk/2013/02/cpu-cache-flushing-fallacy.html\" rel=\"nofollow noreferrer\">CPU Cache Flushing Fallacy</a> article.</p>\n", "LastEditorUserId": "412080", "LastActivityDate": "2017-02-02T14:24:18.270", "Score": "2", "CreationDate": "2017-02-02T14:00:18.750", "ParentId": "42003798", "CommentCount": "0", "OwnerUserId": "412080", "LastEditDate": "2017-02-02T14:24:18.270"}, "42011343": {"Id": "42011343", "PostTypeId": "2", "Body": "<p>The C++ standard is rather vague about making atomic stores visible  to other threads..</p>\n<blockquote>\n<p id=\"so_42003798_42011343_0\">29.3.12\n  Implementations <em>should</em> make atomic stores visible to atomic loads within a reasonable amount of time.</p>\n</blockquote>\n<p>That is as detailed as it gets, there is no definition of 'reasonable', and it does not have to be immediately.  </p>\n<p>Using a stand-alone fence to force a certain memory ordering is not necessary since you can specify those on atomic operations, but the question is,\nwhat is your expectation with regards to using a memory fence..<br>\nFences are designed to enforce ordering on memory operations (between threads), but they do not guarantee visibility in a <em>timely</em> manner.\nYou can store a value to an atomic variable with the strongest memory ordering (ie. <code>seq_cst</code>), but even when another thread executes <code>load()</code> at a later time than the <code>store()</code>,\nyou might still get an old value from the cache and yet (surprisingly) it does <em>not</em> violate the <em>happens-before</em> relationship.\nUsing a stronger fence <em>might</em> make a difference wrt. timing and visibility, but there are no guarantees.</br></p>\n<p>If prompt visibility is important, I would consider using a Read-Modify-Write (RMW) operation to load the value.\nThese are atomic operations that read and modify atomically (ie. in a single call), and have the additional property that they are guaranteed to operate on the latest value.\nBut since they have to reach a little further than the local cache, these calls also tend to be more expensive to execute.</p>\n<p>As pointed out by Maxim Egorushkin, whether or not you can use weaker memory orderings than the default (<code>seq_cst</code>) depends on whether other memory operations need to be synchronized (made visible) between threads.\nThat is not clear from your question, but it is generally considered safe to use the default (sequential consistency).<br>\nIf you are on an unusually weak platform, if performance is problematic, and if you need data synchronization between threads, you could consider using acquire/release semantics:</br></p>\n<pre><code>// thread 1\ndevice_reg_copy.store(*Device_reg_ptr, std::memory_order_release);\n\n\n// thread 2\ndevice_reg_copy.fetch_add(0, std::memory_order_acquire);\n</code></pre>\n<p><em>If</em> thread 2 sees the value written by thread 1, it is guaranteed that memory operations prior to the store in thread 1 are visible after the load in thread 2.\nAcquire/Release operations form a pair and they synchronize based on a run-time relationship between the store and load. In other words, if thread 2 does not see the value stored by thread 1,\nthere are no ordering guarantees.</p>\n<p>If the atomic variable has no dependencies on any other data, you can use <code>std::memory_order_relaxed</code>; store ordering is always guaranteed for a single atomic variable.</p>\n<p>As mentioned by others, there is no need for <code>volatile</code> when it comes to inter-thread communication with <code>std::atomic</code>.</p>\n", "LastActivityDate": "2017-02-02T20:05:16.577", "CommentCount": "0", "CreationDate": "2017-02-02T20:05:16.577", "ParentId": "42003798", "Score": "0", "OwnerUserId": "6651824"}});