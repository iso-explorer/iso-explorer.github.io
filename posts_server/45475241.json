post_cb({"45476880": {"ParentId": "45475241", "CommentCount": "1", "CreationDate": "2017-08-03T06:51:42.930", "OwnerUserId": "4442671", "PostTypeId": "2", "Id": "45476880", "Score": "0", "Body": "<p>The answer seem to lie in <a href=\"http://eel.is/c++draft/intro.multithread#intro.races-3\" rel=\"nofollow noreferrer\">http://eel.is/c++draft/intro.multithread#intro.races-3</a></p>\n<p>The two pertinent parts are</p>\n<blockquote>\n<p id=\"so_45475241_45476880_0\">[...] In addition, there are relaxed atomic operations, which are not synchronization operations [...]</p>\n</blockquote>\n<p>and</p>\n<blockquote>\n<p id=\"so_45475241_45476880_1\">[...] performing a release operation on A forces prior side effects on other memory locations to become visible to other threads that later perform a consume or an acquire operation on A. [...]</p>\n</blockquote>\n<p>While relaxed orders atomics are not considered synchronization operations, that's all the standard has to say about them in this context. Since they are still memory locations, the general rule of them being governed by <strong>other</strong> synchronization operations still applies.</p>\n<p>So in conclusion, the standard does not seem to have anything specifically in there to prevent the reordering you described, but the wording as it stands would prevent it naturally.</p>\n<p><strong>Edit:</strong> Woops, I linked to the draft. The C++11 paragraph covering this is 1.10-5, using the same language.</p>\n", "LastActivityDate": "2017-08-03T06:51:42.930"}, "45502571": {"ParentId": "45475241", "PostTypeId": "2", "CommentCount": "1", "CreationDate": "2017-08-04T09:03:15.607", "Score": "0", "LastEditorUserId": "4213662", "LastEditDate": "2017-08-04T10:12:39.517", "Id": "45502571", "OwnerUserId": "4213662", "Body": "<p><code>CheckFoo()</code> cannot cause the program to crash (i.e. trigger the <code>assert()</code>) but there is also no guarantee the <code>assert()</code> will ever be executed.</p>\n<p>If the condition at the start of <code>CheckFoo()</code> triggers (see below) the visible value of <code>foo</code> will be 1 because of the memory barriers and synchronization between <code>mu.unlock()</code> in <code>SetFoo()</code> and <code>mu.lock()</code> in <code>CheckFoo()</code>.</p>\n<p>I believe that is covered by the description of mutex cited in other answers. </p>\n<p>However there is no guarantee that the if condition (<code>foo_has_been_set.load(std::memory_order_relaxed))</code>) will ever be true.\nRelaxed memory order makes no guarantees and only the atomicity of the operation is assured. Consequently in the absence of some other barrier there's no guarantee when the relaxed store in <code>SetFoo()</code> will be visible in <code>CheckFoo()</code> but if it is visible it will only be because the store was executed and then following the <code>mu.lock()</code> must be ordered after <code>mu.unlock()</code> and the writes before it visible.</p>\n<p>Please note this argument relies on the fact that <code>foo_has_been_set</code> is only ever set from <code>false</code> to <code>true</code>. If there were another function called <code>UnsetFoo()</code> that set it back to false:</p>\n<pre><code>void SetFoo() {\n  mu.lock();\n  foo = 0;\n  foo_has_been_set.store(false, std::memory_order_relaxed);\n  mu.unlock();\n}\n</code></pre>\n<p>That was called from the other (or yet a third) thread then there's no guarantee that checking <code>foo_has_been_set</code> without synchronization will guarantee that <code>foo</code> is set.</p>\n<p>To be clear (and assuming <code>foo_has_been_set</code> is never unset):</p>\n<pre><code>void CheckFoo() {\n  if (foo_has_been_set.load(std::memory_order_relaxed)) {\n    assert(foo == 1); //&lt;- All bets are off.\n    mu.lock();\n    assert(foo == 1); //Guaranteed to succeed.\n    mu.unlock();\n  }\n}\n</code></pre>\n<p>In practice on any real platform on any long running application it is probably inevitable that the relax store will eventually become visible to the other thread. But there is no formal guarantee regarding if or when that will happen unless other barriers exist to assure it.</p>\n<p>Formal References:</p>\n<p><a href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3690.pdf\" rel=\"nofollow noreferrer\">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3690.pdf</a></p>\n<p>Refer to the notes at the end of p.13 and start of p.14 particularly notes 17 - 20. They are essentially assuring coherence of 'relaxed' operations. Their visibility is relaxed but the visibility that occurs will be coherent and use of the phrase 'happens before' is within the overall principle of program ordering and particularly acquire and release barriers of mutexes.\nNote 19 is particularly relevant:</p>\n<blockquote>\n<p id=\"so_45475241_45502571_0\">The four preceding coherence requirements effectively disallow\n  compiler reordering of atomic operations to a single object, even if\n  both operations are relaxed loads. This effectively makes the cache\n  coherence guarantee provided by most hardware available to C++ atomic\n  operations.</p>\n</blockquote>\n", "LastActivityDate": "2017-08-04T10:12:39.517"}, "45475241": {"CommentCount": "0", "AcceptedAnswerId": "45498508", "CreationDate": "2017-08-03T05:04:11.193", "LastActivityDate": "2017-08-07T05:11:36.420", "PostTypeId": "1", "ViewCount": "429", "FavoriteCount": "1", "Title": "C++ standard: can relaxed atomic stores be lifted above a mutex lock?", "Id": "45475241", "Score": "13", "Body": "<p>Is there any wording in the standard that guarantees that relaxed stores to atomics won't be lifted above the locking of a mutex? If not, is there any wording that explicitly says that it's kosher for the compiler or CPU to do so?</p>\n<p>For example, take the following program:</p>\n<pre><code>std::mutex mu;\nint foo = 0;  // Guarded by mu\nstd::atomic&lt;bool&gt; foo_has_been_set{false};\n\nvoid SetFoo() {\n  mu.lock();\n  foo = 1;\n  foo_has_been_set.store(true, std::memory_order_relaxed);\n  mu.unlock();\n}\n\nvoid CheckFoo() {\n  if (foo_has_been_set.load(std::memory_order_relaxed)) {\n    mu.lock();\n    assert(foo == 1);\n    mu.unlock();\n  }\n}\n</code></pre>\n<p>Is it possible for <code>CheckFoo</code> to crash in the above program if another thread is calling <code>SetFoo</code> concurrently, or is there some guarantee that the store to <code>foo_has_been_set</code> can't be lifted above the call to <code>mu.lock</code> by the compiler and CPU?</p>\n<p>This is related to <a href=\"https://stackoverflow.com/q/24901772/1505451\">an older question</a>, but it's not 100% clear to me that the answer there applies to this. In particular, the counter-example in that question's answer may apply to two concurrent calls to <code>SetFoo</code>, but I'm interested in the case where the compiler knows that there is one call to <code>SetFoo</code> and one call to <code>CheckFoo</code>. Is that guaranteed to be safe?</p>\n<p>I'm looking for specific citations in the standard. Thank you!</p>\n", "Tags": "<c++><atomic><memory-model>", "OwnerUserId": "1505451", "AnswerCount": "5"}, "45477313": {"ParentId": "45475241", "PostTypeId": "2", "CommentCount": "9", "CreationDate": "2017-08-03T07:15:15.817", "Score": "1", "LastEditorUserId": "6651824", "LastEditDate": "2017-08-03T07:20:23.450", "Id": "45477313", "OwnerUserId": "6651824", "Body": "<p>No memory operation inside a mutex protected region can 'escape' from that area. That applies to all memory operations, atomic and non-atomic.</p>\n<p>In section 1.10.1:</p>\n<blockquote>\n<p id=\"so_45475241_45477313_0\">a call that acquires a mutex will perform an acquire operation on the locations comprising the mutex\n  Correspondingly, a call that releases the same mutex will perform a release operation on those same locations</p>\n</blockquote>\n<p>Furthermore, in section 1.10.1.6:</p>\n<blockquote>\n<p id=\"so_45475241_45477313_1\">All operations on a given mutex occur in a single total order. Each mutex acquisition \u201creads the value written\u201d by the last mutex release.</p>\n</blockquote>\n<p>And in 30.4.3.1</p>\n<blockquote>\n<p id=\"so_45475241_45477313_2\">A mutex object facilitates protection against data races and allows safe synchronization of data between execution agents</p>\n</blockquote>\n<p>This means, acquiring (locking) a mutex sets a one-way barrier that prevents operations that are sequenced after the acquire (inside the protected area) from moving up across the mutex lock.</p>\n<p>Releasing (unlocking) a mutex sets a one-way barrier that prevents operations that are sequenced before the release (inside the protected area) from moving down across the mutex unlock.</p>\n<p>In addition, memory operations that are released by a mutex are synchronized (visible) with another thread that acquires the same mutex.  </p>\n<p>In your example, <code>foo_has_been_set</code> is checked in <code>CheckFoo</code>.. If it reads <code>true</code> you know that the value 1 has been assigned to <code>foo</code> by <code>SetFoo</code>, but it is not synchronized yet.\nThe mutex lock that follows will acquire <code>foo</code>, synchronization is complete and the assert cannot fire.</p>\n", "LastActivityDate": "2017-08-03T07:20:23.450"}, "45498508": {"ParentId": "45475241", "PostTypeId": "2", "CommentCount": "7", "CreationDate": "2017-08-04T04:54:13.023", "Score": "5", "LastEditorUserId": "1505451", "LastEditDate": "2017-08-06T10:41:10.547", "Id": "45498508", "OwnerUserId": "1505451", "Body": "<p>I think I've figured out the particular partial order edges that guarantee the\nprogram can't crash. In the answer below I'm referencing <a href=\"https://timsong-cpp.github.io/cppwp/n4659/\" rel=\"nofollow noreferrer\">version\nN4659</a> of the draft standard.</p>\n<p>The code involved for the writer thread A and reader thread B is:</p>\n<pre><code>A1: mu.lock()\nA2: foo = 1\nA3: foo_has_been_set.store(relaxed)\nA4: mu.unlock()\n\nB1: foo_has_been_set.load(relaxed) &lt;-- (stop if false)\nB2: mu.lock()\nB3: assert(foo == 1)\nB4: mu.unlock()\n</code></pre>\n<p>We seek a proof that if B3 executes, then A2 happens before B3, as defined in <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#10\" rel=\"nofollow noreferrer\">[intro.races]/10</a>. By <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#10.2\" rel=\"nofollow noreferrer\">[intro.races]/10.2</a>, it's sufficient to prove that A2 inter-thread happens\nbefore B3.</p>\n<p>Because lock and unlock operations on a given mutex happen in a single total\norder (<a href=\"https://timsong-cpp.github.io/cppwp/n4659/thread#mutex.requirements.mutex-5\" rel=\"nofollow noreferrer\">[thread.mutex.requirements.mutex]/5</a>), we must have either A1 or B2\ncoming first. The two cases:</p>\n<ol>\n<li><p>Assume that A1 happens before B2. Then by <a href=\"https://timsong-cpp.github.io/cppwp/n4659/thread#mutex.class-1\" rel=\"nofollow noreferrer\">[thread.mutex.class]/1</a> and\n<a href=\"https://timsong-cpp.github.io/cppwp/n4659/thread#mutex.requirements.mutex-25\" rel=\"nofollow noreferrer\">[thread.mutex.requirements.mutex]/25</a>, we know that A4 will synchronize with B2.\nTherefore by <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#9.1\" rel=\"nofollow noreferrer\">[intro.races]/9.1</a>, A4 inter-thread happens before B2. Since B2 is\nsequenced before B3, by <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#9.3.1\" rel=\"nofollow noreferrer\">[intro.races]/9.3.1</a> we know that A4 inter-thread\nhappens before B3. Since A2 is sequenced before A4, by <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#9.3.2\" rel=\"nofollow noreferrer\">[intro.races]/9.3.2</a>, A2\ninter-thread happens before B3.</p></li>\n<li><p>Assume that B2 happens before A1. Then by the same logic as above, we know\nthat B4 synchronizes with A1. So since A1 is sequenced before A3, by\n<a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#9.3.1\" rel=\"nofollow noreferrer\">[intro.races]/9.3.1</a>, B4 inter-thread happens before A3. Therefore since B1 is\nsequenced before B4, by <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#9.3.2\" rel=\"nofollow noreferrer\">[intro.races]/9.3.2</a>, B1 inter-thread happens before A3.\nTherefore by <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#10.2\" rel=\"nofollow noreferrer\">[intro.races]/10.2</a>, B1 happens before A3. But then according to  <a href=\"https://timsong-cpp.github.io/cppwp/n4659/intro.races#16\" rel=\"nofollow noreferrer\">[intro.races]/16</a>, B1 must take its value from the pre-A3 state. Therefore the load will return false, and B2 will never run in the first place. In other words, this case can't happen.</p></li>\n</ol>\n<p>So if B3 executes at all (case 1), A2 happens before B3 and the assert will pass. \u220e</p>\n", "LastActivityDate": "2017-08-06T10:41:10.547"}, "45539794": {"ParentId": "45475241", "CommentCount": "0", "CreationDate": "2017-08-07T05:11:36.420", "OwnerUserId": "177923", "PostTypeId": "2", "Id": "45539794", "Score": "0", "Body": "<p>This ordering is possible:</p>\n<pre><code>void SetFoo() {\n  mu.lock();\n  // REORDERED:\n  foo_has_been_set.store(true, std::memory_order_relaxed);\n  PAUSE(); //imagine scheduler pause here \n  foo = 1;\n  mu.unlock();\n}\n</code></pre>\n<p>Now, the question is <code>CheckFoo</code> - can the read of <code>foo_has_been_set</code> fall into the lock?  Normally a read like that <em>can</em> (things can fall into locks, just not out), but the lock should never be taken if the if is false, so it would be a strange ordering.  Does anything say \"speculative locks\" are not allowed? Or can the CPU speculate that the if is true before reading <code>foo_has_been_set</code>?</p>\n<pre><code>void CheckFoo() {\n    // REORDER???\n    mu.lock();\n    if (foo_has_been_set.load(std::memory_order_relaxed)) {\n        assert(foo == 1);\n    }\n    mu.unlock();\n}\n</code></pre>\n<p>That ordering is probably not OK, but only because of \"logic order\" not memory order.  If the <code>mu.lock()</code> was inlined (and became some atomic ops) what stops them from being reordered?</p>\n<p>I'm not too worried about your current code, but I worry about any real code that uses something <em>like</em> this. It is too close to wrong.</p>\n<p>ie if the OP code was the real code, you would just change foo to atomic, and get rid of the rest.  So the real code must be different.  More complicated? ...</p>\n", "LastActivityDate": "2017-08-07T05:11:36.420"}, "bq_ids": {"n4140": {"so_45475241_45502571_0": {"section_id": 5832, "quality": 0.9333333333333333, "length": 28}, "so_45475241_45477313_1": {"section_id": 5821, "quality": 1.0, "length": 17}, "so_45475241_45476880_0": {"section_id": 5818, "quality": 1.0, "length": 7}, "so_45475241_45477313_0": {"section_id": 5818, "quality": 1.0, "length": 22}, "so_45475241_45477313_2": {"section_id": 2747, "quality": 1.0, "length": 14}, "so_45475241_45476880_1": {"section_id": 5818, "quality": 1.0, "length": 19}}, "n3337": {"so_45475241_45502571_0": {"section_id": 5603, "quality": 0.9333333333333333, "length": 28}, "so_45475241_45477313_1": {"section_id": 5592, "quality": 1.0, "length": 17}, "so_45475241_45476880_0": {"section_id": 5589, "quality": 1.0, "length": 7}, "so_45475241_45477313_0": {"section_id": 5589, "quality": 1.0, "length": 22}, "so_45475241_45477313_2": {"section_id": 2708, "quality": 1.0, "length": 14}, "so_45475241_45476880_1": {"section_id": 5589, "quality": 1.0, "length": 19}}, "n4659": {"so_45475241_45502571_0": {"section_id": 7294, "quality": 0.9333333333333333, "length": 28}, "so_45475241_45477313_1": {"section_id": 7282, "quality": 1.0, "length": 17}, "so_45475241_45476880_0": {"section_id": 7279, "quality": 1.0, "length": 7}, "so_45475241_45477313_0": {"section_id": 7279, "quality": 1.0, "length": 22}, "so_45475241_45477313_2": {"section_id": 3485, "quality": 1.0, "length": 14}, "so_45475241_45476880_1": {"section_id": 7279, "quality": 1.0, "length": 19}}}});