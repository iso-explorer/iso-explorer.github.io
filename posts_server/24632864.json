post_cb({"bq_ids": {"n4140": {"so_24632864_24633015_0": {"length": 20, "quality": 1.0, "section_id": 5818}}, "n3337": {"so_24632864_24633015_0": {"length": 20, "quality": 1.0, "section_id": 5589}}, "n4659": {"so_24632864_24633015_0": {"length": 20, "quality": 1.0, "section_id": 7279}}}, "24633015": {"Id": "24633015", "PostTypeId": "2", "Body": "<p>If you have data which can be shared between multiple threads (such as the <code>testValue</code> member in your case), you <em>must</em> synchronise all accesses to that data. \"Synchronise\" has a broad meaning here: it could be done using a mutex, by making the data atomic, or by explicitly invoking a memory barrier.</p>\n<p>But you cannot skip on this. In a parallel world with multiple threads, CPU cores, CPUs and caches, there is no guarantee that a write by one thread will be visible to another thread if they don't \"shake hands\" on a synchronisation primitive. It is quite possible that thread T1's cache entry for <code>testValue</code> will not be updated when thread T2 writes into <code>testValue</code>, precisely because the HW cache management system sees \"no synchronisation is happening, the threads don't access shared data, why should I torpedo performance by invalidating caches?\"</p>\n<p>The C++11 standard chapter [intro.multithread] goes into more detail than you'd like on this, but here's an informal Note from that chapter summarising the idea:</p>\n<blockquote>\n<p id=\"so_24632864_24633015_0\">5 ... Informally, performing a release operation on <em>A</em> forces prior side\n  effects on other memory locations to become visible to other threads that later perform a consume or an\n  acquire operation on <em>A.</em> ...</p>\n</blockquote>\n", "LastEditorUserId": "1782465", "LastActivityDate": "2014-07-08T13:43:06.343", "Score": "6", "CreationDate": "2014-07-08T13:22:56.427", "ParentId": "24632864", "CommentCount": "0", "OwnerUserId": "1782465", "LastEditDate": "2014-07-08T13:43:06.343"}, "24632864": {"ViewCount": "281", "Body": "<p>I try to understand proper way of developing threadsafe applications.</p>\n<p>In current project I have following class :</p>\n<pre><code>class Test\n{\npublic:\n    void setVal(unsigned int val)\n    {\n        mtx.lock();\n        testValue = val;\n        mtx.unlock();\n    }\n\n    unsigned int getVal()\n    {\n        unsigned int copy = testValue;\n        return copy;\n    }\nprivate:\n    boost::mutex mtx;\n    unsigned int testValue;\n}\n</code></pre>\n<p>And my question : is above method Test::getVal() threadsafe in multithreaded environment, or it must be locked before taking copy ?\nI've read some articles about COW, and now I'm unsure.</p>\n<p>Thanks!</p>\n", "AcceptedAnswerId": "24633015", "Title": "Thread safety of copy on write", "CreationDate": "2014-07-08T13:15:33.357", "Id": "24632864", "CommentCount": "3", "LastEditDate": "2014-07-08T13:18:18.653", "PostTypeId": "1", "LastEditorUserId": "1221236", "LastActivityDate": "2014-07-08T13:43:06.343", "Score": "3", "OwnerUserId": "3512620", "Tags": "<c++><multithreading><copy-on-write>", "AnswerCount": "1"}});