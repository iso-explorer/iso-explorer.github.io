post_cb({"bq_ids": {"n4140": {"so_47436919_47451933_0": {"length": 26, "quality": 0.7647058823529411, "section_id": 3161}}, "n3337": {"so_47436919_47451933_0": {"length": 26, "quality": 0.7647058823529411, "section_id": 3034}}, "n4659": {"so_47436919_47451933_0": {"length": 27, "quality": 0.7941176470588235, "section_id": 3923}}}, "47451933": {"Id": "47451933", "PostTypeId": "2", "Body": "<h3>The short story</h3>\n<p>given a <em>copy and move-constructible</em> type T</p>\n<pre><code>V f(T);\nV g(T const&amp;);\n\nT t;\nauto v = std::async(f,t).get();\nauto v = std::async(g,t).get();\n</code></pre>\n<p>the only relevant difference concerning the two async calls is that, in the first one, t's copy is destroyed as soon as f returns; in the second, t's copy <em>may</em> be destroyed as per effect of the get() call.\nIf the async calls happen in a loop with the future being <em>get()</em> later, the first will have constant memory on avarage (assuming a constant per-thread workload), the second a linearly growing memory at worst, resulting in more cache hits and worse allocation performance.</p>\n<h3>The long story</h3>\n<p>First of all, I can reproduce the observed slowdown (consistently ~2x in my system) on both gcc and clang; moreover, the same code with equivalent <code>std::thread</code> invocations does <em>not</em> manifest the same behavior, with the const&amp; version turning out slightly faster as expected. Let's see why.</p>\n<p>Firstly, the specification of async reads:</p>\n<blockquote>\n<p id=\"so_47436919_47451933_0\"><strong>[futures.async]</strong> If launch::async is set in policy, calls INVOKE(DECAY_COPY(std::forward(f)), DECAY_COPY(std::forward(args))...) (23.14.3, 33.3.2.2) as if in a new thread of execution represented by a thread object with the calls to DECAY_COPY() being evaluated in the thread that called async[...]<strong>The thread object is stored in the shared state and affects the behavior of any asynchronous return objects that reference that state.</strong></p>\n</blockquote>\n<p>so, async will copy the arguments forwarding those copies to the callable, preserving rvalueness; in this regard, it's the same as of <code>std::thread</code> constructor, and there's no difference in the two OP versions, both copy the vector.</p>\n<p><strong>The difference is in the bold part</strong>: the thread object is part of the shared state and will not be freed until the latter gets released (eg. by a future::get() call).</p>\n<p><strong>Why is this important ?</strong> because the standard does not specify to who the decayed copies are bound, we only know that they must outlive the callable invocation, but we don't know if they will be destroyed immediately after the call or at thread exit or when the thread object is destroyed (along with the shared state).</p>\n<p>In fact, it turns out that gcc and clang implementations store the decayed copies in the shared state of the resulting future.</p>\n<p>Consequently, in the <em>const&amp;</em> version the vector copy is stored in the shared state and destroyed at <code>future::get</code>: <strong>this results in the \"Start threads\" loop allocating a new vector at each step, with a linear growth of memory</strong>.</p>\n<p>Conversely, in the <em>by-value</em> version the vector copy is moved in the callable argument and destroyed as soon as the callable returns; at <code>future::get</code>, a moved, empty vector will be destroyed. So, if the callable is fast enough to destroy the vector before a new one is created, <strong>the same vector will be allocated over and over and memory will stay almost constant. This will result in less cache hits and faster allocations, explaining the improved timings.</strong></p>\n", "LastEditorUserId": "8631381", "LastActivityDate": "2017-11-23T11:33:02.743", "Score": "6", "CreationDate": "2017-11-23T09:30:32.913", "ParentId": "47436919", "CommentCount": "0", "OwnerUserId": "8631381", "LastEditDate": "2017-11-23T11:33:02.743"}, "47437606": {"Id": "47437606", "PostTypeId": "2", "Body": "<p>As people said, without std::ref the object is being copied.</p>\n<p>Now I believe that the reason that passing by value is actually faster might have something to do with the following question: <a href=\"https://stackoverflow.com/questions/270408/is-it-better-in-c-to-pass-by-value-or-pass-by-constant-reference\">Is it better in C++ to pass by value or pass by constant reference?</a></p>\n<p>What might happen, that in the internal implementation of async, the vector being copied once to the new thread. And then internally being passed by reference, to a function which take ownership of the vector, which mean it will than be copied once again. On the other hand, if you pass it by value, it will copy it once to the new thread, but than will move it twice inside the new thread. Resulting in 2 copies if the object is being passed by reference, and 1 copy and 2 move in the second case if the object is passed by value.</p>\n", "LastActivityDate": "2017-11-22T14:49:34.673", "CommentCount": "0", "CreationDate": "2017-11-22T14:49:34.673", "ParentId": "47436919", "Score": "0", "OwnerUserId": "8908931"}, "47436919": {"ViewCount": "368", "Body": "<p>As an exercise to learn about <code>std::async</code> I wrote a small program that calculates the sum of a large <code>vector&lt;int&gt;</code>, distributed about a lot of threads.</p>\n<p>My code below is as follows</p>\n<pre><code>#include &lt;iostream&gt;\n#include &lt;vector&gt;\n#include &lt;future&gt;\n#include &lt;chrono&gt;\n\ntypedef unsigned long long int myint;\n\n// Calculate sum of part of the elements in a vector\nmyint partialSum(const std::vector&lt;myint&gt;&amp; v, int start, int end)\n{\n    myint sum(0);\n    for(int i=start; i&lt;=end; ++i)\n    {\n        sum += v[i];\n    }\n    return sum;\n}\n\nint main()\n{\n    const int nThreads = 100;\n    const int sizePerThread = 100000;\n    const int vectorSize = nThreads * sizePerThread;\n\n    std::vector&lt;myint&gt; v(vectorSize);   \n    std::vector&lt;std::future&lt;myint&gt;&gt; partial(nThreads);\n    myint tot = 0;\n\n    // Fill vector  \n    for(int i=0; i&lt;vectorSize; ++i)\n    {\n        v[i] = i+1;\n    }\n    std::chrono::steady_clock::time_point startTime = std::chrono::steady_clock::now();\n\n    // Start threads\n    for( int t=0; t &lt; nThreads; ++t)\n    {\n        partial[t] = std::async( std::launch::async, partialSum, v, t*sizePerThread, (t+1)*sizePerThread -1);               \n    }\n\n    // Sum total\n    for( int t=0; t &lt; nThreads; ++t)\n    {\n        myint ps = partial[t].get();\n        std::cout &lt;&lt; t &lt;&lt; \":\\t\" &lt;&lt; ps &lt;&lt; std::endl;\n        tot += ps;\n    }\n    std::cout &lt;&lt; \"Sum:\\t\" &lt;&lt; tot &lt;&lt; std::endl;\n\n    std::chrono::steady_clock::time_point endTime = std::chrono::steady_clock::now();\n    std::cout &lt;&lt; \"Time difference = \" &lt;&lt; std::chrono::duration_cast&lt;std::chrono::milliseconds&gt;(endTime - startTime).count() &lt;&lt;std::endl;\n}\n</code></pre>\n<p>My question is concerned about the calls to the function <code>partialSum</code>, and then especially how the large vector is passed. The function is called as follows:</p>\n<pre><code>        partial[t] = std::async( std::launch::async, partialSum, v, t*sizePerThread, (t+1)*sizePerThread -1);       \n</code></pre>\n<p>with the definition as follows</p>\n<pre><code>myint partialSum(const std::vector&lt;myint&gt;&amp; v, int start, int end)\n</code></pre>\n<p>With this approach, the calculation is relatively slow. If I use <code>std::ref(v)</code> in the <code>std::async</code> function call, my function is a lot quicker and more efficient. This still makes sense to me.</p>\n<p>However, if I still call by <code>v</code>, instead of <code>std::ref(v)</code>, but replace the function with</p>\n<pre><code>myint partialSum(std::vector&lt;myint&gt; v, int start, int end)\n</code></pre>\n<p>the program also runs a lot quicker (and uses less memory). I don't understand why the const ref implementation is slower. How does the compiler fix this without any references in place?</p>\n<p>With the const ref implementation this program typically takes 6.2 seconds to run, without 3.0. (Note that with const ref, and <code>std::ref</code> it runs in 0.2 seconds for me)</p>\n<p>I am compiling with <code>g++ -Wall -pedantic</code> using (adding the <code>-O3</code> when passing just <code>v</code> demonstrates the same effect)</p>\n<blockquote>\n<p id=\"so_47436919_47436919_0\">g++ --version</p>\n<p id=\"so_47436919_47436919_1\">g++ (Rev1, Built by MSYS2 project) 6.3.0\n  Copyright (C) 2016 Free Software Foundation, Inc.\n  This is free software; see the source for copying conditions.  There is NO\n  warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</p>\n</blockquote>\n", "AcceptedAnswerId": "47451933", "Title": "Why is passing by const ref slower when using std::async", "CreationDate": "2017-11-22T14:16:09.110", "Id": "47436919", "CommentCount": "8", "FavoriteCount": "2", "PostTypeId": "1", "LastEditDate": "2017-11-24T06:45:40.087", "LastEditorUserId": "1134387", "LastActivityDate": "2017-11-24T06:45:40.087", "Score": "10", "OwnerUserId": "1134387", "Tags": "<c++><stl><pass-by-reference>", "AnswerCount": "2"}});