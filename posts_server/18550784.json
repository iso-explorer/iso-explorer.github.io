post_cb({"bq_ids": {"n4140": {"so_18550784_18550834_0": {"length": 7, "quality": 1.0, "section_id": 5435}}, "n4659": {"so_18550784_18550834_0": {"length": 4, "quality": 0.5714285714285714, "section_id": 6862}}}, "18550784": {"ViewCount": "2093", "LastEditDate": "2017-05-23T12:01:53.873", "AcceptedAnswerId": "18550834", "Title": "Does volatile qualifier cancel caching for this memory?", "CreationDate": "2013-08-31T17:16:59.077", "LastActivityDate": "2013-09-01T09:35:39.173", "CommentCount": "2", "Body": "<p>In this article: <a href=\"http://www.drdobbs.com/parallel/volatile-vs-volatile/212701484?pgno=2\" rel=\"nofollow noreferrer\">http://www.drdobbs.com/parallel/volatile-vs-volatile/212701484?pgno=2</a>\nsays, that we can't do any optimization for <code>volatile</code>, even such as (where: <code>volatile int&amp; v = *(address);</code>):</p>\n<pre><code>v = 1;                // C: write to v\nlocal = v;            // D: read from v\n</code></pre>\n<p>can't be optimized to this:</p>\n<pre><code>v = 1;                // C: write to v\nlocal = 1;            // D: read from v  // but it can be done for std::atomic&lt;&gt;\n</code></pre>\n<p>It is can't be done, because between 1st and 2nd lines may <code>v</code> value be changed by <strong>hardware device (not CPU where can't work cache coherence: network adapter, GPU, FPGA, etc...)</strong> (sequentila/concurrency), which mapped to this memory location. But it is make sense only if <code>v</code> can't be cached in CPU-cache L1/2/3, because for usual (non-<code>volatile</code>) variable between 1st and 2nd line too small time and is likely to trigger cached. </p>\n<p>Does <code>volatile</code> qualifier guarantees no caching for this memory location?</p>\n<p><strong>ANSWER:</strong> </p>\n<ol>\n<li>No, <code>volatile</code> <strong>doesn't guarantee no caching</strong> for this memory location, and there aren't anything about this in C/C++ Standards or <a href=\"http://gcc.gnu.org/onlinedocs/gcc/Volatiles.html\" rel=\"nofollow noreferrer\">compiler manual</a>.</li>\n<li>Using memory mapped region, <strong><a href=\"https://stackoverflow.com/a/1757198/1558037\">when memory mapped from device memory to CPU-memory is already marked as WC</a></strong> (write combining) instead of WB, that cancels the caching. <strong>And need not to do cache-flushing</strong>.</li>\n<li>An opposite, if CPU-memory mapped to the device memory, then incidentally, the controller PCIE, located on crystal of CPU, is snooping for data which going through DMA from this device, and updates(invalidate) CPU-cache L3. In this case, <strong>if the executable code on the device using the</strong> <code>volatile</code> tries to perform the same two lines, it also cancels the cache memory of the device (e.g. in the cache GPU-L2). And <strong><a href=\"https://stackoverflow.com/questions/12027849/how-can-i-read-from-the-pinned-lock-page-ram-and-not-from-the-cpu-cache-use/12028433#12028433\">need not to do GPU-cache-flushing and need not to do CPU-cache-flushing</a></strong>. Also for CPU might need to use <code>std::atomic_thread_fence(std::memory_order_seq_cst);</code> <a href=\"http://en.wikipedia.org/wiki/Direct_memory_access#Cache_coherency\" rel=\"nofollow noreferrer\">if L3-cache(LLC) coherency with DMA over PCIE, but L1/L2 is not</a>. And for nVidia CUDA we can use: <a href=\"http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#memory-fence-functions\" rel=\"nofollow noreferrer\"><code>void __threadfence_system();</code></a></li>\n<li>We <strong>need to flushing DMA-controllers-cache</strong>, when sending unaligned data: <a href=\"http://msdn.microsoft.com/en-us/library/windows/hardware/ff545924%28v=vs.110%29.aspx\" rel=\"nofollow noreferrer\">(WDK: <code>KeFlushIoBuffers(), FlushAdapterBuffers()</code>)</a></li>\n<li>Also, we can mark any memory region as uncached as WC-marked by yourself via the MTRR registers.</li>\n</ol>\n", "PostTypeId": "1", "LastEditorUserId": "-1", "Id": "18550784", "AnswerCount": "1", "Score": "8", "OwnerUserId": "1558037", "Tags": "<c++><c><caching><c++11><concurrency>", "FavoriteCount": "4"}, "18550834": {"Id": "18550834", "PostTypeId": "2", "LastEditDate": "2017-05-23T12:33:53.633", "CommentCount": "9", "LastEditorUserId": "-1", "LastActivityDate": "2013-08-31T17:58:03.390", "CreationDate": "2013-08-31T17:21:39.003", "ParentId": "18550784", "Score": "6", "Body": "<p><code>volatile</code> ensures that the variable won't be \"cached\" in CPU register. CPU cache is transparent to the programmer and if another CPU writes to the memory mapped by another CPU's cache, the second CPU's cache gets invalidated, therefore it will reload the value from the memory again during the next access.</p>\n<p>Something about <a href=\"http://en.wikipedia.org/wiki/Cache_coherence\" rel=\"nofollow noreferrer\">Cache coherence</a></p>\n<p>As for the external memory writes (via DMA or another CPU-independent channel), you might need to flush the cache manually (see <a href=\"https://stackoverflow.com/questions/1756825/cpu-cache-flush\">this</a> SO question)</p>\n<hr>\n<p>C Standard \u00a76.7.3 7:</p>\n<blockquote>\n<p id=\"so_18550784_18550834_0\">What constitutes an access to an object that\n  has volatile-qualified type is implementation-defined.</p>\n</blockquote>\n</hr>", "OwnerUserId": "624664"}});