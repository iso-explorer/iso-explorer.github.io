post_cb({"20548675": {"ParentId": "20548528", "PostTypeId": "2", "CommentCount": "2", "Body": "<p>In a conforming C++11 compiler this is safe [intro.memory] (\u00a71.7):</p>\n<blockquote>\n<p id=\"so_20548528_20548675_0\">A memory location is either an object of scalar type or a maximal\n  sequence of adjacent bit-fields all having non-zero width. [...] Two\n  threads of execution (1.10) can update and access separate memory\n  locations without interfering with each other.</p>\n</blockquote>\n<p>C11 gives identical guarantees (they even use the same wording) in \u00a73.14.</p>\n<p>In a C++03 compiler this is not guaranteed to work by the standard, but it might still work if the compiler provides similar guarantees as an extension.</p>\n", "OwnerUserId": "577603", "LastEditorUserId": "577603", "LastEditDate": "2014-07-11T07:05:06.847", "Id": "20548675", "Score": "31", "CreationDate": "2013-12-12T16:21:11.520", "LastActivityDate": "2014-07-11T07:05:06.847"}, "20552026": {"ParentId": "20548528", "CommentCount": "2", "Body": "<p>Yes.</p>\n<p>You do not even need to guarantee that no two threads <strong>access</strong> the same memory location. All you need to guarantee is that no single thread <strong>modifies</strong> any location that another one accesses (regardless whether that means reading or writing).</p>\n<p>Given <strong>either</strong> no concurrent access at all <strong>or</strong> read-only concurrent access, you're good to go without locking.</p>\n", "OwnerUserId": "572743", "PostTypeId": "2", "Id": "20552026", "Score": "4", "CreationDate": "2013-12-12T19:03:04.400", "LastActivityDate": "2013-12-12T19:03:04.400"}, "bq_ids": {"n4140": {"so_20548528_20548675_0": {"section_id": 5787, "quality": 0.9259259259259259, "length": 25}}, "n3337": {"so_20548528_20548675_0": {"section_id": 5560, "quality": 0.9259259259259259, "length": 25}}, "n4659": {"so_20548528_20548675_0": {"section_id": 7244, "quality": 0.8888888888888888, "length": 24}}}, "20648170": {"ParentId": "20548528", "CommentCount": "0", "Body": "<p>Important performance issue !</p>\n<p>Right, you doesn't need explicit locking, since, as said by others, no memory location is shared.</p>\n<p>But you may trigger <strong>implicit hardware synchronization</strong>, since arbitrary chunks are likely to lead cache lines to be shared (not much with the figures used in your example, though). It is known as <a href=\"http://en.wikipedia.org/wiki/False_sharing\" rel=\"nofollow\">false sharing</a>.</p>\n<p>Higher level approach such as <a href=\"http://en.wikipedia.org/wiki/OpenMP\" rel=\"nofollow\">OpenMP</a> resolves these kinds of issue :</p>\n<ul>\n<li>chunks alignment (and threads numbers) are tuned according to underlying hardware.</li>\n<li>it provides a better control over pool of threads, eg amortizing the cost of thread instantiations.</li>\n<li>it's easier to write, and actually less intrusive.</li>\n</ul>\n", "OwnerUserId": "995896", "PostTypeId": "2", "Id": "20648170", "Score": "3", "CreationDate": "2013-12-18T01:38:29.743", "LastActivityDate": "2013-12-18T01:38:29.743"}, "20548596": {"ParentId": "20548528", "PostTypeId": "2", "CommentCount": "3", "Body": "<p>Yes: if you can guarantee that no two threads will access the same element, then there's no need for any further synchronisation.</p>\n<p>There is only a conflict (and therefore a potential data race) if two threads access the same memory location (with at least one of them modifying it) without synchronisation.</p>\n<p>(NOTE: this answer is based on the C++11 memory model. I've just noticed that you're also asking about a second language; I believe that C11 specifies a very similar memory model, but can't say for sure that the answer is also valid for C. For older versions of both languages, thread-safety was implementation-dependent.)</p>\n", "OwnerUserId": "204847", "LastEditorUserId": "204847", "LastEditDate": "2013-12-12T20:10:09.677", "Id": "20548596", "Score": "18", "CreationDate": "2013-12-12T16:17:57.020", "LastActivityDate": "2013-12-12T20:10:09.677"}, "20548528": {"CommentCount": "0", "AcceptedAnswerId": "20548675", "PostTypeId": "1", "LastEditorUserId": "1157100", "CreationDate": "2013-12-12T16:14:58.827", "LastActivityDate": "2014-07-11T07:05:06.847", "LastEditDate": "2013-12-12T21:13:57.967", "ViewCount": "2049", "FavoriteCount": "3", "Title": "Can you avoid locking by guaranteeing that multiple threads won't access the same memory?", "Id": "20548528", "Score": "41", "Body": "<p>Say I have a large array and I want to process the contents with multiple threads.  If I delegate each thread to a specific section, guaranteeing no overlap, does that eliminate any need for locking, assuming the threads don't access any other memory outside the array?</p>\n<p>Something like this (pseudo-code):</p>\n<pre><code>global array[9000000];\n\ndo_something(chunk) {\n    for (i = chunk.start; i &lt; chunk.end; i++)\n        //do something with array\n}\n\nmain() {\n    chunk1 = {start: 0, end: 5000000};\n    chunk2 = {start: 5000000, end: 9000000};\n\n    start_thread(thread1, do_something(chunk1));\n    start_thread(thread2, do_something(chunk2));\n\n    wait_for_join(thread1);\n    wait_for_join(thread2);\n    //do something else with the altered array\n}\n</code></pre>\n", "Tags": "<c++><c><multithreading><lock-free>", "OwnerUserId": "2923657", "AnswerCount": "5"}, "20548579": {"ParentId": "20548528", "CommentCount": "0", "Body": "<p>Yes, you can indeed.  </p>\n<p><a href=\"http://goog-perftools.sourceforge.net/doc/tcmalloc.html\" rel=\"noreferrer\">TCMalloc</a> is a good example.</p>\n", "OwnerUserId": "1056928", "PostTypeId": "2", "Id": "20548579", "Score": "8", "CreationDate": "2013-12-12T16:17:04.727", "LastActivityDate": "2013-12-12T16:17:04.727"}});