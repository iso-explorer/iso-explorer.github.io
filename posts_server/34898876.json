post_cb({"34899986": {"Id": "34899986", "PostTypeId": "2", "Body": "<p>In memory a double is 8 byte = 8 oct. </p>\n<p>The memory used by a vector is:</p>\n<pre><code>// size of vector + size of type * n.elements\nsizeof(std::vector&lt;double&gt;) + (sizeof(double) * n_elem);\n</code></pre>\n<p>so, a <strong>vector&lt; double &gt; of 10 elements</strong> has the size of: 24 + (8 * 10) = <strong>104 byte/oct</strong>;</p>\n<p>But you have a vector of vector of that type, so:</p>\n<pre><code>24 + [24 + (24 + 8*10) * 100 000] * 500 ~ 5Go.\n</code></pre>\n", "LastActivityDate": "2016-01-20T12:23:32.883", "CommentCount": "0", "CreationDate": "2016-01-20T12:23:32.883", "ParentId": "34898876", "Score": "0", "OwnerUserId": "1219593"}, "34898876": {"ViewCount": "98", "Body": "<p>I wrote this little code that creates a matrix. the size of the matrix is 500 x 100 000. The elements of the matrix are vectors of doubles of size 10.\nI expect the size of memory to stock this object should be something close to :  500 x 100 000 x 10 octets = 500 MB.\nHowever when I compile it with g++, the object takes 5GB.\nDo you know why the object is so heavy?</p>\n<p>Here is the code :</p>\n<pre><code>int main(int argc, const char * argv[]) {\n    vector&lt;vector&lt;vector&lt;double&gt;&gt;&gt; truc;\n    truc.resize(500);\n    for (int i =0; i&lt;500; i++) {\n        truc[i].resize(100000);\n        for (int j=0; j&lt;100000; j++) {\n            truc[i][j].resize(10);\n        }\n    }\n</code></pre>\n<p>and I compile it with the command :</p>\n<pre><code>g++ -std=c++11 -O3 main.cpp -o main\n</code></pre>\n", "AcceptedAnswerId": "34899842", "Title": "matrix 10 times heavier than expected in cpp", "CreationDate": "2016-01-20T11:32:33.410", "Id": "34898876", "CommentCount": "3", "LastEditDate": "2016-01-20T12:37:31.590", "PostTypeId": "1", "OwnerDisplayName": "user5815490", "LastEditorUserId": "1212012", "LastActivityDate": "2016-01-20T12:41:51.553", "Score": "0", "Tags": "<c++>", "AnswerCount": "4"}, "34899757": {"Id": "34899757", "PostTypeId": "2", "Body": "<p>Here is what the standard says about the number of bytes used to store a <code>double</code> (emphasis mine):</p>\n<blockquote>\n<p id=\"so_34898876_34899757_0\">\u00a7 3.9.1</p>\n<p id=\"so_34898876_34899757_1\">There are three floating point types: float, double, and long double. The type double provides at least\n  as much precision as float, and the type long double provides at least as much precision as double.\n  The set of values of the type float is a subset of the set of values of the type double; the set of values\n  of the type double is a subset of the set of values of the type long double. <strong>The value representation of\n  floating-point types is implementation-defined.</strong> Integral and floating types are collectively called arithmetic\n  types. Specializations of the standard template std::numeric_limits (18.3) shall specify the maximum\n  and minimum values of each arithmetic type for an implementation.</p>\n</blockquote>\n<p>Therefore, the amount of space required is entirely down the the implementation of your compiler.</p>\n<p>As mentioned in the comments, <code>sizeof(double)</code> will reveal how many bytes are required to store a double on your machine.</p>\n", "LastActivityDate": "2016-01-20T12:12:02.387", "CommentCount": "0", "CreationDate": "2016-01-20T12:12:02.387", "ParentId": "34898876", "Score": "1", "OwnerUserId": "2015579"}, "34899842": {"Id": "34899842", "PostTypeId": "2", "Body": "<p>Just for the actual <code>double</code>s, you require <code>500*100000*10*sizeof(double)</code> bytes.  <code>sizeof(double)</code> is usually 8 bytes, which brings you to 4,000,000,000 bytes.</p>\n<p>In addition, the <code>std::vector</code>s themselves require some space for their internal fields which manage the data: e.g. on 64-Bit Linux with <code>gcc</code>, <code>sizeof(std::vector&lt;double&gt;)</code> is 24.  You create a total of (1+500+500*100000) <code>std::vector</code> objects, which by itself comes to 1,200,012,024 bytes.</p>\n<p>You may want to think about using a sparse data structure, which explicitly stores only non-zero entries, if that is feasible for the kind of data you deal with.  <a href=\"http://eigen.tuxfamily.org/index.php?title=Main_Page\" rel=\"nofollow\">The Eigen matrix library</a> comes to my mind as a possible candidate.</p>\n", "LastActivityDate": "2016-01-20T12:15:52.797", "CommentCount": "1", "CreationDate": "2016-01-20T12:15:52.797", "ParentId": "34898876", "Score": "0", "OwnerUserId": "3233921"}, "bq_ids": {"n4140": {"so_34898876_34899757_1": {"length": 65, "quality": 0.9285714285714286, "section_id": 7217}}, "n3337": {"so_34898876_34899757_1": {"length": 65, "quality": 0.9285714285714286, "section_id": 6961}}, "n4659": {"so_34898876_34899757_1": {"length": 63, "quality": 0.9, "section_id": 8726}}}, "34900384": {"Id": "34900384", "PostTypeId": "2", "Body": "<p>A <code>double</code> is not an octet.    An octet is a set of 8 bits, and is equivalent to a single <code>char</code> (with most implementations).    The size of a <code>double</code> is implementation dependent, but typically has a size of 8 BYTES, which is equivalent to 8 octets.</p>\n<p>So multiply your expected memory usage by <code>8</code> to get a lower bound on memory usage.   Bear in mind that every vector will use additional memory (e.g. to keep track of the set of <code>double</code>s they manage) - and your vector <code>truc</code> contains <code>500*100000 = 50,000,000</code> of them.   Your calculation is not taking those into account at all.</p>\n", "LastActivityDate": "2016-01-20T12:41:51.553", "CommentCount": "1", "CreationDate": "2016-01-20T12:41:51.553", "ParentId": "34898876", "Score": "0", "OwnerUserId": "4706785"}});