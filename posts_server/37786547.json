post_cb({"37786733": {"ParentId": "37786547", "PostTypeId": "2", "CommentCount": "27", "CreationDate": "2016-06-13T09:56:58.963", "Score": "3", "LastEditorUserId": "4850040", "LastEditDate": "2016-06-13T16:38:23.653", "Id": "37786733", "OwnerUserId": "6255513", "Body": "<p>No it can't. According to the C++ standard [intro.execution]: </p>\n<blockquote>\n<p id=\"so_37786547_37786733_0\">14 Every value computation and side effect associated with a\n  full-expression is sequenced before every value computation and side\n  effect associated with the next full-expression to be evaluated.</p>\n</blockquote>\n<p>A full-expression is basically a statement terminated by a semicolon. As you can see the above rule stipulates statements must be executed in order. It is <em>within</em> statements that the compiler is allowed more free rein (i.e. it is under some circumstance allowed to evaluate expressions that make up a statement in orders other than left-to-right or anything else specific).</p>\n<p>Note the conditions for the as-if rule to apply are not met here. It is unreasonable to think that any compiler would be able to <em>prove</em> that reordering calls to get the system time would not affect observable program behaviour. If there was a circumstance in which two calls to get the time could be reordered without changing observed behaviour, it would be extremely inefficient to actually produce a compiler that analyses a program with enough understanding to be able to infer this with certainty.</p>\n", "LastActivityDate": "2016-06-13T16:38:23.653"}, "37789799": {"ParentId": "37786547", "PostTypeId": "2", "CommentCount": "20", "CreationDate": "2016-06-13T12:24:22.887", "Score": "60", "LastEditorUserId": "193887", "LastEditDate": "2016-06-14T09:38:26.890", "Id": "37789799", "OwnerUserId": "193887", "Body": "<p><strong>Summary:</strong></p>\n<p>There seems to be no guaranteed way to prevent reordering, but as long as link-time/full-program optimisation is not enabled, <strong>locating the called function in a separate compilation unit seems a fairly good bet</strong>.  (At least with GCC, although logic would suggest that this is likely with other compilers too.)  This comes at the cost of the function call - inlined code is by definition in the same compilation unit and open to reordering.</p>\n<p><strong>Original answer:</strong></p>\n<p>GCC reorders the calls under -O2 optimisation:</p>\n<pre><code>#include &lt;chrono&gt;\nstatic int foo(int x)    // 'static' or not here doesn't affect ordering.\n{\n    return x*2;\n}\nint fred(int x)\n{\n    auto t1 = std::chrono::high_resolution_clock::now();\n    int y = foo(x);\n    auto t2 = std::chrono::high_resolution_clock::now();\n    return y;\n}\n</code></pre>\n<p>GCC 5.3.0:</p>\n<p><code>g++ -S --std=c++11 -O0 fred.cpp</code> :</p>\n<pre><code>_ZL3fooi:\n        pushq   %rbp\n        movq    %rsp, %rbp\n        movl    %ecx, 16(%rbp)\n        movl    16(%rbp), %eax\n        addl    %eax, %eax\n        popq    %rbp\n        ret\n_Z4fredi:\n        pushq   %rbp\n        movq    %rsp, %rbp\n        subq    $64, %rsp\n        movl    %ecx, 16(%rbp)\n        call    _ZNSt6chrono3_V212system_clock3nowEv\n        movq    %rax, -16(%rbp)\n        movl    16(%rbp), %ecx\n        call    _ZL3fooi\n        movl    %eax, -4(%rbp)\n        call    _ZNSt6chrono3_V212system_clock3nowEv\n        movq    %rax, -32(%rbp)\n        movl    -4(%rbp), %eax\n        addq    $64, %rsp\n        popq    %rbp\n        ret\n</code></pre>\n<p>But:</p>\n<p><code>g++ -S --std=c++11 -O2 fred.cpp</code> : </p>\n<pre><code>_Z4fredi:\n        pushq   %rbx\n        subq    $32, %rsp\n        movl    %ecx, %ebx\n        call    _ZNSt6chrono3_V212system_clock3nowEv\n        call    _ZNSt6chrono3_V212system_clock3nowEv\n        leal    (%rbx,%rbx), %eax\n        addq    $32, %rsp\n        popq    %rbx\n        ret\n</code></pre>\n<p>Now, with foo() as an extern function:</p>\n<pre><code>#include &lt;chrono&gt;\nint foo(int x);\nint fred(int x)\n{\n    auto t1 = std::chrono::high_resolution_clock::now();\n    int y = foo(x);\n    auto t2 = std::chrono::high_resolution_clock::now();\n    return y;\n}\n</code></pre>\n<p><code>g++ -S --std=c++11 -O2 fred.cpp</code> : </p>\n<pre><code>_Z4fredi:\n        pushq   %rbx\n        subq    $32, %rsp\n        movl    %ecx, %ebx\n        call    _ZNSt6chrono3_V212system_clock3nowEv\n        movl    %ebx, %ecx\n        call    _Z3fooi\n        movl    %eax, %ebx\n        call    _ZNSt6chrono3_V212system_clock3nowEv\n        movl    %ebx, %eax\n        addq    $32, %rsp\n        popq    %rbx\n        ret\n</code></pre>\n<p>BUT, if this is linked with -flto (link-time optimisation):</p>\n<pre><code>0000000100401710 &lt;main&gt;:\n   100401710:   53                      push   %rbx\n   100401711:   48 83 ec 20             sub    $0x20,%rsp\n   100401715:   89 cb                   mov    %ecx,%ebx\n   100401717:   e8 e4 ff ff ff          callq  100401700 &lt;__main&gt;\n   10040171c:   e8 bf f9 ff ff          callq  1004010e0 &lt;_ZNSt6chrono3_V212system_clock3nowEv&gt;\n   100401721:   e8 ba f9 ff ff          callq  1004010e0 &lt;_ZNSt6chrono3_V212system_clock3nowEv&gt;\n   100401726:   8d 04 1b                lea    (%rbx,%rbx,1),%eax\n   100401729:   48 83 c4 20             add    $0x20,%rsp\n   10040172d:   5b                      pop    %rbx\n   10040172e:   c3                      retq\n</code></pre>\n", "LastActivityDate": "2016-06-14T09:38:26.890"}, "38025837": {"ParentId": "37786547", "CommentCount": "3", "CreationDate": "2016-06-25T06:48:59.950", "OwnerUserId": "552038", "PostTypeId": "2", "Id": "38025837", "Score": "67", "Body": "<p>I'd like to try to provide a somewhat more comprehensive answer after this was discussed with the C++ standards committee. In addition to being a member of the C++ committee, I'm also a developer on the LLVM and Clang compilers.</p>\n<p>Fundamentally, there is no way to use a barrier or some operation in the sequence to achieve these transformations. The fundamental problem is that the operational semantics of something like an integer addition are <em>totally known</em> to the implementation. It can simulate them, it knows they cannot be observed by correct programs, and is always free to move them around.</p>\n<p>We could try to prevent this, but it would have extremely negative results and would ultimately fail.</p>\n<p>First, the only way to prevent this in the compiler is to tell it that all of these basic operations are observable. The problem is that this then would preclude the overwhelming majority of compiler optimizations. Inside the compiler, we have essentially no good mechanisms to model that the <em>timing</em> is observable but nothing else. We don't even have a good model of <em>what operations take time</em>. As an example, does converting a 32-bit unsigned integer to a 64-bit unsigned integer take time? It takes zero time on x86-64, but on other architectures it takes non-zero time. There is no generically correct answer here.</p>\n<p>But even if we succeed through some heroics at preventing the compiler from reordering these operations, there is no guarantee this will be enough. Consider a valid and conforming way to execute your C++ program on an x86 machine: DynamoRIO. This is a system that dynamically evaluates the machine code of the program. One thing it can do is online optimizations, and it is even capable of speculatively executing the entire range of basic arithmetic instructions outside of the timing. And this behavior isn't unique to dynamic evaluators, the actual x86 CPU will also speculate (a much smaller number of) instructions and reorder them dynamically.</p>\n<p>The essential realization is that the fact that arithmetic isn't observable (even at the timing level) is something that permeates the layers of the computer. It is true for the compiler, the runtime, and often even the hardware. Forcing it to be observable would both dramatically constrain the compiler, but it would also dramatically constrain the hardware.</p>\n<p>But all of this should not cause you to lose hope. When you want to time the execution of basic mathematical operations, we have well studied techniques that work reliably. Typically these are used when doing <em>micro-benchmarking</em>. I gave a talk about this at CppCon2015: <a href=\"https://youtu.be/nXaxk27zwlk\">https://youtu.be/nXaxk27zwlk</a></p>\n<p>The techniques shown there are also provided by various micro-benchmark libraries such as Google's: <a href=\"https://github.com/google/benchmark#preventing-optimisation\">https://github.com/google/benchmark#preventing-optimisation</a></p>\n<p>The key to these techniques is to focus on the data. You make the input to the computation opaque to the optimizer and the result of the computation opaque to the optimizer. Once you've done that, you can time it reliably. Let's look at a realistic version of the example in the original question, but with the definition of <code>foo</code> fully visible to the implementation. I've also extracted a (non-portable) version of <code>DoNotOptimize</code> from the Google Benchmark library which you can find here: <a href=\"https://github.com/google/benchmark/blob/master/include/benchmark/benchmark_api.h#L208\">https://github.com/google/benchmark/blob/master/include/benchmark/benchmark_api.h#L208</a></p>\n<pre><code>#include &lt;chrono&gt;\n\ntemplate &lt;class T&gt;\n__attribute__((always_inline)) inline void DoNotOptimize(const T &amp;value) {\n  asm volatile(\"\" : \"+m\"(const_cast&lt;T &amp;&gt;(value)));\n}\n\n// The compiler has full knowledge of the implementation.\nstatic int foo(int x) { return x * 2; }\n\nauto time_foo() {\n  using Clock = std::chrono::high_resolution_clock;\n\n  auto input = 42;\n\n  auto t1 = Clock::now();         // Statement 1\n  DoNotOptimize(input);\n  auto output = foo(input);       // Statement 2\n  DoNotOptimize(output);\n  auto t2 = Clock::now();         // Statement 3\n\n  return t2 - t1;\n}\n</code></pre>\n<p>Here we ensure that the input data and the output data are marked as un-optimizable around the computation <code>foo</code>, and only around those markers are the timings computed. Because you are using data to pincer the computation, it is guaranteed to stay between the two timings and yet the computation itself is allowed to be optimized. The resulting x86-64 assembly generated by a recent build of Clang/LLVM is:</p>\n<pre><code>% ./bin/clang++ -std=c++14 -c -S -o - so.cpp -O3\n        .text\n        .file   \"so.cpp\"\n        .globl  _Z8time_foov\n        .p2align        4, 0x90\n        .type   _Z8time_foov,@function\n_Z8time_foov:                           # @_Z8time_foov\n        .cfi_startproc\n# BB#0:                                 # %entry\n        pushq   %rbx\n.Ltmp0:\n        .cfi_def_cfa_offset 16\n        subq    $16, %rsp\n.Ltmp1:\n        .cfi_def_cfa_offset 32\n.Ltmp2:\n        .cfi_offset %rbx, -16\n        movl    $42, 8(%rsp)\n        callq   _ZNSt6chrono3_V212system_clock3nowEv\n        movq    %rax, %rbx\n        #APP\n        #NO_APP\n        movl    8(%rsp), %eax\n        addl    %eax, %eax              # This is \"foo\"!\n        movl    %eax, 12(%rsp)\n        #APP\n        #NO_APP\n        callq   _ZNSt6chrono3_V212system_clock3nowEv\n        subq    %rbx, %rax\n        addq    $16, %rsp\n        popq    %rbx\n        retq\n.Lfunc_end0:\n        .size   _Z8time_foov, .Lfunc_end0-_Z8time_foov\n        .cfi_endproc\n\n\n        .ident  \"clang version 3.9.0 (trunk 273389) (llvm/trunk 273380)\"\n        .section        \".note.GNU-stack\",\"\",@progbits\n</code></pre>\n<p>Here you can see the compiler optimizing the call to <code>foo(input)</code> down to a single instruction, <code>addl %eax, %eax</code>, but without moving it outside of the timing or eliminating it entirely despite the constant input.</p>\n<p>Hope this helps, and the C++ standards committee is looking at the possibility of standardizing APIs similar to <code>DoNotOptimize</code> here.</p>\n", "LastActivityDate": "2016-06-25T06:48:59.950"}, "37787147": {"ParentId": "37786547", "PostTypeId": "2", "CommentCount": "3", "CreationDate": "2016-06-13T10:17:12.350", "Score": "19", "LastEditorUserId": "31317", "LastEditDate": "2016-06-13T13:02:18.880", "Id": "37787147", "OwnerUserId": "31317", "Body": "<p>Reordering may be done by the compiler, or by the processor. </p>\n<p>Most compilers offer a platform-specific method to prevent reordering of read-write instructions. On gcc, this is </p>\n<pre><code>asm volatile(\"\" ::: \"memory\");\n</code></pre>\n<p>(<a href=\"https://en.wikipedia.org/wiki/Memory_ordering#Compile-time_memory_barrier_implementation\">More information here</a>)</p>\n<p>Note that this only indirectly prevents reordering operations, as long as they depend on the reads / writes. </p>\n<p><strong>In practice</strong> I haven't yet seen a system where the system call in <code>Clock::now()</code> does have the same effect as such a barrier. You could inspect the resulting assembly to be sure. </p>\n<p>It is not uncommon, however, that the function under test gets evaluated during compile time. To enforce \"realistic\" execution, you may need to derive input for <code>foo()</code> from I/O or a <code>volatile</code> read. </p>\n<hr>\n<p>Another option would be to disable inlining for <code>foo()</code> - again, this is compiler  specific and usually not portable, but would have the same effect.</p>\n<p>On gcc, this would be <code>__attribute__ ((noinline))</code></p>\n<hr>\n<p>@Ruslan brings up a fundamental issue: How realistic is this measurement? </p>\n<p>Execution time is affected by many factors: one is the actual hardware we are running on, the other is concurrent access to shared resources like cache, memory, disk and CPU cores. </p>\n<p>So what we usually do to get <em>comparable</em> timings: make sure they are <em>reproducible</em> with a low error margin. This makes them somewhat artificial. </p>\n<p>\"hot cache\" vs. \"cold cache\" execution performance can easily differ by an order of magnitude - but in reality, it will be something inbetween (\"lukewarm\"?)</p>\n</hr></hr>", "LastActivityDate": "2016-06-13T13:02:18.880"}, "37786547": {"CommentCount": "14", "AcceptedAnswerId": "38025837", "PostTypeId": "1", "LastEditorUserId": "63550", "CreationDate": "2016-06-13T09:47:32.740", "LastActivityDate": "2016-06-25T14:35:49.113", "LastEditDate": "2016-06-14T00:25:44.220", "ViewCount": "6375", "FavoriteCount": "24", "Title": "Enforcing statement order in C++", "Id": "37786547", "Score": "87", "Body": "<p>Suppose I have a number of statements that I want to execute in\na fixed order. I want to use g++ with optimization level 2, so some\nstatements could be reordered. What tools does one have to enforce a certain ordering of statements?</p>\n<p>Consider the following example.</p>\n<pre><code>using Clock = std::chrono::high_resolution_clock;\n\nauto t1 = Clock::now(); // Statement 1\nfoo();                  // Statement 2\nauto t2 = Clock::now(); // Statement 3\n\nauto elapsedTime = t2 - t1;\n</code></pre>\n<p>In this example it is important that the statements 1-3 are executed in\nthe given order. However, can't the compiler think statement 2 is\nindependent of 1 and 3 and execute the code as follows?</p>\n<pre><code>using Clock=std::chrono::high_resolution_clock;\n\nfoo();                  // Statement 2\nauto t1 = Clock::now(); // Statement 1\nauto t2 = Clock::now(); // Statement 3\n\nauto elapsedTime = t2 - t1;\n</code></pre>\n", "Tags": "<c++><c++11><order-of-evaluation>", "OwnerUserId": "6458407", "AnswerCount": "6"}, "bq_ids": {"n4140": {"so_37786547_37786733_0": {"section_id": 5810, "quality": 1.0, "length": 18}}, "n3337": {"so_37786547_37786733_0": {"section_id": 5583, "quality": 1.0, "length": 18}}, "n4659": {"so_37786547_37786733_0": {"section_id": 7271, "quality": 1.0, "length": 18}}}, "37786918": {"ParentId": "37786547", "CommentCount": "8", "CreationDate": "2016-06-13T10:05:11.913", "OwnerUserId": "560648", "PostTypeId": "2", "Id": "37786918", "Score": "2", "Body": "<p><strong>No.</strong></p>\n<p>Sometimes, by the \"as-if\" rule, statements may be re-ordered. This is not because they are logically independent of each other, but because that independence allows such a re-ordering to occur without changing the semantics of the program.</p>\n<p>Moving a system call that obtains the current time obviously does not satisfy that condition. A compiler that knowingly or unknowingly does so is non-compliant and really silly.</p>\n<p>In general, I wouldn't expect any expression that results in a system call to be \"second-guessed\" by even an aggressively optimizing compiler. It just doesn't know enough about what that system call does.</p>\n", "LastActivityDate": "2016-06-13T10:05:11.913"}, "37792745": {"ParentId": "37786547", "PostTypeId": "2", "CommentCount": "3", "CreationDate": "2016-06-13T14:45:23.997", "Score": "10", "LastEditorUserId": "1774667", "LastEditDate": "2016-06-13T18:21:59.420", "Id": "37792745", "OwnerUserId": "1774667", "Body": "<p>The C++ language defines what is observable in a number of ways.</p>\n<p>If <code>foo()</code> does nothing observable, then it can be eliminated completely.  If <code>foo()</code> only does a computation that stores values in \"local\" state (be it on the stack or in an object somewhere), <em>and</em> the compiler can prove that no safely-derived pointer can get into the <code>Clock::now()</code> code, then there are no observable consequences to moving the <code>Clock::now()</code> calls.</p>\n<p>If <code>foo()</code> interacted with a file or the display, and the compiler cannot prove that <code>Clock::now()</code> does <em>not</em> interact with the file or the display, then reordering cannot be done, because interaction with a file or display is observable behavior.</p>\n<p>While you can use compiler-specific hacks to force code not to move around (like inline assembly), another approach is to attempt to outsmart your compiler.</p>\n<p>Create a dynamically loaded library.  Load it prior to the code in question.</p>\n<p>That library exposes one thing:</p>\n<pre><code>namespace details {\n  void execute( void(*)(void*), void *);\n}\n</code></pre>\n<p>and wraps it like this:</p>\n<pre><code>template&lt;class F&gt;\nvoid execute( F f ) {\n  struct bundle_t {\n    F f;\n  } bundle = {std::forward&lt;F&gt;(f)};\n\n  auto tmp_f = [](void* ptr)-&gt;void {\n    auto* pb = static_cast&lt;bundle_t*&gt;(ptr);\n    (pb-&gt;f)();\n  };\n  details::execute( tmp_f, &amp;bundle );\n}\n</code></pre>\n<p>which packs up a nullary lambda and uses the dynamic library to run it in a context that the compiler cannot understand.</p>\n<p>Inside the dynamic library, we do:</p>\n<pre><code>void details::execute( void(*f)(void*), void *p) {\n  f(p);\n}\n</code></pre>\n<p>which is pretty simple.</p>\n<p>Now to reorder the calls to <code>execute</code>, it must understand the dynamic library, which it cannot while compiling your test code.</p>\n<p>It can still eliminate <code>foo()</code>s with zero side effects, but you win some, you lose some.</p>\n", "LastActivityDate": "2016-06-13T18:21:59.420"}});