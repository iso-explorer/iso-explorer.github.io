post_cb({"bq_ids": {"n4140": {"so_13730470_13730864_0": {"length": 4, "quality": 0.5714285714285714, "section_id": 763}, "so_13730470_13730864_2": {"length": 10, "quality": 1.0, "section_id": 763}, "so_13730470_40892857_0": {"length": 12, "quality": 0.9230769230769231, "section_id": 766}, "so_13730470_40892857_1": {"length": 7, "quality": 1.0, "section_id": 761}, "so_13730470_13730864_3": {"length": 4, "quality": 0.8, "section_id": 763}}, "n3337": {"so_13730470_13730864_0": {"length": 4, "quality": 0.5714285714285714, "section_id": 750}, "so_13730470_13730864_2": {"length": 10, "quality": 1.0, "section_id": 750}, "so_13730470_40892857_0": {"length": 7, "quality": 0.5384615384615384, "section_id": 734}, "so_13730470_40892857_1": {"length": 7, "quality": 1.0, "section_id": 748}, "so_13730470_13730864_3": {"length": 4, "quality": 0.8, "section_id": 750}}, "n4659": {"so_13730470_13730864_2": {"length": 7, "quality": 0.7, "section_id": 823}, "so_13730470_13730864_0": {"length": 4, "quality": 0.5714285714285714, "section_id": 823}, "so_13730470_40892857_0": {"length": 12, "quality": 0.9230769230769231, "section_id": 826}, "so_13730470_40892857_1": {"length": 7, "quality": 1.0, "section_id": 821}, "so_13730470_13730864_3": {"length": 4, "quality": 0.8, "section_id": 823}}}, "13731038": {"Id": "13731038", "PostTypeId": "2", "Body": "<p>I am not sure it will work, I do not find a confirmation for it in the documentation - but if the unordered_map is rehashing according to the classic hash table data structure, you could <strong><a href=\"http://www.cplusplus.com/reference/unordered_map/unordered_map/max_load_factor/\" rel=\"nofollow\">set the max_load_factor</a></strong> to a very high value and reset it back to normal when you are done (which will trigger a rehash) (or to predicted value if you can predict how many elements will be removed).</p>\n<p>In terms of classic hash table, it should work since rehash when decreasing the table occures when the size is lower then <code>1/max_load_factor</code>. </p>\n<p>(not sure it is the case in C++, but I assume it worthes the try, since it is really easy to implement).</p>\n", "LastEditorUserId": "572670", "LastActivityDate": "2012-12-05T19:51:00.023", "Score": "2", "CreationDate": "2012-12-05T19:35:46.943", "ParentId": "13730470", "CommentCount": "0", "OwnerUserId": "572670", "LastEditDate": "2012-12-05T19:51:00.023"}, "13730470": {"ViewCount": "3784", "Body": "<p>I have an std::unordered_map that I will be removing elements from via iteration.</p>\n<pre><code>auto itr = myMap.begin();\nwhile (itr != myMap.end()) {\n    if (/* removal condition */) {\n        itr = myMap.erase(itr);\n    } else {\n        ++itr;\n    }\n}\n</code></pre>\n<p>I would like to prevent the map for performing any expensive operations until I'm done removing all of the elements that I need to remove.  Do I have a valid concern?  Am I misunderstanding how the internal storage works?</p>\n", "AcceptedAnswerId": "40892857", "Title": "How do I prevent rehashing of an std::unordered_map while removing elements?", "CreationDate": "2012-12-05T18:59:20.293", "Id": "13730470", "CommentCount": "0", "FavoriteCount": "1", "PostTypeId": "1", "LastActivityDate": "2016-11-30T16:03:59.120", "Score": "21", "OwnerUserId": "1843978", "Tags": "<c++><map><iterator><hashtable><unordered-map>", "AnswerCount": "3"}, "13730864": {"Id": "13730864", "PostTypeId": "2", "Body": "<p>As far as I can tell, <code>std::unordered_map</code> is allowed to rehash on <code>erase(itr)</code>:</p>\n<blockquote>\n<p id=\"so_13730470_13730864_0\">C++11 Table 103 -- Unordered associative container requirements</p>\n<p id=\"so_13730470_13730864_1\"><code>a.erase(q)</code></p>\n<p id=\"so_13730470_13730864_2\">Erases the element pointed to\n  by <code>q</code>. Return value is the\n  iterator immediately following <code>q</code>\n  prior to the erasure.</p>\n<p id=\"so_13730470_13730864_3\">Average case\n  <code>O(1)</code>, <strong>worst\n  case\n  <code>O(a.size())</code></strong></p>\n</blockquote>\n<p>It would therefore seem that you do have a valid concern. As to addressing it, I can suggest several avenues:</p>\n<ol>\n<li>Make sure it's an actual problem rather than a hypothetical one. Profile the application, look at the source code for your C++ library, etc.</li>\n<li>If it is an actual problem, consider using a different container or a different algorithm.</li>\n<li>Consider simply marking the elements for deletion through a boolean flag associated with each element, and sweeping the deleted elements from time to time, thereby amortizing the costs.</li>\n<li>Consider experimenting with the load factor, as suggested by @amit in the comments. Even though the container would still be allowed to take <code>O(a.size())</code> time to erase elements, a different load factor might have an effect on the real-world performance of your application.</li>\n</ol>\n", "LastEditorUserId": "367273", "LastActivityDate": "2012-12-05T19:38:21.167", "Score": "5", "CreationDate": "2012-12-05T19:24:22.867", "ParentId": "13730470", "CommentCount": "8", "OwnerUserId": "367273", "LastEditDate": "2012-12-05T19:38:21.167"}, "40892857": {"Id": "40892857", "PostTypeId": "2", "Body": "<p>The unordered containers are forbidden from rehashing during an <code>erase</code>:</p>\n<p>[unord.req]/p14:</p>\n<blockquote>\n<p id=\"so_13730470_40892857_0\">The <code>erase</code> members shall invalidate only iterators and references to\n  the erased elements, and preserve the relative order of the elements\n  that are not erased.</p>\n</blockquote>\n<p>[unord.req]/p9:</p>\n<blockquote>\n<p id=\"so_13730470_40892857_1\">Rehashing invalidates iterators, changes ordering between elements, and ...</p>\n</blockquote>\n<p>Your code is fine as is.</p>\n", "LastActivityDate": "2016-11-30T16:03:59.120", "CommentCount": "3", "CreationDate": "2016-11-30T16:03:59.120", "ParentId": "13730470", "Score": "6", "OwnerUserId": "576911"}});